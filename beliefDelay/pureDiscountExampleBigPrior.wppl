// like pureDiscountExample, but with a prior with bigger support, meaning that
// exact inference is infeasible.

// NOTE: approximate inference is also infeasible, don't use this example

// WORLD PARAMS

var gridworldMDP = makeDonutWorld2({big: true, maxTimeAtRestaurant : 2});
var world = makeGridworldPOMDP(gridworldMDP);

// possible latent states

var trueLatentState = {'Donut N': true,
		       'Donut S': true,
		       'Veg': true,
		       'Noodle': true};

// start state
var startState = {manifestState: {loc: [3,1],
				  terminateAfterAction: false,
				  timeLeft: 14},
		  latentState: trueLatentState};

// POTENTIAL AGENT PARAMS

// the agent's prior
var agentPrior = getPriorBeliefGridworld( startState.manifestState,
					  function(){
					    return trueLatentState;
					  });

// PRIORS OVER AGENT PARAMS

var agentUtilityTableSampler = function() {
  var donutUtility1 = uniformDraw([-20, -10, 10, 20]);
  var donutUtility2 = donutUtility1 < 0 ? uniformDraw([10, 20])
	: uniformDraw([-10, -20]);
  var vegUtility1 = uniformDraw([-20, -10, 10, 20]);
  var vegUtility2 = vegUtility1 < 0 ? uniformDraw([10, 20])
	: uniformDraw([-10, -20]);
  return {
    'Donut N' : [donutUtility1, donutUtility2],
    'Donut S' : [donutUtility1, donutUtility2],
    Veg       : [vegUtility1, vegUtility2],
    Noodle    : [0, 0]
  };
};

var agentDiscountSampler = function() {
  return uniformDraw(range(4));
};

var agentSophisticationSampler = function() {
  return uniformDraw(['sophisticated', 'naive']);
};

var pomdpUtilityFromManifestUtility = function(utility) {
  return function (state) { 
    return utility(state.manifestState);
  };
};

// see what the agent does with the parameters we want to infer to check if we're right

// var agent = makeBeliefDelayAgent({
//   priorBelief : agentPrior,
//   utility : pomdpUtilityFromManifestUtility(makeDonutUtility(world, vegUtilityTable)),
//   // utility : pomdpUtilityFromManifestUtility(makeDonutUtility(world, donutUtilityTable)),
//   alpha : 100,
//   noDelays: false,
//   discount: 1,
//   sophisticatedOrNaive: 'sophisticated',
//   myopia: {on: false, bound: 0},
//   boundVOI: {on: false, bound: 0}
// }, world);


// var trajectory = simulateBeliefDelayAgent(startState, world, agent, 'states');

// var locs = map(function(state) {return state.manifestState.loc;}, trajectory);

// console.log(locs);
// ash();


// PATH WE CONDITION ON
var path = [[3,1], [3,2], [3,3], [3,4], [3,5], [2,5]];

// INFERENCE

var conditionOnPath = function (agent, path, world, startState) {
  var agentAct = agent.act;
  var agentUpdateBelief = agent.updateBelief;
  var priorBelief = agent.params.priorBelief;
  var transition = world.transition;
  var worldObserve = world.observe;
  var observe = getFullObserve(worldObserve);

  var shouldTerminate = function (manifestState) {
    return manifestState.terminateAfterAction;
  };
  
  var _conditionOnPath = function(state, priorBelief, action, i) {
    var observation = observe(state);

    var delay = 0;

    var belief = agentUpdateBelief(priorBelief, observation, action, delay);

    var newAction = sample(agentAct(belief, delay));

    if (shouldTerminate(state.manifestState) || i >= path.length) {
      return 0;
    } else {   
      var nextState = transition(state, newAction);

      condition(_.isEqual(nextState.manifestState.loc, path[i]));

      return _conditionOnPath(nextState, belief, newAction, i+1);
    }
  };

  var startAction = 'noAction';

  return _conditionOnPath(startState, priorBelief, startAction, 1);
};

var posterior = function(inferFunction, options) {
  return function() {
    var posteriorERP = inferFunction(function () { 

      var agentUtilityTable = agentUtilityTableSampler();
      var discount = agentDiscountSampler();
      var sophistication = agentSophisticationSampler();
      var agent = makeBeliefDelayAgent({
	priorBelief : agentPrior,
	utility : pomdpUtilityFromManifestUtility(makeDonutUtility(world, agentUtilityTable)),
	alpha : 100,
	noDelays: discount===0,
	discount: discount,
	sophisticatedOrNaive: sophistication,
	myopia: {on: false, bound: 0},
	boundVOI: {on: false, bound: 0}
      }, world);

      conditionOnPath(agent, path, world, startState);

      return {
	utilityTable : agentUtilityTable,
	discount: discount,
	sophistication: sophistication
      };

    }, options);

    printERP(posteriorERP);
  };
};

// printERP(posterior);
// with way more possibilities (5*5*5*5*2*10 = 12500):
// estimate for time to enumerate: 295 minutes (based on time for pureDiscountExample)
// MCMC doesn't explore enough, takes ~100 seconds (depends on the run)
// SMC only comes up with one option, takes ~200 seconds

// with 1280 possiblities:
// estimate for time to enumerate: 30 minutes (based on time for pureDiscountExample)
// MCMC takes 221 seconds ~ 3.7 min, doesn't really get it right, but at least it explores
// SMC takes 151 seconds ~ 2.5 min, doesn't really get it right
// Incremental MH fails for some weird reason.

// with 512 possibilities:
// estimate for time to enumerate: 15 min
// MCMC: 141 seconds, kind of right (why is MCMC getting quicker?) - actually, time wildly
// varies, as does accuracy
// SMC: trial 1, 141 seconds, gets the right answer. trial 2, 127 seconds, gets it wrong

// should probably just give up, try pureBelief instead
timeit(posterior(SMC));
