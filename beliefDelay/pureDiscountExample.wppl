// here, we observe the agent start off near donut south, but go to donut north.
// we know that the agent knows the true state, so it must not be that the agent
// just likes donuts. Instead, the solution is that the agent likes veg, but is
// a naive hyperbolic discounter, aimed to go to veg, but got tempted by donuts
// instead. we also can conclude that the agent is probably not an extreme
// discounter, since they would go to donut south if they were, but it's within
// the realm of possibility because of softmax noise.

// WORLD PARAMS

var gridworldMDP = makeDonutWorld2({big: true, maxTimeAtRestaurant : 2});
var world = makeGridworldPOMDP(gridworldMDP);

// possible latent states

var trueLatentState = {'Donut N': true,
		       'Donut S': true,
		       'Veg': true,
		       'Noodle': true};

// start state
var startState = {manifestState: {loc: [3,1],
				  terminateAfterAction: false,
				  timeLeft: 14},
		  latentState: trueLatentState};

// POTENTIAL AGENT PARAMS

// possible utility functions
var donutUtilityTable = {
    'Donut N' : [20, -10],
    'Donut S' : [20, -10],
    'Veg'   : [-10, 20],
    'Noodle': [0, 0]
}

var vegUtilityTable = {
    'Donut N' : [10, -10],
    'Donut S' : [10, -10],
    'Veg'   : [-10, 20],
    'Noodle': [0, 0]
};

// the agent's prior
var agentPrior = getPriorBeliefGridworld( startState.manifestState,
					  function(){
					    return trueLatentState;
					  });

// PRIORS OVER AGENT PARAMS

var agentUtilityTableSampler = function() {
  return uniformDraw([donutUtilityTable, vegUtilityTable]);
};

var agentDiscountSampler = function() {
  return uniformDraw([1, 0, 100]);
};

var agentSophisticationSampler = function() {
  return uniformDraw(['sophisticated', 'naive']);
};

// see what the agent does with the parameters we want to infer to check if we're right
var pomdpUtilityFromManifestUtility = function(utility) {
  return function (state) { 
    return utility(state.manifestState);
  };
};

var agent = makeBeliefDelayAgent({
  priorBelief : agentPrior,
  utility : pomdpUtilityFromManifestUtility(makeDonutUtility(world, vegUtilityTable)),
  alpha : 100,
  noDelays: false,
  discount: 1,
  sophisticatedOrNaive: 'naive',
  myopia: {on: false, bound: 0},
  boundVOI: {on: false, bound: 0}
}, world);


var trajectory = simulateBeliefDelayAgent(startState, world, agent, 'states');

var locs = map(function(state) {return state.manifestState.loc;}, trajectory);

console.log(locs);


// PATH WE CONDITION ON
var path = [[3,1], [3,2], [3,3], [3,4], [3,5], [2,5]];

// INFERENCE

var conditionOnPath = function (agent, path, world, startState) {
  var agentAct = agent.act;
  var agentUpdateBelief = agent.updateBelief;
  var priorBelief = agent.params.priorBelief;
  var transition = world.transition;
  var worldObserve = world.observe;
  var observe = getFullObserve(worldObserve);

  var shouldTerminate = function (manifestState) {
    return manifestState.terminateAfterAction;
  };
  
  var _conditionOnPath = function(state, priorBelief, action, i) {
    var observation = observe(state);
    // we set *delay = 0* since we are not using hyperbolic discounting or myopia
    var delay = 0;

    var belief = agentUpdateBelief(priorBelief, observation, action, delay);

    var newAction = sample(agentAct(belief, delay));

    if (shouldTerminate(state.manifestState) || i >= path.length) {
      return 0;
    } else {   
      var nextState = transition(state, newAction);

      condition(_.isEqual(nextState.manifestState.loc, path[i]));

      return _conditionOnPath(nextState, belief, newAction, i+1);
    }
  };

  var startAction = 'noAction';

  return _conditionOnPath(startState, priorBelief, startAction, 1);
};

var posterior = Enumerate(function () { 

  var agentUtilityTable = agentUtilityTableSampler();
  var discount = agentDiscountSampler();
  var sophistication = agentSophisticationSampler();
  var agent = makeBeliefDelayAgent({
    priorBelief : agentPrior,
    utility : pomdpUtilityFromManifestUtility(makeDonutUtility(world, agentUtilityTable)),
    alpha : 100,
    noDelays: discount===0,
    discount: discount,
    sophisticatedOrNaive: sophistication,
    myopia: {on: false, bound: 0},
    boundVOI: {on: false, bound: 0}
  }, world);

  console.log("first", discount);
  conditionOnPath(agent, path, world, startState);
  console.log("after", discount);

  return {
    utilityTable : agentUtilityTable,
    discount: discount,
    sophistication: sophistication
  };

});

printERP(posterior);
