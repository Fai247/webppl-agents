// We know that donuts are immediately pleasurable, but one timestep later have
// a bad aftertaste, and that vegetables are initially unpleasant, but one
// timestep later have a very good aftertaste. We know that either veg or noodle
// gives net positive reward, and that the other gives net zero reward, but
// don't know which is which. We also aren't sure how much the agent discounts,
// or whether the agent is naive, but we do know that the agent knows the true
// latent state of the MDP.

// We observe the agent start off near donut south, but go to donut north.
// we know that the agent knows the true state, so it must not be that the agent
// just likes donuts. Instead, the solution is that the agent likes veg, but is
// a naive hyperbolic discounter, and aimed to go to veg. However, when the
// agent got near veg, the immediate reward of donut and the immediate negative
// reward of veg became very salient, and the later negative reward of donut
// and positive reward of veg looked small in comparison, so the agent changed
// its mind and went to donut instead.

// we also can conclude that the agent is probably not an extreme
// discounter, since they would go to donut south if they were, but it's within
// the realm of possibility because of softmax noise.


var nameToPath = {
  naive: [[3,1], [3,2], [3,3], [3,4], [3,5], [2,5]],
  sophisticated: [[ 3, 1 ],[ 3, 2 ],[ 3, 3 ],[ 4, 3 ], [ 5, 3 ],
                  [ 5, 4 ], [ 5, 5 ], [ 5, 6 ], [4, 6 ], [ 4, 7 ] ],
  donutSouth: [[3,1], [2,1], [1,1], [0,1], [0,0]],
  vegDirect: [[3,1], [3,2], [3,3], [3,4], [3,5], [3,6], [4,6], [4,7]]
};

var pathToName = function(path){
  var path = path.slice(0,path.length-1);

  var namedPaths = ._keys(nameToPath);

  var out = _.filter( namedPaths
    function(namedPath){
      return _.isEqual(path, nameToPath(namedPath)) ?
    });
  return out;
};
  
  
      

//   if (_.isEqual(path, nameToPath(naive))
//     return 'path is Donut North Naive';
//   }
//   if (_.isEqual(path,
//                [[ 3, 1 ],[ 3, 2 ],[ 3, 3 ],[ 4, 3 ], [ 5, 3 ],
//                 [ 5, 4 ], [ 5, 5 ], [ 5, 6 ], [4, 6 ], [ 4, 7 ] ])){
//     return 'path is Veg Sophistiated';
//   }
//   if (_.isEqual(path, [[3,1], [2,1], [1,1], [0,1], [0,0]])){
//     return 'path is Donut South Direct';
//   }
//   if (_.isEqual(path, [[3,1], [3,2], [3,3], [3,4], [3,5], [3,6], [4,6], [4,7]])){
//     return 'path is Veg direct';
//   }
//   return 'other path';
// };



// WORLD PARAMS

var gridworldMDP = makeDonutWorld2({big: true, maxTimeAtRestaurant : 2});
var world = makeGridworldPOMDP(gridworldMDP);

// possible latent states

var trueLatentState = {'Donut N': true,
		       'Donut S': true,
		       'Veg': true,
		       'Noodle': true};


// start state
var timeLeft = 11;
var startState = {manifestState: {loc: [3,1],
				  terminateAfterAction: false,
				  timeLeft: timeLeft},
		  latentState: trueLatentState};

// POTENTIAL AGENT PARAMS

// possible utility functions
var donutUtilityTable = {
    'Donut N' : [20, -10],
    'Donut S' : [20, -10],
    'Veg'   : [-10, 10],
    'Noodle': [0, 0]
};

var vegUtilityTable = {
    'Donut N' : [10, -10],
    'Donut S' : [10, -10],
    'Veg'   : [-10, 20],
    'Noodle': [0, 0]
};


var agentTable = function(){
  var donut = [uniformDraw([5,10]), -10];
  var veg = [0, uniformDraw([5,10])];
  return {
    'Donut N' : donut,
    'Donut S' : donut,
    'Veg'   : veg,
    'Noodle': [0, 0]
  };
};
                         
  
// the agent's prior
var agentPrior = getPriorBeliefGridworld( startState.manifestState,
					  function(){
					    return trueLatentState;
					  });

// PRIORS OVER AGENT PARAMS

var agentUtilityTableSampler = function() {
  return uniformDraw([donutUtilityTable, vegUtilityTable]);
};
var agentUtilityTableSampler = agentTable;


var agentDiscountSampler = function() {
  return uniformDraw([0, .1, 1]);
};

var agentSophisticationSampler = function() {
  return uniformDraw(['sophisticated', 'naive']);
};

var pomdpUtilityFromManifestUtility = function(utility) {
  return function (state) { 
    return utility(state.manifestState);
  };
};





// PATH WE CONDITION ON
var path = [[3,1], [3,2], [3,3], [3,4], [3,5], [2,5]];
var sophPath = [[ 3, 1 ],[ 3, 2 ],[ 3, 3 ],[ 4, 3 ], [ 5, 3 ],
                [ 5, 4 ], [ 5, 5 ], [ 5, 6 ], [4, 6 ], [ 4, 7 ] ];

// see what the agent does with the parameters we want to infer to check if we're right
var testAgent = makeBeliefDelayAgent({
  priorBelief : agentPrior,
  utility : pomdpUtilityFromManifestUtility(makeDonutUtility(world, vegUtilityTable)),
  alpha : 1000,
  noDelays: false,
  discount: 100,//1,
  sophisticatedOrNaive: 'naive',
  myopia: {on: false, bound: 0},
  boundVOI: {on: false, bound: 0}
}, world);


var testLocations = function(){
  return pathToName(trajectoryToLocations(
    simulateBeliefDelayAgent(startState, world, testAgent, 'states')));
};

var pathDist = Rejection(testLocations, 10);
printERP(pathDist);
//assert.ok( arraysEqual(path, testLocations.slice(0,testLocations.length-1), 'check' ) );
ash();



// INFERENCE

var conditionOnPath = function (agent, path, world, startState) {
  var agentAct = agent.act;
  var agentUpdateBelief = agent.updateBelief;
  var priorBelief = agent.params.priorBelief;
  var transition = world.transition;
  var worldObserve = world.observe;
  var observe = getFullObserve(worldObserve);

  var shouldTerminate = function (manifestState) {
    return manifestState.terminateAfterAction;
  };
  
  var _conditionOnPath = function(state, priorBelief, action, i) {
    var observation = observe(state);

    var delay = 0;

    var belief = agentUpdateBelief(priorBelief, observation, action, delay);

    var newAction = sample(agentAct(belief, delay));

    if (shouldTerminate(state.manifestState) || i >= path.length) {
      return 0;
    } else {   
      var nextState = transition(state, newAction);

      condition(_.isEqual(nextState.manifestState.loc, path[i]));

      return _conditionOnPath(nextState, belief, newAction, i+1);
    }
  };

  var startAction = 'noAction';

  return _conditionOnPath(startState, priorBelief, startAction, 1);
};

var posterior = function() {

  var posteriorERP = Enumerate(function () { 

    var agentUtilityTable = agentUtilityTableSampler();
    var discount = agentDiscountSampler();
    var sophistication = agentSophisticationSampler();
    var agent = makeBeliefDelayAgent({
      priorBelief : agentPrior,
      utility : pomdpUtilityFromManifestUtility(makeDonutUtility(world, agentUtilityTable)),
      alpha : 1000,
      noDelays: discount===0,
      discount: discount,
      sophisticatedOrNaive: sophistication,
      myopia: {on: false, bound: 0},
      boundVOI: {on: false, bound: 0}
    }, world);

    conditionOnPath(agent, path, world, startState);

    return {
      utilityTable : agentUtilityTable,
      discount: discount,
      sophistication: sophistication
    };

  });

  printERP(posteriorERP);
};

// printERP(posterior);
timeit(posterior);
