// we see the agent go to donuts instead of noodles. this could be because they
// like donuts, or it could be that the agent likes noodles but thinks that the
// shop is closed: we can't tell. however, if we see the agent pass by the noodle
// shop (and therefore learn that it is open), we will be able to infer whether
// they like noodles, and if they do, this will imply that they initially
// thought that the noodle shop was closed.

var gridworldMDP = makeDonutWorld2({big: true});
var gridworldPOMDP = makeGridworldPOMDP(gridworldMDP);
var feature = gridworldMDP.feature;
var transition = gridworldPOMDP.transition;
var observe = gridworldPOMDP.observe;

var donutUtilityTable = {'Donut N': 5,
			 'Donut S': 5,
			 'Veg': 1,
			 'Noodle': 1,
			 timeCost: -0.1};
 
var noodleUtilityTable = {'Donut N': 2,
			  'Donut S': 2,
			  Veg: 1,
			  Noodle: 5,
			  timeCost: -0.1};

var uninformedPrior = Enumerate(function(){
  if (flip(0.8)) {
    return {'Donut N': true,
	    'Donut S': true,
	    'Veg': true,
	    'Noodle': false};
  } else {
    return {'Donut N': true,
	    'Donut S': true,
	    'Veg': true,
	    'Noodle': true};
  }
});

var informedPrior = deltaERP({'Donut N': true,
			      'Donut S': true,
			      'Veg': true,
			      'Noodle': true});

var startState = {manifestState: {loc: [3,1],
				  terminateAfterAction: false,
				  timeLeft: 6,
				  },
		  latentState: {'Donut N': true,
				'Donut S': true,
				'Veg': true,
				'Noodle': true}};

var agent = makeBeliefAgent({utility: tableToUtilityFunction(noodleUtilityTable, feature),
			     alpha: 100,
			     priorBelief: uninformedPrior}, gridworldPOMDP);

var observedTrajectory = simulateBeliefAgent(startState, gridworldPOMDP, agent, 6,
					     'stateAction');
// GridWorld.draw(gridworldMDP, {trajectory: observedTrajectory});
// TODO: labels

// in a second trajectory, we let the agent know that noodle is open, and see where
// it goes
var startState2 = {manifestState: {loc: [5,4],
				   terminateAfterAction: false,
				   timeLeft: 10,
				   timeAtRestaurant: 1
				   },
		   latentState: {'Donut N': true,
				 'Donut S': true,
				 'Veg': true,
				 'Noodle': true}};
var observedTrajectory2 = simulateBeliefAgent(startState2, gridworldPOMDP, agent,
					      'stateAction');
// GridWorld.draw(gridworldMDP, {trajectory: observedTrajectory2});
// TODO: labels

// uncomment one of these lines to see the effect of conditioning on one or
// both trajectories.
// var observedTrajectories = [observedTrajectory, observedTrajectory2];
var observedTrajectories = [observedTrajectory];

var numTrajectories = observedTrajectories.length;

var factorOnSequence = function(currentBelief, index, observedStateAction, agent){
  if (index >= observedStateAction.length){ 
    return []; // no-op
  } else {
    var agentAct = agent.act;
    var agentUpdateBelief = agent.updateBelief;
    
    var state = observedStateAction[index][0];
    var observedAction = observedStateAction[index][1];

    var observation = observe(state);
    var nextBelief = agentUpdateBelief(state.manifestState, currentBelief, observation);
    var nextActionERP = agentAct(state.manifestState, nextBelief, 0);
    
    factor(nextActionERP.score([], observedAction));
    
    return factorOnSequence(nextBelief, index + 1, observedStateAction, agent);
  }
};

var agentPosterior = function(){
  return printERP(Enumerate(function(){
    var utilityTable = uniformDraw([donutUtilityTable, noodleUtilityTable]);
    var utility = tableToUtilityFunction(utilityTable);
    var agentPrior = uniformDraw([uninformedPrior, informedPrior]);
    var agent = makeBeliefAgent({utility: utility,
				 alpha: 100,
				 priorBelief: agentPrior},
				gridworldPOMDP);

    var factorTrajectory = function(trajectory) {
      return factorOnSequence(agentPrior, 0, trajectory,
				 agent);
    };

    map(factorTrajectory, observedTrajectories);

    return {utilityTable: utilityTable,
	    prior: agentPrior};
  }));
};

timeit(agentPosterior);
