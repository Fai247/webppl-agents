// here, we observe the agent in a gridworld, going past a nearby donut shop
// and towards a further away donut shop. we can conclude that the agent likes
// donuts, but thinks that the nearby donut shop is closed.

var gridworldMDP = makeDonutWorld2({big: true});
var gridworldPOMDP = makeGridworldPOMDP(gridworldMDP);
var feature = gridworldMDP.feature;
var transition = gridworldPOMDP.transition;
var observe = gridworldPOMDP.observe;

// here, we define tables listing the utility of each restaurant, and a function
// that converts these tables into utility functions.

var donutUtilityTable = {'Donut N': 5,
			 'Donut S': 5,
			 'Veg': 1,
			 'Noodle': 1,
			 timeCost: -0.1};
 
var vegUtilityTable = {'Donut N': 1,
		       'Donut S': 1,
		       Veg: 3,
		       Noodle: 1,
		       timeCost: -0.1};

var tableToUtilityFunction = function(table) {
  return function(state, action) {
    if (state.manifestState.dead) {
      return 0;
    }
    var stateFeatureName = feature(state.manifestState).name;
    if (stateFeatureName) {
      return table[stateFeatureName];
    } else {
      return table.timeCost;
    }
  };
};

// here, we define the agent's actual prior, as well as an informed prior that
// knows the true latent state.

var uninformedPrior = Enumerate(function(){
  if (flip(0.8)) {
    return {'Donut N': true,
	    'Donut S': false,
	    'Veg': true,
	    'Noodle': true};
  } else {
    return {'Donut N': true,
	    'Donut S': true,
	    'Veg': true,
	    'Noodle': true};
  }
});

var informedPrior = deltaERP({'Donut N': true,
			      'Donut S': true,
			      'Veg': true,
			      'Noodle': true});

// we start the agent off near Donut South
var startState = {manifestState: {loc: [2,1],
				  dead: false,
				  timeLeft: 10,
				  digest: 1},
		  latentState: {'Donut N': true,
				'Donut S': true,
				'Veg': true,
				'Noodle': true}};

// making the agent
var agent = makeBeliefAgent({utility: tableToUtilityFunction(donutUtilityTable),
			     alpha: 100,
			     priorBelief: uninformedPrior}, gridworldPOMDP);

// generating the agent's trajectory. note that we observe the agent's actions,
// for reasons which will soon become clear.
var observedTrajectory = simulateBeliefAgent(startState, gridworldPOMDP, agent, 10,
					     'stateAction');
// GridWorld.draw(gridworldMDP, {trajectory: observedTrajectory});
// TODO: get labels

// here, we do inference in a slightly different way. instead of conditioning
// on our randomly generated agent generating exactly the same trajectory as
// the one we observe, instead we take them along the trajectory, let them
// update their beliefs from the observations along the trajectory, and
// condition on them taking the same actions. This way, we reject agents at the
// first action where they differ, rather than having to generate a whole
// incorrect trajectory.
var factorOnSequence = function(currentBelief, index, observedStateAction, agent){
  // *index* tracks how far through the trajectory we are. If we are at the end
  // of the trajectory, we don't have to factor any more.
  if (index >= observedStateAction.length){ 
    return [];
  } else {
    var agentAct = agent.act;
    var agentUpdateBelief = agent.updateBelief;
    
    var state = observedStateAction[index][0];
    var observedAction = observedStateAction[index][1];

    var observation = observe(state);
    var nextBelief = agentUpdateBelief(state.manifestState, currentBelief, observation);
    var nextActionERP = agentAct(state.manifestState, nextBelief, 0);
    
    factor(nextActionERP.score([], observedAction));
    
    return factorOnSequence(nextBelief, index + 1, observedStateAction, agent);
  }
};

// now, we actually do the inference.
var agentPosterior = function(){
  return printERP(Enumerate(function(){
    var utilityTable = uniformDraw([donutUtilityTable, vegUtilityTable]);
    var utility = tableToUtilityFunction(utilityTable);
    var agentPrior = uniformDraw([uninformedPrior, informedPrior]);
    var agent = makeBeliefAgent({utility: utility,
				 alpha: 100,
				 priorBelief: agentPrior},
				gridworldPOMDP);

    factorOnSequence(agentPrior, 0, observedTrajectory, agent);
    
    return {utilityTable: utilityTable,
	    prior: agentPrior};
  }));
};

timeit(agentPosterior);
