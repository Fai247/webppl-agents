// note: currently, most tests are focussing on the inference via enumeration,
// since that's deterministic and easier to write tests for.
// TODO: fix that.

// also TODO: finish test 4 maybe

var myInSupport = function(x, erp){return erp.score([], x) > -100; };

var getActualSupport = function(erp) {
  assert.ok(isERP(erp), 'tried to get the support of something other than an ERP');
  var hasNonNegligibleProbability = function(x) {
    return erp.score([], x) > -100;
  };
  return filter(hasNonNegligibleProbability, erp.support());
};t

var checkEqualDeltaErps = function(erpArray) {
  assert.ok(isERP(erpArray[0]) && isERP(erpArray[1]),
	    'checkEqualDeltaErps applied to something other than an array of erps');
  var sample2 = function() {
    assert.ok(_.isEqual(sample(erpArray[0]), sample(erpArray[1])),
	      'erps not equal');
  };
  repeat(5, sample2);
};

var test1 = function() {

  // WORLD PARAMS
  var world = makeRestaurantChoiceWorld({POMDP:true});
  var perceivedTotalTime = 10;
  var startingLocation = [2,1];

  // Possible latent states
  var allOpenLatentState = {
    'Donut N': true, 'Donut S': true, 'Veg': true, 'Noodle': true
  };
  var onlyDonutSouthClosedLatentState = {
    'Donut N': true, 'Donut S': false, 'Veg': true, 'Noodle': true
  };

  var trueLatentState = allOpenLatentState;
  var startState = buildState({loc: startingLocation,
		               terminateAfterAction: false,
		               timeLeft: perceivedTotalTime,
		               timeAtRestaurant: 1},
	                      trueLatentState);


  // TRUE AGENT PARAMS
  // Params for true agent: agent thinks Donut South closed w/ prob .8


  // Possible utility functions (true agent has donutUtility)
  var donutUtilityTable = {'Donut N': 5,
			   'Donut S': 5,
			   'Veg': 1,
			   'Noodle': 1,
			   'timeCost': -0.1};
  
  var vegUtilityTable = {'Donut N': 1,
			 'Donut S': 1,
			 'Veg': 10,
			 'Noodle': 1,
			 'timeCost': -0.1};

  var uninformedLatentStateSampler = function(){
    return flip(.8) ? onlyDonutSouthClosedLatentState : trueLatentState;
  };
  
  var truePriorBelief = getPriorBeliefGridworld( startState.manifestState, uninformedLatentStateSampler);


  var trueAgentParams = update(baseParamsNoDiscount, 
                               {priorBelief: truePriorBelief,
				utility: tableToUtilityFunction(donutUtilityTable, world)});



  // PRIOR FOR INFERENCE PARAMS

  var beliefOrBeliefDelay = 'belief';
  var makeAgent = getMakeAgentFunction(beliefOrBeliefDelay);
  var simulate = getSimulateFunction(beliefOrBeliefDelay);
  var agentTypeAndFunctions = {type: beliefOrBeliefDelay, makeAgent:makeAgent, simulate: simulate};

  var alternativePriorBelief = getPriorBeliefGridworld( startState.manifestState, function(){return trueLatentState;});
  var priorUtilityTable = function(){return uniformDraw([donutUtilityTable, vegUtilityTable]);};
  var priorAgentPrior = function(){return uniformDraw([truePriorBelief, alternativePriorBelief]);};

  var prior = {priorUtilityTable: Enumerate(priorUtilityTable),
               priorAgentPrior: Enumerate(priorAgentPrior)};

  // INFERENCE
  
  var numRejectionSamples = 10;
  var erps = map( function(trajectoryOrOffPolicy){
    return inferGridWorldPOMDP(world, startState, baseParamsNoDiscount, trueAgentParams, prior, agentTypeAndFunctions,
                               trajectoryOrOffPolicy, numRejectionSamples);
  }, ['trajectory', 'offPolicy']);

  // TESTS FOR INFERENCE

  // support of trajectory should be contained in support of offPolicy (since
  // trajectory is rejection sampled and offPolicy is rejection sampled)
  // need to filter 'support' for things which actually have positive
  // probability
  // NB: this is generally applicable


  var erp0ActualSupport = getActualSupport(erps[0]);
  
  var erp1ActualSupport = getActualSupport(erps[1]);

  map(function(index){
    assert.ok( myInSupport(erp0ActualSupport[index], erps[1]),
  	       'support of trajectory ERP not contained in support of offPolicy ERP');
  }, range(erp0ActualSupport.length));


  // we expect both ERPs to be delta ERPs
  
  checkEqualDeltaErps(erps);

  assert.ok(sample(erps[1]).utilityTable['Donut S'] === 5,
	    'posterior ERP failed to infer agent liking donuts');

  var agentBelief = sample(erps[1]).priorBelief;
  var agentBeliefSample = sample(agentBelief);
  assert.ok(agentBelief.score([], agentBeliefSample) < -0.1,
	    'posterior ERP failed to infer agents uncertainty');

  // other possible tests: look at MAP of erps[0] and erps[1], see if certain
  // things are more probable than other things in erps[1]

  console.log('passed first test');
};

var test2 = function() {
  // we see the agent go to donuts instead of noodles. this could be because they
  // like donuts, or it could be that the agent likes noodles but thinks that the
  // shop is closed: we can't tell. however, if we see the agent pass by the noodle
  // shop (and therefore learn that it is open), we will be able to infer whether
  // they like noodles, and if they do, this will imply that they initially
  // thought that the noodle shop was closed.

  // WORLD PARAMS
  var world = makeRestaurantChoiceWorld({POMDP:true});

  var perceivedTotalTime = 10;

  // possible latent states
  var noodleClosedLatent = {'Donut N': true,
			    'Donut S': true,
			    'Veg': true,
			    'Noodle': false};
  var everythingOpenLatent = {'Donut N': true,
			      'Donut S': true,
			      'Veg': true,
			      'Noodle': true};

  var trueLatentState = everythingOpenLatent;
  
  // start states
  var startState1 = {manifestState: {loc: [3,1],
				     terminateAfterAction: false,
				     timeLeft: 6,
				     timeAtRestaurant: 1},
		     latentState: trueLatentState};

  var startState2 = {manifestState: {loc: [5,4],
				     terminateAfterAction: false,
				     timeLeft: 10,
				     timeAtRestaurant: 1},
		     latentState: trueLatentState};

  // TRUE AGENT PARAMS
  
  // possible utility functions (agent has noodleUtilityTable)
  var donutUtilityTable = {'Donut N': 5,
			   'Donut S': 5,
			   'Veg': 1,
			   'Noodle': 1,
			   timeCost: -0.1};
  
  var noodleUtilityTable = {'Donut N': 2,
			    'Donut S': 2,
			    Veg: 1,
			    Noodle: 5,
			    timeCost: -0.1};

  // possible priors that the agent could have (actual prior is uninformed)
  var uninformedLatentStateSampler = function(){
    return flip(.8) ? noodleClosedLatent : trueLatentState;
  };

  var truePriorBelief1 = getPriorBeliefGridworld( startState1.manifestState,
						  uninformedLatentStateSampler);


  var trueAgentParams1 = update(baseParamsNoDiscount, 
				{priorBelief: truePriorBelief1,
				 utility: tableToUtilityFunction(noodleUtilityTable,
								 world)});
  // PRIOR FOR INFERENCE PARAMS

  var beliefOrBeliefDelay = 'belief';
  var makeAgent = getMakeAgentFunction(beliefOrBeliefDelay);
  var simulate = getSimulateFunction(beliefOrBeliefDelay);
  var agentTypeAndFunctions = {type: beliefOrBeliefDelay,
			       makeAgent:makeAgent,
			       simulate: simulate};

  var alternativePriorBelief1 = getPriorBeliefGridworld( startState1.manifestState,
							 function(){return trueLatentState;});
  var priorUtilityTable = function(){
    return uniformDraw([donutUtilityTable, noodleUtilityTable]);
  };
  var priorAgentPrior1 = function(){
    return uniformDraw([truePriorBelief1, alternativePriorBelief1]);
  };

  var prior1 = {priorUtilityTable: Enumerate(priorUtilityTable),
		priorAgentPrior: Enumerate(priorAgentPrior1)};

  // INFERENCE
  
  var numRejectionSamples = 20;

  var erps1 = map( function(trajectoryOrOffPolicy){
    return inferGridWorldPOMDP(world, startState1, baseParamsNoDiscount,
			       trueAgentParams1, prior1, agentTypeAndFunctions,
			       trajectoryOrOffPolicy, numRejectionSamples);
  }, ['trajectory', 'offPolicy']);

  // INFERENCE TESTS

  // support of trajectory should be contained in support of offPolicy (since
  // trajectory is rejection sampled and offPolicy is rejection sampled)
  // need to filter 'support' for things which actually have positive
  // probability
  // NB: this is generally applicable
  var erp10ActualSupport = getActualSupport(erps1[0]);
  
  var erp11ActualSupport = getActualSupport(erps1[1]);

  map(function(index){
    assert.ok( myInSupport(erp10ActualSupport[index], erps1[1]),
  	       'support of trajectory ERP not contained in support of offPolicy ERP');
  }, range(erp10ActualSupport.length));

  // inference should be unsure of whether the agent likes noodles

  assert.ok(Math.abs(erps1[1].score([], {utilityTable: noodleUtilityTable,
					 priorBelief: truePriorBelief1})
		     - erps1[1].score([], {utilityTable: donutUtilityTable,
					   priorBelief: truePriorBelief1})) < 0.5,
	    'inference improperly sure about whether agent likes noodles');

  assert.ok(Math.abs(erps1[1].score([], {utilityTable: noodleUtilityTable,
					 priorBelief: truePriorBelief1})
		     - erps1[1].score([], {utilityTable: donutUtilityTable,
					   priorBelief: alternativePriorBelief1})) < 0.5,
	    'inference improperly sure about whether agent likes noodles');
  
  // inference should think that if agent likes noodles, that agent thinks
  // noodles are closed, but if agent doesn't like noodles, then unsure about
  // agent's beliefs

  // console.log('posterior on agent params:');
  // printERP(erps1[1]);
  
  // console.log('true prior belief 1:');
  // printERP(truePriorBelief1);


  assert.ok(myInSupport({utilityTable: noodleUtilityTable,
			 priorBelief: truePriorBelief1}, erps1[1]),
	    'Enumeration incorrectly rules out true explanation');

  assert.ok(myInSupport({utilityTable: noodleUtilityTable,
			 priorBelief: truePriorBelief1}, erps1[0]),
	    'Rejection sampling incorrectly rules out true explanation');
  
  assert.ok(!myInSupport({utilityTable: noodleUtilityTable,
			  priorBelief: alternativePriorBelief1}, erps1[1]),
	    'incorrect inference that agent could like noodles and know latent state');

  console.log('passed second test part 1');
  
  // condition on second trajectory

  // update erps1[1] so that the agent knows the initial manifest state
  var jointPrior = Enumerate(function(){
    var jointSample = sample(erps1[1]);
    var utilityTable = jointSample.utilityTable;
    var agentPrior = jointSample.priorBelief;
    var latentStateSampler = function(){
      return sample(agentPrior).latentState;
    };
    var newAgentPrior = getPriorBeliefGridworld(startState2.manifestState,
						latentStateSampler);
    return {utilityTable: utilityTable,
	    priorBelief: newAgentPrior};
  });

  var prior2 = {isJoint: true,
		jointPrior: jointPrior};

  var truePriorBelief2 = getPriorBeliefGridworld( startState2.manifestState,
						  uninformedLatentStateSampler);


  var trueAgentParams2 = update(baseParamsNoDiscount, 
				{priorBelief: truePriorBelief2,
				 utility: tableToUtilityFunction(noodleUtilityTable,
								 world)});


  var erps2 = map( function(trajectoryOrOffPolicy){
    return inferGridWorldPOMDP(world, startState2, baseParamsNoDiscount,
  			       trueAgentParams2, prior2, agentTypeAndFunctions,
  			       trajectoryOrOffPolicy, numRejectionSamples);
  }, ['trajectory', 'offPolicy']);

  // check if inference functions are working as expected
  var erp20ActualSupport = getActualSupport(erps2[0]);
  
  var erp21ActualSupport = getActualSupport(erps2[1]);

  map(function(index){
    assert.ok( myInSupport(erp20ActualSupport[index], erps2[1]),
  	       'support of trajectory ERP not contained in support of offPolicy ERP');
  }, range(erp20ActualSupport.length));

  // ERPs should be delta ERPs (almost)

  checkEqualDeltaErps(erps2);
  
  // inference should think that agent likes noodles and thought noodles were closed

  assert.ok(sample(erps2[1]).utilityTable['Noodle'] === 5,
	    'posterior ERP failed to infer agent liking noodles');
  var agentBelief = sample(erps2[1]).priorBelief;
  var agentBeliefSample = sample(agentBelief);
  assert.ok(agentBelief.score([], agentBeliefSample) < -0.1,
	    'posterior ERP failed to infer agents uncertainty');

  // true params should be in support of both erps -- this test fails because
  // the true agent prior erp has its possiblities listed in the wrong order.
  // I don't think that there would have been a problem had I not modified the
  // ERP in the *jointPrior* code block at line 279.
  // I judged that fixing this would be more trouble than it was worth, although
  // it should be done eventually.
  
  // assert.ok(myInSupport({utilityTable: noodleUtilityTable,
  // 			 priorBelief: truePriorBelief2}, erps2[1]),
  // 	    'Enumeration incorrectly rules out true explanation');

  // assert.ok(myInSupport({utilityTable: noodleUtilityTable,
  // 			 priorBelief: truePriorBelief1}, erps2[0]),
  // 	    'Rejection sampling incorrectly rules out true explanation');

  console.log('passed second test part 2');
};

var test3 = function() {
  // here, we see the agent go the long way around to veg. we deduce that they
  // must prefer noodle to veg, and think that noodle is open, despite noodle
  // actually being closed (as otherwise they would just go the short way
  // around)

  // WORLD PARAMS
  var world = makeRestaurantChoiceWorld({POMDP:true});


  // possible latent states
  var noodleClosedLatent = {'Donut N': true,
			    'Donut S': true,
			    'Veg': true,
			    'Noodle': false};
  var everythingOpenLatent = {'Donut N': true,
			      'Donut S': true,
			      'Veg': true,
			      'Noodle': true};

  var trueLatentState = noodleClosedLatent;
  
  // start states
  var startState = {manifestState: {loc: [3,1],
				    terminateAfterAction: false,
				    timeLeft: 10,
				    timeAtRestaurant: 1},
		    latentState: trueLatentState};

  // TRUE AGENT PARAMS
  
  // possible utility functions (agent has noodleUtilityTable)
  var noodleUtilityTable = {'Donut N': 1,
			    'Donut S': 1,
			    Veg: 1,
			    Noodle: 3,
			    timeCost: -0.1};

  var vegUtilityTable = {'Donut N': 1,
			 'Donut S': 1,
			 Veg: 3,
			 Noodle: 1,
			 timeCost: -0.1};

  // possible priors that the agent could have (actual prior is uninformed)
  var uninformedLatentStateSampler = function(){
    return flip(.8) ? everythingOpenLatent : trueLatentState;
  };

  var truePriorBelief = getPriorBeliefGridworld( startState.manifestState,
						 uninformedLatentStateSampler);


  var trueAgentParams = update(baseParamsNoDiscount, 
			       {priorBelief: truePriorBelief,
				utility: tableToUtilityFunction(noodleUtilityTable,
								world)});
  // PRIOR FOR INFERENCE PARAMS

  var beliefOrBeliefDelay = 'belief';
  var makeAgent = getMakeAgentFunction(beliefOrBeliefDelay);
  var simulate = getSimulateFunction(beliefOrBeliefDelay);
  var agentTypeAndFunctions = {type: beliefOrBeliefDelay,
			       makeAgent:makeAgent,
			       simulate: simulate};

  var alternativePriorBelief = getPriorBeliefGridworld( startState.manifestState,
							function(){return trueLatentState;});

  var priorUtilityTable = function(){
    return uniformDraw([vegUtilityTable, noodleUtilityTable]);
  };
  var priorAgentPrior = function(){
    return uniformDraw([truePriorBelief, alternativePriorBelief]);
  };

  var prior = {priorUtilityTable: Enumerate(priorUtilityTable),
	       priorAgentPrior: Enumerate(priorAgentPrior)};

  // INFERENCE
  
  var numRejectionSamples = 20;

  var erps = map( function(trajectoryOrOffPolicy){
    return inferGridWorldPOMDP(world, startState, baseParamsNoDiscount,
			       trueAgentParams, prior, agentTypeAndFunctions,
			       trajectoryOrOffPolicy, numRejectionSamples);
  }, ['trajectory', 'offPolicy']);

  // INFERENCE TESTS

  // support of trajectory should be contained in support of offPolicy (since
  // trajectory is rejection sampled and offPolicy is rejection sampled)
  // need to filter 'support' for things which actually have positive
  // probability
  // NB: this is generally applicable
  var erp0ActualSupport = getActualSupport(erps[0]);
  
  var erp1ActualSupport = getActualSupport(erps[1]);

  map(function(index){
    assert.ok( myInSupport(erp0ActualSupport[index], erps[1]),
  	       'support of trajectory ERP not contained in support of offPolicy ERP');
  }, range(erp0ActualSupport.length));

  // ERPs should be delta ERPs (almost)

  checkEqualDeltaErps(erps);
  
  // inference should think that agent likes noodles and thought noodles were closed

  assert.ok(sample(erps[1]).utilityTable['Noodle'] === 3,
	    'posterior ERP failed to infer agent liking noodles');
  var agentBelief = sample(erps[1]).priorBelief;
  var agentBeliefSample = sample(agentBelief);
  assert.ok(agentBelief.score([], agentBeliefSample) < -0.1,
	    'posterior ERP failed to infer agents uncertainty');

  // true params should be in support of both erps
  
  assert.ok(myInSupport({utilityTable: noodleUtilityTable,
  			 priorBelief: truePriorBelief}, erps[1]),
  	    'Enumeration incorrectly rules out true explanation');

  assert.ok(myInSupport({utilityTable: noodleUtilityTable,
  			 priorBelief: truePriorBelief}, erps[0]),
  	    'Rejection sampling incorrectly rules out true explanation');

  console.log('passed third test');
};

var test4 = function() {
  // like test1, but with rich priors, such that we need to use
  // MCMC inference, and won't get an exact result

  // WORLD PARAMS
  // noReverse is an optimisation for gridworldMDP that makes inference run faster
  var gridworldMDP = makeDonutWorld2({big: true, noReverse: false});
  var world = makeGridworldPOMDP(gridworldMDP);

  // possible latent states
  var dsClosedLatent = {'Donut N': true,
			'Donut S': false,
			'Veg': true,
			'Noodle': true};
  var everythingOpenLatent = {'Donut N': true,
			      'Donut S': true,
			      'Veg': true,
			      'Noodle': true};

  var trueLatentState = everythingOpenLatent;
  
  var startState = buildState({loc: [3,1],
		               terminateAfterAction: false,
		               timeLeft: 6,
		               timeAtRestaurant: 1},
	                      trueLatentState);


  // TRUE AGENT PARAMS
  // Params for true agent: agent thinks Donut South closed w/ prob .8

  // agent's utility function
  var donutUtilityTable = {'Donut N': 4,
			   'Donut S': 4,
			   'Veg': 1,
			   'Noodle': 1,
			   'timeCost': -0.1};
  
  var uninformedLatentStateSampler = function(){
    return flip(.8) ? dsClosedLatent : trueLatentState;
  };

  var makeLatentSampler = function(p) {
    return function(){
      return flip(p) ? dsClosedLatent : trueLatentState;
    };
  };
  
  var truePriorBelief = getPriorBeliefGridworld(startState.manifestState,
						makeLatentSampler(0.8));


  var trueAgentParams = update(baseParamsNoDiscount, 
                               {priorBelief: truePriorBelief,
				utility: tableToUtilityFunction(donutUtilityTable,
								world)});



  // PRIOR FOR INFERENCE PARAMS

  var beliefOrBeliefDelay = 'belief';
  var makeAgent = getMakeAgentFunction(beliefOrBeliefDelay);
  var simulate = getSimulateFunction(beliefOrBeliefDelay);
  var agentTypeAndFunctions = {type: beliefOrBeliefDelay,
			       makeAgent: makeAgent,
			       simulate: simulate};

  var priorUtilityTable = function(){
    var donutUtility = uniformDraw(range(5));
    return {'Donut N': donutUtility,
	    'Donut S': donutUtility,
	    'Veg': uniformDraw(range(5)),
	    'Noodle': uniformDraw(range(5)),
	    'timeCost': -0.1};
  };
  
  var priorAgentPrior = function(){
    var agentProbDSClosed = uniformDraw([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,
					 0.8, 0.9]);
    var agentLatentSampler = makeLatentSampler(agentProbDSClosed);
    return getPriorBeliefGridworld(startState.manifestState,
				   agentLatentSampler);
  };

  var prior = {priorUtilityTable: Enumerate(priorUtilityTable),
               priorAgentPrior: Enumerate(priorAgentPrior)};

  // INFERENCE
  
  var numRejectionSamples = 10;
  var erps = map( function(trajectoryOrOffPolicy){
    return inferGridWorldPOMDP(world, startState, baseParamsNoDiscount,
			       trueAgentParams, prior, agentTypeAndFunctions,
                               trajectoryOrOffPolicy, numRejectionSamples);
  }, ['trajectory', 'offPolicy']);

  // TESTS FOR INFERENCE

  // support of trajectory should be contained in support of offPolicy (since
  // trajectory is rejection sampled and offPolicy is rejection sampled)
  // need to filter 'support' for things which actually have positive
  // probability
  // NB: this is generally applicable


  var erp0ActualSupport = getActualSupport(erps[0]);
  
  var erp1ActualSupport = getActualSupport(erps[1]);

  map(function(index){
    assert.ok( myInSupport(erp0ActualSupport[index], erps[1]),
  	       'support of trajectory ERP not contained in support of offPolicy ERP');
  }, range(erp0ActualSupport.length));


  // we expect both ERPs to be delta ERPs
  
  checkEqualDeltaErps(erps);

  assert.ok(sample(erps[1]).utilityTable['Donut S'] === 5,
	    'posterior ERP failed to infer agent liking donuts');

  var agentBelief = sample(erps[1]).priorBelief;
  var agentBeliefSample = sample(agentBelief);
  assert.ok(agentBelief.score([], agentBeliefSample) < -0.1,
	    'posterior ERP failed to infer agents uncertainty');

  // other possible tests: look at MAP of erps[0] and erps[1], see if certain
  // things are more probable than other things in erps[1]

  console.log('passed fourth test');
};

test1();
test2();
test3();
