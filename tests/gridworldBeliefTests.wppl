var test1 = function() {

  // WORLD PARAMS
  var world = getBigDonutWorld();
  var feature = world.feature;
  var perceivedTotalTime = 10;
  var startingLocation = [2,1];

  // Possible latent states
  var allOpenLatentState = {
    'Donut N': true, 'Donut S': true, 'Veg': true, 'Noodle': true
  };
  var onlyDonutSouthClosedLatentState = {
    'Donut N': true, 'Donut S': false, 'Veg': true, 'Noodle': true
  };

  var trueLatentState = allOpenLatentState;
  var startState = buildState({loc: startingLocation,
		               terminateAfterAction: false,
		               timeLeft: perceivedTotalTime,
		               timeAtRestaurant: 1},
	                      trueLatentState);


  // TRUE AGENT PARAMS
  // Params for true agent: agent thinks Donut South closed w/ prob .8


  // Possible utility functions (true agent has donutUtility)
  var donutUtilityTable = {'Donut N': 5,
			   'Donut S': 5,
			   'Veg': 1,
			   'Noodle': 1,
			   'timeCost': -0.1};
  
  var vegUtilityTable = {'Donut N': 1,
			 'Donut S': 1,
			 'Veg': 10,
			 'Noodle': 1,
			 'timeCost': -0.1};

  var uninformedLatentStateSampler = function(){
    return flip(.8) ? onlyDonutSouthClosedLatentState : trueLatentState;
  };

  var truePriorBelief = getPriorBeliefGridworld( startState.manifestState, uninformedLatentStateSampler);


  var trueAgentParams = update(baseParamsNoDiscount, 
                               {priorBelief: truePriorBelief,
				utility: tableToUtilityFunction(donutUtilityTable, feature)});



  // PRIOR FOR INFERENCE PARAMS

  var beliefOrBeliefDelay = 'belief';
  var makeAgent = getMakeAgentFunction(beliefOrBeliefDelay);
  var simulate = getSimulateFunction(beliefOrBeliefDelay);
  var agentTypeAndFunctions = {type: beliefOrBeliefDelay, makeAgent:makeAgent, simulate: simulate};

  var alternativePriorBelief = getPriorBeliefGridworld( startState.manifestState, function(){return trueLatentState;});
  var priorUtilityTable = function(){return uniformDraw([donutUtilityTable, vegUtilityTable]);};
  var priorAgentPrior = function(){return uniformDraw([truePriorBelief, alternativePriorBelief]);};

  var prior = {priorUtilityTable: Enumerate(priorUtilityTable),
               priorAgentPrior: Enumerate(priorAgentPrior)};

  var numRejectionSamples = 10;
  var erps = map( function(trajectoryOrOffPolicy){
    return inferGridWorldPOMDP(world, startState, baseParamsNoDiscount, trueAgentParams, prior, agentTypeAndFunctions,
                               trajectoryOrOffPolicy, numRejectionSamples);
  }, ['trajectory', 'offPolicy']);


  // support doesn't work
  // TODO: figure out how to make support work
  // // support of trajectory should be contained in support of offPolicy (since trajectory is rejection
  // // sampled and offPolicy is rejection sampled)
  // // NB: this is generally applicable
  // map(function(index){
  //   assert.ok(_.some(erps[1].support(), function(elem){return elem === erps[0].support()[index];}),
  // 	   'support of trajectory ERP not contained in support of offPolicy ERP');
  // }, range(erps[0].support().length));
  // // in this case, the posterior should be a delta prior on the agent liking
  // // donuts and not knowing that donut south is open
  // console.log(erps[1].support());
  // assert.ok(isDeltaERP(erps[1]), 'posterior ERP not delta ERP');

  // we expect both ERPs to be delta ERPs
  assert.ok(_.isEqual(sample(erps[0]), sample(erps[1])), 'posterior erps not equal');
  assert.ok(_.isEqual(sample(erps[0]), sample(erps[1])), 'posterior erps not equal');
  assert.ok(_.isEqual(sample(erps[0]), sample(erps[1])), 'posterior erps not equal');
  assert.ok(sample(erps[1]).utilityTable['Donut S'] === 5,
	    'posterior ERP failed to infer agent liking donuts');
  var agentBelief = sample(erps[1]).priorBelief;
  var agentBeliefSample = sample(agentBelief);
  assert.ok(agentBelief.score([], agentBeliefSample) < -0.1,
	    'posterior ERP failed to infer agents uncertainty');

  // other possible tests: look at MAP of erps[0] and erps[1], see if certain
  // things are more probable than other things in erps[1]

  console.log('passed first test');
};

var test2 = function() {
  // we see the agent go to donuts instead of noodles. this could be because they
  // like donuts, or it could be that the agent likes noodles but thinks that the
  // shop is closed: we can't tell. however, if we see the agent pass by the noodle
  // shop (and therefore learn that it is open), we will be able to infer whether
  // they like noodles, and if they do, this will imply that they initially
  // thought that the noodle shop was closed.

  // world params
  var world = getBigDonutWorld();
  var feature = world.feature;
  var perceivedTotalTime = 10;

  // possible latent states
  var noodleClosed = {'Donut N': true,
		      'Donut S': true,
		      'Veg': true,
		      'Noodle': false};
  var everythingOpen = {'Donut N': true,
			'Donut S': true,
			'Veg': true,
			'Noodle': true};

  var trueLatentState = everythingOpen;
  // write start state
  
  // possible utility functions
  
};

test1();
