/* jshint shadow: true, newcap: false, maxerr:500, sub:false, latedef:false */

console.log('--- "IRL" bandit tests ---\n');

var getPriorBelief = function(numberOfTrials, armToPrizeERPThunk){
  
  var startManifestState = {timeLeft: numberOfTrials, 
                            loc: 'start', 
                            terminateAfterAction: false};
  
  return Infer({ method: 'enumerate' },  function(){
    var latentState = armToPrizeERPThunk();
    return buildState(startManifestState, latentState);
  });
};


var testInferBandit = function(beliefOrBeliefDelay){
  console.log('started testInferBandit, beliefOrBeliefDelay? ', beliefOrBeliefDelay);
  
  // Prizes are [a,b]. If agent chooses 0, then they prefer 'a'. 
  
  // world params
  var options = {
    numberOfArms: 2,
    armToPrizeERP: {0:Delta({ v: 'a' }), 1:Delta({ v: 'b' })},
    numberOfTrials: 3
  };
  var numberOfArms = options.numberOfArms;
  var armToPrizeERP = options.armToPrizeERP;
  var numberOfTrials = options.numberOfTrials;
  var bandit = makeBandit(options);
  
  // agent params
  var baseAgentParams = noDiscountBaseAgentParams;

  var agentPrior = getPriorBelief(numberOfTrials, function(){
    return {0:Delta({ v: 'a' }), 1:Delta({ v: 'b' })};
  });
  var priorAgentPrior = Delta({ v: agentPrior });
  var prior = {
    priorPrizeToUtility: Infer({ method: 'enumerate' }, function(){
      return uniformDraw( [{a:0, b:1}, {a:1, b:0} ] );
    }),
    
    priorAgentPrior: priorAgentPrior
  };
  
  // EXAMPLE 1
  var observedStateAction = [['start',1], ['b',1], ['b',1]]; 
  var latentState = armToPrizeERP;
  var fullObservedStateAction = stateActionPairsToFullStates(observedStateAction, latentState);

  // Test on two different inference functions
  var erp1 = inferBandit( bandit, baseAgentParams, prior,
			  fullObservedStateAction, 'trajectory', 10,
			  beliefOrBeliefDelay);
  var erp2 = inferBandit( bandit, baseAgentParams, prior,
			  fullObservedStateAction,'offPolicy', 10,
			  beliefOrBeliefDelay);
  assert.ok( sample(erp1).prizeToUtility.a === 0
	     && sample(erp2).prizeToUtility.a === 0, 'testbandit infer 1');

  // EXAMPLE 2
  var observedStateAction = [['start',0], ['a',0], ['a',0]]; 
  var fullObservedStateAction = stateActionPairsToFullStates(observedStateAction, latentState);

  var erp1 = inferBandit( bandit, baseAgentParams, prior,
			  fullObservedStateAction, 'trajectory', 10,
			  beliefOrBeliefDelay); 
  var erp2 = inferBandit( bandit, baseAgentParams, prior,
			  fullObservedStateAction,'offPolicy', 10,
			  beliefOrBeliefDelay);
  assert.ok( sample(erp1).prizeToUtility.a === 1
	     && sample(erp2).prizeToUtility.a === 1, 'testbandit infer 2');

  console.log('passed easy inferBandit tests');
  
  
  // EXAMPLE 3 - INFER PRIOR AND UTILITY
  
  // Two arms: {0:a, 1:c}. Agent stays at 0. 
  // Explanation: u(a) high and prior that 1:b is low.

  // True armToPrizeERP: 0:a, 1:c
  // True priorBelief:  0:a, 1:categorical([.05,.95],[b,c])
  // True utilities: {a:10, b:20, c:1}
  
  // world params
  var options = {
    numberOfArms: 2,
    armToPrizeERP: {0:Delta({ v: 'a' }), 1:Delta({ v: 'c' })},
    numberOfTrials: 5
  };
  var numberOfArms = options.numberOfArms;
  var armToPrizeERP = options.armToPrizeERP;
  var numberOfTrials = options.numberOfTrials;
  var bandit = makeBandit(options);
  
  // agent params
  var baseAgentParams = noDiscountBaseAgentParams;

  // Prior on agent's prizeToUtility
  var truePrizeToUtility = {a:10, b:20, c:1};
  var priorPrizeToUtility = Infer({ method: 'enumerate' }, function(){
    return {a: uniformDraw([0,3,10]), b:20, c:1};
  });
  
  // Prior on agent's prior
  var trueAgentPrior = getPriorBelief(numberOfTrials, function(){
    return {
      0:Delta({ v: 'a' }),
      1: categorical([.05, .95], [Delta({ v: 'b' }), Delta({ v: 'c' })])
    };
  });
  var falseAgentPrior = getPriorBelief(numberOfTrials, function(){
    return {
      0:Delta({ v: 'a' }),
      1: categorical([.5, .5], [Delta({ v: 'b' }), Delta({ v: 'c' })])
    };
  });

  var priorAgentPrior = Infer({ method: 'enumerate' }, function(){
    return flip() ? trueAgentPrior : falseAgentPrior;
  });
  
  var prior = {priorPrizeToUtility: priorPrizeToUtility, priorAgentPrior: priorAgentPrior};

  var latentState = armToPrizeERP;
  var observedStateAction = [['start',0], ['a',0], ['a',0], ['a',0], ['a',0]]; 
  var fullObservedStateAction = stateActionPairsToFullStates(observedStateAction, latentState);


  var out1 = timeit( function(){
    return inferBandit( bandit, baseAgentParams, prior, fullObservedStateAction,
			'trajectory', 10, beliefOrBeliefDelay);
  });
  var out2 = timeit( function(){
    return inferBandit( bandit, baseAgentParams, prior, fullObservedStateAction,
			'offPolicy', 10, beliefOrBeliefDelay);
  });
  console.log('\n Time for Example 3, 2 arms and time 5: [from states, offpolicy]', out1.runtimeInMilliseconds, out2.runtimeInMilliseconds);
  
  var testERP = function(erp){
    var out = sample(erp);
    assert.ok( out.prizeToUtility.a===10, 'testbandit inferbelief example 4' );
  };
  map(testERP,[out1.value,out2.value]);
  

  // He goes to 1 every time => u(a)==0=
  var observedStateAction = [['start',1], ['c',1], ['c',1], ['c',1], ['c',1]]; 
  var fullObservedStateAction = stateActionPairsToFullStates(observedStateAction, latentState);

  var erp1 = inferBandit( bandit, baseAgentParams, prior,
			  fullObservedStateAction, 'trajectory', 10,
			  beliefOrBeliefDelay); 
  var erp2 = inferBandit( bandit, baseAgentParams, prior,
			  fullObservedStateAction,'offPolicy', 10,
			  beliefOrBeliefDelay);

  var testERP = function(erp){
    var out = sample(erp);
    assert.ok( out.prizeToUtility.a == 0, 'testbandit inferbelief example 5' );
  };
  map(testERP,[erp1,erp2]);
 
  console.log('\n-----\npassed ALL inferBandit tests');
};

var stochasticTest1 = function() {
  // prizes are deterministic, and the agent knows this (as well as what the
  // prizes actually are). the agent should just pick the arm with the highest
  // utility prize.
  
  // params for world
  var options = {
    numberOfArms: 2,
    armToPrizeERP: {0: Delta({ v: 0 }), 1: Delta({ v: 1 })},
    numberOfTrials: 3,
    numericalPrizes: true
  };
  var bandit = makeBandit(options);
  var world = bandit.world;
  var startState = bandit.startState;

  // agent parameters

  var prior = Delta({ v: startState });

  var agentParams = {alpha: 100,
		     priorBelief: prior};

  var agent = makeBanditAgent(agentParams, bandit, 'belief');

  // agent's behaviour

  var trajectory = simulate(startState, world, agent, 'actions');

  // check the agent is choosing the highest-utility arm

  assert.ok(_.isEqual(most(trajectory), [1,1]),
	    'agent is not choosing right arms in first stochastic test');

  console.log('passed first stochastic test');
};

var stochasticTest2 = function() {
  // there are two arms, one with a deterministic prize, one with a random
  // prize, and the agent knows this. No matter how long the time left is,
  // the agent should choose the highest utility arm, whether it be the sure
  // or the unsure arm.

  var uncertainArmRiskERP = Infer({ method: 'enumerate' }, function() {
    return uniformDraw([0, 10]);
  });

  var uncertainArmSafeERP = Infer({ method: 'enumerate' }, function() {
    return uniformDraw([0, 1.2]);
  });

  var shortRiskBandit = makeBandit({
    numberOfArms: 2,
    numberOfTrials: 3,
    armToPrizeERP: {0: Delta({ v: 1 }), 1: uncertainArmRiskERP},
    numericalPrizes: true
  });
  
  var shortSafeBandit = makeBandit({
    numberOfArms: 2,
    numberOfTrials: 3,
    armToPrizeERP: {0: Delta({ v: 1 }), 1: uncertainArmSafeERP},
    numericalPrizes: true
  });
  
  var longRiskBandit = makeBandit({
    numberOfArms: 2,
    numberOfTrials: 20,
    armToPrizeERP: {0: Delta({ v: 1 }), 1: uncertainArmRiskERP},
    numericalPrizes: true
  });

  var longSafeBandit = makeBandit({
    numberOfArms: 2,
    numberOfTrials: 20,
    armToPrizeERP: {0: Delta({ v: 1 }), 1: uncertainArmSafeERP},
    numericalPrizes: true
  });

  // agent parameters

  var priorShortRisk = Delta({ v: shortRiskBandit.startState });

  var priorShortSafe = Delta({ v: shortSafeBandit.startState });
  
  var priorLongRisk = Delta({ v: longRiskBandit.startState });

  var priorLongSafe = Delta({ v: longSafeBandit.startState });

  // simulating agents
  var riskyShortAgentParams = {utility: makeBanditUtility(shortRiskBandit),
			       alpha: 100,
			       priorBelief: priorShortRisk};

  var riskyShortAgent = makeBanditAgent(riskyShortAgentParams, shortRiskBandit,
					'belief');
  var riskyShortTrajectory = simulate(shortRiskBandit.startState,
						 shortRiskBandit.world,
						 riskyShortAgent, 'actions');

  assert.ok(_.isEqual(riskyShortTrajectory[0], 1),
	    'agent not risky enough with short lifespan');

  var riskyLongAgentParams = {utility: makeBanditUtility(longRiskBandit),
  			      alpha: 100,
  			      priorBelief: priorLongRisk};

  var riskyLongAgent = makeBanditAgent(riskyLongAgentParams, longRiskBandit,
				       'belief');
  var riskyLongTrajectory = simulate(longRiskBandit.startState,
						longRiskBandit.world,
  						riskyLongAgent, 'actions');

  assert.ok(_.isEqual(riskyLongTrajectory[0], 1),
  	    'agent not risky enough with long lifespan');

  var safeShortAgentParams = {utility: makeBanditUtility(shortSafeBandit),
  			      alpha: 100,
  			      priorBelief: priorShortSafe};

  var safeShortAgent = makeBanditAgent(safeShortAgentParams, shortSafeBandit,
				       'belief');
  var safeShortTrajectory = simulate(shortSafeBandit.startState,
						shortSafeBandit.world,
  						safeShortAgent, 'actions');

  assert.ok(_.isEqual(safeShortTrajectory[0], 0),
  	    'agent not safe enough with short lifespan');

  var safeLongAgentParams = {utility: makeBanditUtility(longSafeBandit),
  			     alpha: 100,
  			     priorBelief: priorLongSafe};

  var safeLongAgent = makeBanditAgent(safeLongAgentParams, longSafeBandit,
				      'belief');
  var safeLongTrajectory = simulate(longSafeBandit.startState,
					       longSafeBandit.world,
  					       safeLongAgent, 'actions');

  assert.ok(_.isEqual(safeLongTrajectory[0], 0),
  	    'agent not safe enough with long lifespan');

  console.log('passed second stochastic test');
};


var stochasticTest3 = function(){
  // have example where agent isn't sure what the probabilities for the second
  // arm are. if the lifetime is long enough, agent should explore, and stay on
  // that arm if good news, leave if not. if lifetime is short, agent should not
  // explore.

  // note that this test is nondeterministic - if the code is right, it should
  // always pass, but if the code is wrong, it might pass anyway sometimes.


  // parameters for world

  var luckyArmToPrizeERP = {0: Delta({ v: 1 }),
			    1: Categorical({ ps: [0.2, 0.8], vs: [0, 1.5] })};

  var unluckyArmToPrizeERP = {0: Delta({ v: 1 }),
			      1: Categorical({ ps: [0.8, 0.2], vs: [0, 1.5] })};

  var shortBandit = makeBandit({
    numberOfTrials: 2,
    numberOfArms: 2,
    armToPrizeERP: luckyArmToPrizeERP,
    numericalPrizes: true
  });

  var longLuckyBandit = makeBandit({
    numberOfTrials: 12,
    numberOfArms: 2,
    armToPrizeERP: luckyArmToPrizeERP,
    numericalPrizes: true
  });

  var longUnluckyBandit = makeBandit({
    numberOfTrials: 12,
    numberOfArms: 2,
    armToPrizeERP: unluckyArmToPrizeERP,
    numericalPrizes: true
  });

  // parameters for agent

  var agentArmToPrizeERPPrior = function() {
    return uniformDraw([luckyArmToPrizeERP, unluckyArmToPrizeERP]);
  };

  var shortPrior = {manifestState: shortBandit.startState.manifestState,
		    latentStateERP: Infer({ method: 'enumerate' }, agentArmToPrizeERPPrior)};

  var longPrior = {manifestState: longLuckyBandit.startState.manifestState,
		   latentStateERP: Infer({ method: 'enumerate' },  agentArmToPrizeERPPrior)};

  // simulating agent in short environment

  var agentParamsShort = {alpha: 100,
			  priorBelief: shortPrior};

  var agentShort = makeBanditAgent(agentParamsShort, shortBandit, 'belief');

  var trajectoryShort = simulate(shortBandit.startState,
					    shortBandit.world, agentShort,
					    'actions');

  assert.ok(trajectoryShort[0] === 0, 'agent explores when it shouldnt');

  // simulating agent in long environments

  var agentParamsLong = {alpha: 100,
			 priorBelief: longPrior};

  var agentLong = makeBanditAgent(agentParamsLong, longLuckyBandit, 'belief');

  var trajectoryLongLucky = simulate(longLuckyBandit.startState,
						longLuckyBandit.world,
						agentLong, 'stateAction');

  assert.ok(trajectoryLongLucky[0][1] === 1, 'agent doesnt explore enough');

  if (trajectoryLongLucky[1][0] === 1.5) {
    assert.ok(trajectoryLongLucky[1][1] === 1, 'agent should follow up luck');
  }

  var trajectoryLongUnlucky = simulate(longUnluckyBandit.startState,
						  longUnluckyBandit.world,
						  agentLong, 'stateAction');
  
  if (trajectoryLongUnlucky[1][0] === 0) {
    assert.ok(trajectoryLongUnlucky[1][1] === 0,
	      'agent should learn from bad luck');
  }
};

var deterministicTest1 = function() {
  // Agent thinks 0 is likely better. It is better and so agent stays
  var options = {
    numberOfArms: 2,
    armToPrizeERP: {
      0: Delta({ v: 10 }),
      1: Delta({ v: 5 })
    },
    numberOfTrials: 3,
    numericalPrizes: true
  };
  var bandit = makeBandit(options);
  var armToPrizeERP = options.armToPrizeERP;
  var numberOfTrials = options.numberOfTrials;
  
  var armToPrizeERPSampler = function(){
    return categorical([0.8, 0.2], [armToPrizeERP, update(armToPrizeERP,
							  {1: Delta({ v: 15 })})]);
  };

  var priorBelief = getPriorBelief(numberOfTrials, armToPrizeERPSampler);
  var agentParams = {
    alpha: 100,
    priorBelief: priorBelief
  };
  var agent = makeBanditAgent(agentParams, bandit, 'belief');

  
  var trajectory = simulate(bandit.startState, bandit.world, agent,
				       'actions');

  map( function(index){assert.ok( trajectory[index] === 0,
				  'Fail test 1 of deterministic numerical bandits');},
       [0,1] );
  console.log('Passed test 1');
};

var deterministicTest2 = function() {
  // Agent thinks 0 is likely better, but tries 1 for the VOI.
  // 1 is worse, so it goes back to 0.
  var options = {
    numberOfArms: 2,
    armToPrizeERP: {
      0: Delta({ v: 10 }),
      1: Delta({ v: 5 })
    },
    numberOfTrials: 5,
    numericalPrizes: true
  };
  var bandit = makeBandit(options);
  var armToPrizeERP = options.armToPrizeERP;
  var numberOfTrials = options.numberOfTrials;
  
  var armToPrizeERPSampler = function(){
    return categorical([0.6, 0.4], [armToPrizeERP, update(armToPrizeERP,
							  {1: Delta({ v: 15 })})]);
  };

  var priorBelief = getPriorBelief(numberOfTrials, armToPrizeERPSampler);
  var agentParams = {
    alpha: 100,
    priorBelief: priorBelief
  };
  var agent = makeBanditAgent(agentParams, bandit, 'belief');

  
  var trajectory = simulate(bandit.startState, bandit.world, agent,
				       'actions');

  assert.ok(trajectory[0] === 1, 'deterministic numerical bandit test 2 fails');

  map(function(index){assert.ok(trajectory[index] === 0,
				'deterministic numerical bandit test 2 fails');},
      [1,2]);

  console.log('Passed test 2');
};


var deterministicTest3 = function(){
  // same as deterministicTest2, but arm 1 is actually better

  var options = {
    numberOfArms: 2,
    armToPrizeERP: {
      0: Delta({ v: 10 }),
      1: Delta({ v: 15 })
    },
    numberOfTrials: 5,
    numericalPrizes: true
  };
  var bandit = makeBandit(options);
  var armToPrizeERP = options.armToPrizeERP;
  var numberOfTrials = options.numberOfTrials;
  
  var armToPrizeERPSampler = function(){
    return categorical([0.4, 0.6], [armToPrizeERP, update(armToPrizeERP,
							  {1: Delta({ v: 5 })})]);
  };

  var priorBelief = getPriorBelief(numberOfTrials, armToPrizeERPSampler);
  var agentParams = {
    alpha: 100,
    priorBelief: priorBelief
  };
  var agent = makeBanditAgent(agentParams, bandit, 'belief');

  
  var trajectory = simulate(bandit.startState, bandit.world, agent,
				       'actions');

  map(function(index){assert.ok(trajectory[index] === 1,
				'deterministic numerical bandit test 3 fails');},
      [0,1,2]);

  console.log('passed test 3');
  
};

var deterministicTest4 = function(){
  // three arms. agent should explore 1, then 2, then stick with 0.

  var options = {
    numberOfArms: 3,
    armToPrizeERP: {
      0: Delta({ v: 1 }),
      1: Delta({ v: 0 }),
      2: Delta({ v: 0 })
    },
    numberOfTrials: 5,
    numericalPrizes: true
  };
  var bandit = makeBandit(options);
  var armToPrizeERP = options.armToPrizeERP;
  var numberOfTrials = options.numberOfTrials;
  
  var armToPrizeERPSampler = function(){
    return {
      0: Delta({ v: 1 }),
      1: categorical([0.8, 0.2], [Delta({ v: 0 }), Delta({ v: 200 })]),
      2: categorical([0.8, 0.2], [Delta({ v: 0 }), Delta({ v: 150 })])
    };
  };
  
  var priorBelief = getPriorBelief(numberOfTrials, armToPrizeERPSampler);
  
  var agentParams = {
    alpha: 100,
    priorBelief: priorBelief
  };
  var agent = makeBanditAgent(agentParams, bandit, 'belief');
  // something is wrong with trajectory
  var trajectory = simulate(bandit.startState, bandit.world, agent,
				       'actions');

  assert.ok(_.isEqual([1,2,0], trajectory.slice(0,3)),
	    'deterministic numerical bandit test 4 fails');

  console.log('passed test 4');
  
};

var deterministicTest5 = function(){
  // three arms. agent should explore 1, then stick with 2.

  var options = {
    numberOfArms: 3,
    armToPrizeERP: {
      0: Delta({ v: 1 }),
      1: Delta({ v: 0 }),
      2: Delta({ v: 150 })
    },
    numberOfTrials: 5,
    numericalPrizes: true
  };
  var bandit = makeBandit(options);
  var armToPrizeERP = options.armToPrizeERP;
  var numberOfTrials = options.numberOfTrials;
  
  var armToPrizeERPSampler = function(){
    return {
      0: Delta({ v: 1 }),
      1: categorical([0.8, 0.2], [Delta({ v: 0 }), Delta({ v: 200 })]),
      2: categorical([0.8, 0.2], [Delta({ v: 0 }), Delta({ v: 150 })])
    };
  };
  
  var priorBelief = getPriorBelief(numberOfTrials, armToPrizeERPSampler);
  
  var agentParams = {
    alpha: 100,
    priorBelief: priorBelief
  };
  var agent = makeBanditAgent(agentParams, bandit, 'belief');
  // something is wrong with trajectory
  var trajectory = simulate(bandit.startState, bandit.world, agent,
				       'actions');

  assert.ok(_.isEqual([1,2,2], trajectory.slice(0,3)),
	    'deterministic numerical bandit test 5 fails');

  console.log('passed test 5');
  
};



var beliefAgentTests = function(){
  testInferBandit('belief');
};

var beliefDelayAgentTests = function(){
  testInferBandit('beliefDelay');   
};

var stochasticTests = function(){
  stochasticTest1();
  stochasticTest2();
  repeat(2, stochasticTest3);
  console.log('passed third stochastic test (one-sided test)');
};

var deterministicTests = function(){
  deterministicTest1();
  deterministicTest2();
  deterministicTest3();
  deterministicTest4();
  deterministicTest5();
};

console.log('\n\n------\n  BELIEF DELAY \n');
beliefDelayAgentTests();
console.log('\n\n------\n  BELIEF \n');
beliefAgentTests();
console.log('\n\n-----------\n ALL "IRL" BANDIT TESTS PASSED');

console.log('\n\n-----------\n BEGINNING STOCHASTIC NUMERICAL BANDIT TESTS \n-----------');
stochasticTests();
console.log('\n\n-----------\n ALL STOCHASTIC NUMERICAL BANDIT TESTS PASSED');

console.log('\n\n-----------\n BEGINNING DETERMINISTIC NUMERICAL BANDIT TESTS \n-----------');
deterministicTests();
console.log('\n\n-----------\n ALL DETERMINISTIC NUMERICAL BANDIT TESTS PASSED');
null;
