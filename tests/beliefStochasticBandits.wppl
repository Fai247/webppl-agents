// testing the behaviour of beliefAgent in a stochastic bandit pomdp.

var test1 = function() {
  // prizes are deterministic, and the agent knows this (as well as what the
  // prizes actually are). the agent should just pick the arm with the highest
  // utility prize.
  
  // params for world
  var world = makeBanditWorld(2);

  var startState = {manifestState: {loc: 'start',
				    timeLeft: 3,
				    terminateAfterAction: false},
		    latentState: {0: deltaERP(0),
				  1: deltaERP(1)}};

  // agent parameters

  var prior = deltaERP(startState);

  var agentParams = {utility: banditUtility,
		     alpha: 100,
		     priorBelief: prior};

  var agent = makeBeliefAgent(agentParams, world);

  // agent's behaviour

  var trajectory = simulateBeliefAgent(startState, world, agent, 'actions');

  // check the agent is choosing the highest-utility arm

  assert.ok(_.isEqual(most(trajectory), [1,1]),
	    'agent is not choosing right arms in first test');


  console.log('passed first test');
};

var test2 = function() {
  // there are two arms, one with a deterministic prize, one with a random
  // prize, and the agent knows this. No matter how long the time left is,
  // the agent should choose the highest utility arm, whether it be the sure
  // or the unsure arm.

  var world = makeBanditWorld(2);

  var uncertainArmRiskERP = Enumerate(function() {
    return uniformDraw([0, 10]);
  });

  var uncertainArmSafeERP = Enumerate(function() {
    return uniformDraw([0, 1.2]);
  });

  var startStateShortRisk = {manifestState: {loc: 'start',
					     timeLeft: 3,
					     terminateAfterAction: false},
			     latentState: {0: deltaERP(1),
					   1: uncertainArmRiskERP}};

  var startStateShortSafe = {manifestState: {loc: 'start',
					     timeLeft: 3,
					     terminateAfterAction: false},
			     latentState: {0: deltaERP(1),
					   1: uncertainArmSafeERP}};
  
  var startStateLongRisk = {manifestState: {loc: 'start',
					    timeLeft: 20,
					    terminateAfterAction: false},
			    latentState: {0: deltaERP(1),
					  1: uncertainArmRiskERP}};

  var startStateLongSafe = {manifestState: {loc: 'start',
					    timeLeft: 20,
					    terminateAfterAction: false},
			    latentState: {0: deltaERP(1),
					  1: uncertainArmSafeERP}};

  // agent parameters

  var priorShortRisk = deltaERP(startStateShortRisk);

  var priorShortSafe = deltaERP(startStateShortSafe);
  
  var priorLongRisk = deltaERP(startStateLongRisk);

  var priorLongSafe = deltaERP(startStateLongSafe);

  // simulating agents
  var riskyShortAgentParams = {utility: banditUtility,
			       alpha: 100,
			       priorBelief: priorShortRisk,
			       fastUpdateBelief: false};

  var riskyShortAgent = makeBeliefAgent(riskyShortAgentParams, world);
  var riskyShortTrajectory = simulateBeliefAgent(startStateShortRisk, world,
						 riskyShortAgent, 'actions');

  assert.ok(_.isEqual(riskyShortTrajectory[0], 1),
	    'agent not risky enough with short lifespan');

  var riskyLongAgentParams = {utility: banditUtility,
  			      alpha: 100,
  			      priorBelief: priorLongRisk,
			      fastUpdateBelief: false};

  var riskyLongAgent = makeBeliefAgent(riskyLongAgentParams, world);
  var riskyLongTrajectory = simulateBeliefAgent(startStateLongRisk, world,
  						 riskyLongAgent, 'actions');

  assert.ok(_.isEqual(riskyLongTrajectory[0], 1),
  	    'agent not risky enough with long lifespan');


  var safeShortAgentParams = {utility: banditUtility,
  			      alpha: 100,
  			      priorBelief: priorShortSafe,
			      fastUpdateBelief: false};

  var safeShortAgent = makeBeliefAgent(safeShortAgentParams, world);
  var safeShortTrajectory = simulateBeliefAgent(startStateShortSafe, world,
  						safeShortAgent, 'actions');

  assert.ok(_.isEqual(safeShortTrajectory[0], 0),
  	    'agent not safe enough with short lifespan');


  var safeLongAgentParams = {utility: banditUtility,
  			     alpha: 100,
  			     priorBelief: priorLongSafe,
			     fastUpdateBelief: false};

  var safeLongAgent = makeBeliefAgent(safeLongAgentParams, world);
  var safeLongTrajectory = simulateBeliefAgent(startStateLongSafe, world,
  						safeLongAgent, 'actions');

  assert.ok(_.isEqual(safeLongTrajectory[0], 0),
  	    'agent not safe enough with long lifespan');

  console.log('passed second test');
};

var test3 = function(){
  // have example where agent isn't sure what the probabilities for the second
  // arm are. if the lifetime is long enough, agent should explore, and stay on
  // that arm if good news, leave if not. if lifetime is short, agent should not
  // explore.

  // note that this test is nondeterministic - if the code is right, it should
  // always pass, but if the code is wrong, it might pass anyway sometimes.


  // parameters for world
  
  var world = makeBanditWorld(2);

  var luckyLatent = {0: deltaERP(1),
		     1: categoricalERP([0.2, 0.8], [0, 1.5])};

  var unluckyLatent = {0: deltaERP(1),
		       1: categoricalERP([0.8, 0.2], [0, 1.5])};
  
  var startStateShort = {manifestState: {loc: 'start',
					 timeLeft: 2,
					 terminateAfterAction: false},
			 latentState: luckyLatent
			};

  var startStateLongLucky = {manifestState: {loc: 'start',
					     timeLeft: 12,
					     terminateAfterAction: false},
			     latentState: luckyLatent
			    };

  var startStateLongUnlucky = {manifestState: startStateLongLucky.manifestState,
			       latentState: unluckyLatent
			      };

  // parameters for agent
  
  var agentLatentPrior = function() {
    return uniformDraw([luckyLatent, unluckyLatent]);
  };

  var shortPrior = getPriorBeliefGridworld(startStateShort.manifestState,
					   agentLatentPrior);

  var longPrior = getPriorBeliefGridworld(startStateLongLucky.manifestState,
					  agentLatentPrior);

  // simulating agent in short environment
  
  var agentParamsShort = {utility: banditUtility,
			  alpha: 100,
			  priorBelief: shortPrior,
			  fastUpdateBelief: false};

  var agentShort = makeBeliefAgent(agentParamsShort, world);

  var trajectoryShort = simulateBeliefAgent(startStateShort, world, agentShort,
					    'actions');

  assert.ok(trajectoryShort[0] === 0, 'agent explores when it shouldnt');

  // simulating agent in long environments

  var agentParamsLong = {utility: banditUtility,
			 alpha: 100,
			 priorBelief: longPrior,
			 fastUpdateBelief: false};

  var agentLong = makeBeliefAgent(agentParamsLong, world);

  var trajectoryLongLucky = simulateBeliefAgent(startStateLongLucky, world,
						agentLong, 'stateAction');

  assert.ok(trajectoryLongLucky[0][1] === 1, 'agent doesnt explore enough');

  if (trajectoryLongLucky[1][0] === 1.5) {
    assert.ok(trajectoryLongLucky[1][1] === 1, 'agent should follow up luck');
  }

  var trajectoryLongUnlucky = simulateBeliefAgent(startStateLongUnlucky, world,
						  agentLong, 'stateAction');
  
  if (trajectoryLongUnlucky[1][0] === 0) {
    assert.ok(trajectoryLongUnlucky[1][1] === 0,
	      'agent should learn from bad luck');
  }

  console.log('passed third test');
};

test1();
test2();
test3();
