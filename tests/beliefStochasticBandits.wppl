// testing the behaviour of beliefAgent in a stochastic bandit pomdp.

var test1 = function() {
  // prizes are deterministic, and the agent knows this (as well as what the
  // prizes actually are). the agent should just pick the arm with the highest
  // utility prize.
  
  // params for world
  var world = makeStochasticBanditWorld(2);

  var startState = {manifestState: {loc: 'start',
				    timeLeft: 3,
				    terminateAfterAction: false},
		    latentState: {0: deltaERP('a'),
				  1: deltaERP('b')}};

  // agent parameters

  var prior = deltaERP(startState);

  var prizeToUtility = {a: 0, b: 1};
  var utility = function(state,action){
    var loc = state.manifestState.loc;
    if (loc=='start'){
      return 0;
    } else {
      return prizeToUtility[loc];
    }
  };

  var agentParams = {utility: utility,
		     alpha: 100,
		     priorBelief: prior};

  var agent = makeBeliefAgent(agentParams, world);

  // agent's behaviour

  var trajectory = simulateBeliefAgent(startState, world, agent, 'actions');

  // check the agent is choosing the highest-utility arm

  assert.ok(_.isEqual(most(trajectory), [1,1]),
	    'agent is not choosing right arms in first test');


  console.log('passed first test');
};

var test2 = function() {
  // there are two arms, one with a deterministic prize, one with a random
  // prize, and the agent knows this. No matter how long the time left is,
  // the agent should choose the highest utility arm, whether it be the sure
  // or the unsure arm.

  var world = makeStochasticBanditWorld(2);

  var uncertainArmERP = Enumerate(function() {
    return uniformDraw(['b', 'c']);
  });

  var startStateShort = {manifestState: {loc: 'start',
					 timeLeft: 3,
					 terminateAfterAction: false},
			 latentState: {0: deltaERP('a'),
				       1: uncertainArmERP}};

  
  var startStateLong = {manifestState: {loc: 'start',
					timeLeft: 20,
					terminateAfterAction: false},
			latentState: {0: deltaERP('a'),
				      1: uncertainArmERP}};

  // agent parameters

  var priorShort = deltaERP(startStateShort);

  var priorLong = deltaERP(startStateLong);

  var prizeToUtilityRisk = {a: 1, b: 0, c: 10};
  var utilityRisk = function(state,action){
    var loc = state.manifestState.loc;
    if (loc=='start'){
      return 0;
    } else {
      return prizeToUtilityRisk[loc];
    }
  };

  var prizeToUtilitySafe = {a: 1, b: 0, c: 1.2};
  var utilitySafe = function(state,action){
    var loc = state.manifestState.loc;
    if (loc=='start'){
      return 0;
    } else {
      return prizeToUtilitySafe[loc];
    }
  };


  // simulating agents
  var riskyShortAgentParams = {utility: utilityRisk,
			       alpha: 100,
			       priorBelief: priorShort,
			       fastUpdateBelief: false};

  var riskyShortAgent = makeBeliefAgent(riskyShortAgentParams, world);
  var riskyShortTrajectory = simulateBeliefAgent(startStateShort, world,
						 riskyShortAgent, 'actions');

  assert.ok(_.isEqual(riskyShortTrajectory[0], 1),
	    'agent not risky enough with short lifespan');

  var riskyLongAgentParams = {utility: utilityRisk,
  			      alpha: 100,
  			      priorBelief: priorLong,
			      fastUpdateBelief: false};

  var riskyLongAgent = makeBeliefAgent(riskyLongAgentParams, world);
  var riskyLongTrajectory = simulateBeliefAgent(startStateLong, world,
  						 riskyLongAgent, 'actions');

  assert.ok(_.isEqual(riskyLongTrajectory[0], 1),
  	    'agent not risky enough with long lifespan');


  var safeShortAgentParams = {utility: utilitySafe,
  			      alpha: 100,
  			      priorBelief: priorShort,
			      fastUpdateBelief: false};

  var safeShortAgent = makeBeliefAgent(safeShortAgentParams, world);
  var safeShortTrajectory = simulateBeliefAgent(startStateShort, world,
  						safeShortAgent, 'actions');

  assert.ok(_.isEqual(safeShortTrajectory[0], 0),
  	    'agent not safe enough with short lifespan');


  var safeLongAgentParams = {utility: utilitySafe,
  			     alpha: 100,
  			     priorBelief: priorLong,
			     fastUpdateBelief: false};

  var safeLongAgent = makeBeliefAgent(safeLongAgentParams, world);
  var safeLongTrajectory = simulateBeliefAgent(startStateLong, world,
  						safeLongAgent, 'actions');

  assert.ok(_.isEqual(safeLongTrajectory[0], 0),
  	    'agent not safe enough with long lifespan');

  console.log('passed second test');
};

var test3 = function(){
  // have example where agent isn't sure what the probabilities for the second
  // arm are. if the lifetime is long enough, agent should explore, and stay on
  // that arm if good news, leave if not. if lifetime is short, agent should not
  // explore.

  // note that this test is nondeterministic - if the code is right, it should
  // always pass, but if the code is wrong, it might pass anyway sometimes.


  // parameters for world
  
  var world = makeStochasticBanditWorld(2);

  var luckyLatent = {0: deltaERP('a'),
		     1: categoricalERP([0.2, 0.8], ['b', 'c'])};

  var unluckyLatent = {0: deltaERP('a'),
		       1: categoricalERP([0.8, 0.2], ['b', 'c'])};
  
  var startStateShort = {manifestState: {loc: 'start',
					 timeLeft: 2,
					 terminateAfterAction: false},
			 latentState: luckyLatent
			};

  var startStateLongLucky = {manifestState: {loc: 'start',
					     timeLeft: 12,
					     terminateAfterAction: false},
			     latentState: luckyLatent
			    };

  var startStateLongUnlucky = {manifestState: startStateLongLucky.manifestState,
			       latentState: unluckyLatent
			      };

  // parameters for agent
  
  var agentLatentPrior = function() {
    return uniformDraw([luckyLatent, unluckyLatent]);
  };

  var shortPrior = getPriorBeliefGridworld(startStateShort.manifestState,
					   agentLatentPrior);

  var longPrior = getPriorBeliefGridworld(startStateLongLucky.manifestState,
					  agentLatentPrior);

  var prizeToUtility = {a: 1, b: 0, c: 1.5};
  var utility = function(state,action){
    var loc = state.manifestState.loc;
    if (loc=='start'){
      return 0;
    } else {
      return prizeToUtility[loc];
    }
  };

  // simulating agent in short environment
  
  var agentParamsShort = {utility: utility,
			  alpha: 100,
			  priorBelief: shortPrior,
			  fastUpdateBelief: false};

  var agentShort = makeBeliefAgent(agentParamsShort, world);

  var trajectoryShort = simulateBeliefAgent(startStateShort, world, agentShort,
					    'actions');

  assert.ok(trajectoryShort[0] === 0, 'agent explores when it shouldnt');

  // simulating agent in long environments

  var agentParamsLong = {utility: utility,
			 alpha: 100,
			 priorBelief: longPrior,
			 fastUpdateBelief: false};

  var agentLong = makeBeliefAgent(agentParamsLong, world);

  var trajectoryLongLucky = simulateBeliefAgent(startStateLongLucky, world,
						agentLong, 'stateAction');

  assert.ok(trajectoryLongLucky[0][1] === 1, 'agent doesnt explore enough');

  if (trajectoryLongLucky[1][0] === 'c') {
    assert.ok(trajectoryLongLucky[1][1] === 1, 'agent should follow up luck');
  }

  var trajectoryLongUnlucky = simulateBeliefAgent(startStateLongUnlucky, world,
						  agentLong, 'stateAction');
  
  if (trajectoryLongUnlucky[1][0] === 'b') {
    assert.ok(trajectoryLongUnlucky[1][1] === 0,
	      'agent should learn from bad luck');
  }

  console.log('passed third test');
};

test1();
test2();
test3();
