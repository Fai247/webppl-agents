// see an agent go to donuts instead of noodles. is this because they like donuts,
// or do they like noodles but think that the noodle shop is closed?
// what if we see the agent pass by the noodle shop?

var gridworldMDP = makeDonutWorld2({big: true});
var gridworldPOMDP = makeGridworldPOMDP(gridworldMDP);
var feature = gridworldMDP.feature;
var transition = gridworldPOMDP.transition;
var observe = gridworldPOMDP.observe;

var donutUtilityTable = {'Donut N': 5,
			 'Donut S': 5,
			 'Veg': 1,
			 'Noodle': 1,
			 timeCost: -0.1};
 
var noodleUtilityTable = {'Donut N': 2,
			  'Donut S': 2,
			  Veg: 1,
			  Noodle: 5,
			  timeCost: -0.1};

var tableToUtilityFunction = function(table) {
  return function(state, action) {
    var stateFeatureName = feature(state.manifestState).name;
    if (stateFeatureName) {
      return table[stateFeatureName];
    } else {
      return table.timeCost;
    }
  };
};

var uninformedPrior = Enumerate(function(){
  if (flip(0.8)) {
    return {'Donut N': true,
	    'Donut S': true,
	    'Veg': true,
	    'Noodle': false};
  } else {
    return {'Donut N': true,
	    'Donut S': true,
	    'Veg': true,
	    'Noodle': true};
  }
});

var informedPrior = deltaERP({'Donut N': true,
			      'Donut S': true,
			      'Veg': true,
			      'Noodle': true});

var startState = {manifestState: {loc: [3,1],
				  dead: false,
				  timeLeft: 6,
				  digest: 1},
		  latentState: {'Donut N': true,
				'Donut S': true,
				'Veg': true,
				'Noodle': true}};

var agent = makeBeliefAgent({utility: tableToUtilityFunction(noodleUtilityTable),
			     alpha: 100,
			     priorBelief: uninformedPrior}, gridworldPOMDP);

var observedTrajectory = simulateBeliefAgent(startState, gridworldPOMDP, agent, 6,
					     'states');

// // in a second trajectory, we let the agent know that noodle is open, and see where
// // it goes
// var startState2 = {manifestState: {loc: [5,4],
// 				   dead: false,
// 				   timeLeft: 10,
// 				   digest: 1},
// 		   latentState: {'Donut N': true,
// 				 'Donut S': true,
// 				 'Veg': true,
// 				 'Noodle': true}};
// var observedTrajectory2 = simulateBeliefAgent(startState2, gridworldPOMDP, agent, 10,
// 					      'states');

// var observedTrajectories = [observedTrajectory, observedTrajectory2];
var observedTrajectories = [observedTrajectory];

var utilityTablePrior = Enumerate(function(){
  if (flip(0.5)) {
    return donutUtilityTable;
  } else {
    return noodleUtilityTable;
  }
});

var beliefPrior = Enumerate(function(){
  if (flip(0.5)) {
    return uninformedPrior;
  } else {
    return informedPrior;
  }
});

var numTrajectories = observedTrajectories.length;

var sampleAlongTrajectory = function(state, currentBelief, actionsSampled,
				     trajectory, agentActionBelief) {
  assert.ok(isERP(agentActionBelief(state.manifestState, currentBelief,
				    observe(state))),
	    'agentActionBelief not correct in sampleAlongTrajectory');
  
  if (actionsSampled === trajectory.length - 1) {
    return [];
  } else {
    var actionBeliefERP = agentActionBelief(state.manifestState, currentBelief,
					    observe(state));
    var nextStateERP = Enumerate(function(){
      return transition(state, sample(actionBeliefERP).action);
    });
    var newBelief = sample(actionBeliefERP).belief;

    var trajectoryNextState = trajectory[actionsSampled + 1];
    
    factor(nextStateERP.score([], trajectoryNextState));
    
    return sampleAlongTrajectory(trajectoryNextState, newBelief, actionsSampled + 1,
				 trajectory, agentActionBelief);
  }
};

var agentPosterior = Enumerate(function(){
  var utilityTable = sample(utilityTablePrior);
  var utility = tableToUtilityFunction(utilityTable);
  var agentPrior = sample(beliefPrior);
  var agent = makeBeliefAgent({utility: utility,
			       alpha: 100,
			       priorBelief: agentPrior},
			      gridworldPOMDP);
  var agentActionBelief = agent.agent;

  var factorTrajectory = function(trajectory) {
    return sampleAlongTrajectory(trajectory[0], agentPrior, 0, trajectory,
				 agentActionBelief);
  };

  map(factorTrajectory, observedTrajectories);

  return {utilityTable: utilityTable,
	  prior: agentPrior};
});

printERP(agentPosterior);
