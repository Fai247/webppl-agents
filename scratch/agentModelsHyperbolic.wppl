var nameToPath = {
  naive: [[3,1], [3,2], [3,3], [3,4], [3,5], [2,5]],
  
  sophisticated: [[ 3, 1 ],[ 3, 2 ],[ 3, 3 ],[ 4, 3 ], [ 5, 3 ],
                  [ 5, 4 ], [ 5, 5 ], [ 5, 6 ], [4, 6 ], [ 4, 7 ] ],
  
  donutSouth: [[3,1], [2,1], [1,1], [0,1], [0,0]],
  
  vegDirect: [[3,1], [3,2], [3,3], [3,4], [3,5], [3,6], [4,6], [4,7]]
};

var pathToName = function(path){
  var path = path.slice(0,path.length-1);
  var table = _.invert(nameToPath);
  return 'path: ' + table[path];
};




var makeAgent = function (params, world) {
  var stateToActions = world.stateToActions;
  var transition = world.transition;
  var utility = params.utility;

  var discountFunction = function(delay){
    return 1/(1 + params.discount*delay);
  };

  var isNaive = params.sophisticatedOrNaive=='naive';
    
  var act = dp.cache( 
    function(state, delay){
      return Enumerate(function(){
        var action = uniformDraw(stateToActions(state));
        var eu = expectedUtility(state, action, delay);    
        factor(params.alpha * eu);
        return action;
      });      
    });
  
  var expectedUtility = dp.cache(
    function(state, action, delay){
      var u = discountFunction(delay) * utility(state, action);
      if (state.terminateAfterAction){
        return u; 
      } else {                     
        return u + expectation( Enumerate(function(){
          var nextState = transition(state, action); 
          var perceivedDelay = isNaive ? delay + 1 : 0;
          var nextAction = sample(act(nextState, perceivedDelay));
          return expectedUtility(nextState, nextAction, delay+1);  
        }));
      }                      
    });
  
  return {
    params : params,
    expectedUtility : expectedUtility,
    act: act
  };
};

var simulate = function(startState, world, agent) {
  var act = agent.act;
  var expectedUtility = agent.expectedUtility;
  var transition = world.transition;

  var sampleSequence = function (state) {
    var delay = 0;
    var action = sample(act(state, delay));
    var nextState = transition(state, action); 
    var out = [state,action];
    return state.terminateAfterAction ?
      [out] : [out].concat(sampleSequence(nextState));
  };
  return sampleSequence(startState);
};


var makeRestaurantUtilityFunction = function (world, rewards) { 
  return function(state, action) {
    var getFeature = world.feature;
    var feature = getFeature(state);

    if (feature.name) { return rewards[feature.name][state.timeAtRestaurant]; }
    return -0.01;
  };
};


// Construct MDP, i.e. world
var startState = { 
  loc : [3,1],
  terminateAfterAction : false,
  timeLeft : 11
};

var world = makeDonutWorld2({ big : true, maxTimeAtRestaurant : 2});


// Construct hyperbolic discounting agent

var restaurantUtility = makeRestaurantUtilityFunction(world, {
    'Donut N' : [10, -10],
    'Donut S' : [10, -10],
    'Veg'   : [-10, 20],
    'Noodle': [0, 0]
});

var donutU = [20,0];
var vegU = [5,40];
var restaurantUtility = makeRestaurantUtilityFunction(world, {
  'Donut N' : donutU,
  'Donut S' : donutU,
  'Veg'   : vegU,
  'Noodle': [0, 0]
});


var baseAgentParams = {
  utility : restaurantUtility,
  alpha : 500, 
  discount : 1
};

var getLocations = function(stateActions){
  return _.map( _.map(stateActions,0), 'loc');
};

var getPath = function(sophisticatedOrNaive){
  var agent = makeAgent(update(baseAgentParams, 
                               {sophisticatedOrNaive: sophisticatedOrNaive}), world);

  var out = timeit( function(){return simulate(startState, world, agent)});
  var locs = _.map( _.map(out.value,0), 'loc');
  console.log('Trajectory: ' + sophisticatedOrNaive, locs,
              '\n\n runtime', out.runtimeInMilliseconds);
  return locs;
};

var priorAgentParams = function(){
  return {
    discount: uniformDraw([0,1]),
    utility: restaurantUtility,
    sophisticatedOrNaive: uniformDraw(['sophisticated', 'naive'])
  };
};

var infer = function(observedPath){
  return Enumerate( function(){
    var agentParams = priorAgentParams();
    var agent = makeAgent( update(baseAgentParams, agentParams), world);
    var path = getLocations( simulate(startState, world, agent) );
    condition( _.isEqual(observedPath, path) );
    return agentParams;
  });
};

var erp = infer(nameToPath.naive);

//getPath('sophisticated');
//getPath('naive');


ash();











// TODO merge with simulate, use a more descriptive name. It seems that
// ideally we'd use the MAP path, and the 
var MAPActionPath = function(state, world, agent, actualTotalTime, statesOrActions) { 
  var perceivedTotalTime = state.timeLeft;
  assert.ok( perceivedTotalTime  > 1, 'perceivedTime<=1. If=1 then should have state.terminateAfterAction, but then simulate wont work' + JSON.stringify(state));

  var agentAction = agent.agent;
  var expectedUtility = agent.expectedUtility;
  var transition = world.transition;

  var sampleSequence = function (state, actualTimeLeft) {
      var action = agentAction(state, actualTotalTime-actualTimeLeft).MAP().val;
      var nextState = transition(state, action); 
      var out = {states:state, actions:action, both:[state,action]}[statesOrActions];
    if (actualTimeLeft==0 || state.terminateAfterAction){
      return [out];
    } else {
      return [ out ].concat( sampleSequence(nextState, actualTimeLeft-1));
    }
  };
  return sampleSequence(state, actualTotalTime);
};

var getExpectedUtilities = function(trajectory, agent, actions) { 
  var expectedUtility = agent.expectedUtility;

  var v = mapIndexed(function(i, state) {
    return [state.loc, map(function (a) { return  expectedUtility(state, a, i); }, actions)];
  }, trajectory)
  return v;
};

// TODO more descriptive name
var mdpSim = function(start, world, agent, actualTotalTime) { 
  var trajectory = simulateHyperbolic(start, world, agent, actualTotalTime, 'states');

  var trajectoryPlans = map(function (state) {
    var currentPlan = MAPActionPath(state, world, agent, state.timeLeft, 'states');
    return getExpectedUtilities(currentPlan, agent, world.actions);
  }, trajectory);

  GridWorld.draw(world, {trajectory : trajectory, paths : trajectoryPlans });
}
null
