

var nameToPath = {
  naive: [[3,1], [3,2], [3,3], [3,4], [3,5], [2,5]],
  
  sophisticated: [[ 3, 1 ],[ 3, 2 ],[ 3, 3 ],[ 4, 3 ], [ 5, 3 ],
                  [ 5, 4 ], [ 5, 5 ], [ 5, 6 ], [4, 6 ], [ 4, 7 ] ],
  
  donutSouth: [[3,1], [2,1], [1,1], [0,1], [0,0]],
  
  vegDirect: [[3,1], [3,2], [3,3], [3,4], [3,5], [3,6], [4,6], [4,7]]
};

var pathToName = function(path){
  var path = path.slice(0,path.length-1);
  var table = _.invert(nameToPath);
  return 'path: ' + table[path];
};


var getLocations = function(stateActions){
  return _.map( _.map(stateActions,0), 'loc');
};

var getPath = function(sophisticatedOrNaive){
  var agent = makeAgent(update(baseAgentParams, 
                               {sophisticatedOrNaive: sophisticatedOrNaive}), world);

  var out = timeit( function(){return simulate(startState, world, agent)});
  var locs = _.map( _.map(out.value,0), 'loc');
  console.log('Trajectory: ' + sophisticatedOrNaive, locs,
              '\n\n runtime', out.runtimeInMilliseconds);
  return locs;
};





var makeAgent = function (params, world) {
  var stateToActions = world.stateToActions;
  var transition = world.transition;
  var utility = params.utility;

  var discountFunction = function(delay){
    return 1/(1 + params.discount*delay);
  };

  var isNaive = params.sophisticatedOrNaive=='naive';
    
  var act = dp.cache( 
    function(state, delay){
      return Enumerate(function(){
        var action = uniformDraw(stateToActions(state));
        var eu = expectedUtility(state, action, delay);    
        factor(params.alpha * eu);
        return action;
      });      
    });
  
  var expectedUtility = dp.cache(
    function(state, action, delay){
      var u = discountFunction(delay) * utility(state, action);
      if (state.terminateAfterAction){
        return u; 
      } else {                     
        return u + expectation( Enumerate(function(){
          var nextState = transition(state, action); 
          var perceivedDelay = isNaive ? delay + 1 : 0;
          var nextAction = sample(act(nextState, perceivedDelay));
          return expectedUtility(nextState, nextAction, delay+1);  
        }));
      }                      
    });
  
  return {
    params : params,
    expectedUtility : expectedUtility,
    act: act
  };
};

var simulate = function(startState, world, agent) {
  var act = agent.act;
  var expectedUtility = agent.expectedUtility;
  var transition = world.transition;

  var sampleSequence = function (state) {
    var delay = 0;
    var action = sample(act(state, delay));
    var nextState = transition(state, action); 
    var out = [state,action];
    return state.terminateAfterAction ?
      [out] : [out].concat(sampleSequence(nextState));
  };
  return sampleSequence(startState);
};


var makeRestaurantUtilityFunction = function (world, rewards) { 
  return function(state, action) {
    var getFeature = world.feature;
    var feature = getFeature(state);

    if (feature.name) { return rewards[feature.name][state.timeAtRestaurant]; }
    return -0.01;
  };
};


// Construct MDP, i.e. world
var startState = { 
  loc : [3,1],
  terminateAfterAction : false,
  timeLeft : 11
};
var world = makeDonutWorld2({ big : true, maxTimeAtRestaurant : 2});


// Construct hyperbolic discounting agent

var getRestaurantParamsHyperbolic = function(world, donut, veg, discount, sophisticatedOrNaive){
  var utilityTable = {
    'Donut N' : donut,
    'Donut S' : donut,
    'Veg'   : veg,
    'Noodle': [0, 0]
  };
  
  return {
    alpha: 500,
    discount: discount,
    sophisticatedOrNaive: sophisticatedOrNaive,
    utility: makeRestaurantUtilityFunction(world,utilityTable)
  };
}; 

var priorUtilityTable = function(){
  var donut = [uniformDraw([5,10,15,20]), 0];
  var veg = [0, uniformDraw([5,10,15,20])];
  return {'Donut N' : donut,
          'Donut S' : donut,
          'Veg'   : veg,
          'Noodle': [0, 0]
         };
};


var priorDiscounting = function(){
  //var discount = categorical([.5, .25, .25], [0, 1, 5]);
  var discount = uniformDraw([0,1]);
  var sophisticatedOrNaive = uniformDraw(['sophisticated', 'naive']);
  

  return {discount: discount, sophisticatedOrNaive: sophisticatedOrNaive};
};

var getHyperbolicParams = function(utilityTable, discounting, alpha, world){
  return {
    alpha: alpha,
    discount: discounting.discount,
    sophisticatedOrNaive : discounting.sophisticatedOrNaive,
    utility: makeRestaurantUtilityFunction(world,utilityTable)
  };
};

var infer = function(observedPath){
  return Enumerate( function(){
    var utilityTable = priorUtilityTable();
    var discounting = priorDiscounting();
    var agent = makeAgent( getHyperbolicParams(utilityTable, discounting,500, world), world);
    var fullPath = getLocations( simulate(startState, world, agent) );
    var path = fullPath.slice(0,fullPath.length-1);
    condition( _.isEqual(observedPath, path) );
    return {utility:utilityTable, discounting: discounting};
  });
};

var erp = infer(nameToPath.naive);
printERP(erp);
ash();

console.log('\nSOPH');
var erp = infer(nameToPath.sophisticated);
printERP(erp);

ash();
getPath('sophisticated');
//getPath('naive');


ash();











// TODO merge with simulate, use a more descriptive name. It seems that
// ideally we'd use the MAP path, and the 
var MAPActionPath = function(state, world, agent, actualTotalTime, statesOrActions) { 
  var perceivedTotalTime = state.timeLeft;
  assert.ok( perceivedTotalTime  > 1, 'perceivedTime<=1. If=1 then should have state.terminateAfterAction, but then simulate wont work' + JSON.stringify(state));

  var agentAction = agent.agent;
  var expectedUtility = agent.expectedUtility;
  var transition = world.transition;

  var sampleSequence = function (state, actualTimeLeft) {
      var action = agentAction(state, actualTotalTime-actualTimeLeft).MAP().val;
      var nextState = transition(state, action); 
      var out = {states:state, actions:action, both:[state,action]}[statesOrActions];
    if (actualTimeLeft==0 || state.terminateAfterAction){
      return [out];
    } else {
      return [ out ].concat( sampleSequence(nextState, actualTimeLeft-1));
    }
  };
  return sampleSequence(state, actualTotalTime);
};

var getExpectedUtilities = function(trajectory, agent, actions) { 
  var expectedUtility = agent.expectedUtility;

  var v = mapIndexed(function(i, state) {
    return [state.loc, map(function (a) { return  expectedUtility(state, a, i); }, actions)];
  }, trajectory)
  return v;
};

// TODO more descriptive name
var mdpSim = function(start, world, agent, actualTotalTime) { 
  var trajectory = simulateHyperbolic(start, world, agent, actualTotalTime, 'states');

  var trajectoryPlans = map(function (state) {
    var currentPlan = MAPActionPath(state, world, agent, state.timeLeft, 'states');
    return getExpectedUtilities(currentPlan, agent, world.actions);
  }, trajectory);

  GridWorld.draw(world, {trajectory : trajectory, paths : trajectoryPlans });
}
null
