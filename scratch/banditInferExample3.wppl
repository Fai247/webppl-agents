var numArms = 2;
var bandit = makeDeterministicBandit(numArms);
var trueLatent = {start: 0, 0: 10, 1: 1};

var agentBelief = Enumerate(function(){
  if (flip(0.8)) {
    return {start: 0, 0: 10, 1: 20};
  } else {
    return trueLatent;
  }
});

var informedBelief = Enumerate(function(){
  return trueLatent;
});

var observedTrajectory = runBandit(numArms, trueLatent, agentBelief, 2);

console.log('observed trajectory', map( function (state) {
  return state.manifestState.loc;
}, observedTrajectory) );

// infer what the agent knows and whether they like rewards.
// doesn't work, because they could either think that 1 has high rewards and
// like rewards, or they could think that 1 has low rewards but hate rewards.
// without seeing what they do once they know the rewards for 1, no way to tell.
var inferredAgent = Enumerate(function(){
  var priorBelief = uniformDraw([agentBelief, informedBelief]);
  var utilitySign = uniformDraw([-1, 1]);

  var agentUtility = function(state, action) {
    return utilitySign * state.latentState[state.manifestState.loc];
  };
  
  var alpha = 100;
  
  var agent = makeBeliefAgent({utility: agentUtility,
			       alpha: alpha,
			       priorBelief: priorBelief},
			      bandit);
  var newTrajectory = simulateBeliefAgent(observedTrajectory[0], bandit, agent,
					  observedTrajectory.length, 'states');
  condition(_.isEqual(newTrajectory, observedTrajectory));

  return {utilitySign: utilitySign, priorBelief: priorBelief};
});


printERP(inferredAgent);

