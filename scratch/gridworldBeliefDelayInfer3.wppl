// note - this takes almost a minute to run

// we see the agent start out on the bottom-left corner of a loop and go around
// the long way to a noodle place. We can confer that they must be myopic rather
// than normal or hyperbolic (otherwise it would go the short way or go to one
// of the restaurants on the way, respectively), that they must prefer noodle to
// veg to donut (otherwise it would stop at one of the restaurants on the way),
// and that they must not think it very likely that veg is closed (as otherwise
// they would stop at donut).

// making a gridworld where this works

var makeSmallLoopWorld = function(options) { 
  var _ = ' '; 
  var D = {name: 'Donut'};
  var V = {name: 'Veg'};
  var N = {name: 'Noodle'};

  var myOptions = options || {};

  var features =
	[['#', '#',  V , '#', '#'],
	 ['#',  _ ,  _ ,  _ , '#'],
	 [ D ,  _ , '#',  _ ,  N ],
	 ['#',  _ , '#',  _ , '#'],
	 ['#',  _ ,  _ ,  _ , '#']];
  
  return makeGridWorld(features, myOptions);
};

var gridworldMDP = makeSmallLoopWorld({noReverse: true});
var gridworldPOMDP = makeGridworldPOMDP(gridworldMDP);
var feature = gridworldMDP.feature;
var transition = gridworldPOMDP.transition;
var observe = gridworldPOMDP.observe;

// here, we define a table giving the agent's true utility function

var trueUtilityTable = { Donut: 1,
			 Veg: 2,
			 Noodle: 3,
			 timeCost: -0.1 };

var tableToUtilityFunction = function(table) {
  return function(state, action) {
    if (state.manifestState.dead) {
      return 0;
    }
    var stateFeatureName = feature(state.manifestState).name;
    if (stateFeatureName) {
      return table[stateFeatureName];
    } else {
      return table.timeCost;
    }
  };
};

// we start the agent off near Donut South
var startState = {manifestState: {loc: [1,0],
				  dead: false,
				  timeLeft: 10,
				  digest: 0},
		  latentState: {Donut: true,
				Veg: true,
				Noodle: true}};

// we define some beliefs that the agent could have
var informedBelief = deltaERP(startState.latentState);
var vegClosedBelief = Enumerate(function(){
  return categorical([0.1, 0.9], [startState.latentState, {Donut: true,
							   Veg: false,
							   Noodle: true}]);
});

// making the agent
var params = {
  alpha: 100,
  noDelays: false,
  discount: 0,
  sophisticatedOrNaive: 'naive',
  myopia: {on: true, bound: 4}, 
  priorBelief: informedBelief,
  boundVOI: {on: false, bound: 0},
  utility: tableToUtilityFunction(trueUtilityTable)
};
var agent = makeBeliefDelayAgent(params, gridworldPOMDP);

// generating the agent's trajectory
var observedTrajectory = simulateBeliefDelayAgent(startState, gridworldPOMDP,
						  agent, 'stateAction');
// (visualise trajectory in codebox)

// helper function for inference
var factorAlongTrajectory = function(index, trajectory, agent, belief){
  if (index >= trajectory.length) {
    return [];
  } else {

    var agentAct = agent.act;
    var agentUpdateBelief = agent.updateBelief;
    
    var state = trajectory[index][0];
    var observedAction = trajectory[index][1];

    var observation = observe(state);
    var nextBelief = agentUpdateBelief(state.manifestState, belief, observation, 0);
    var nextActionERP = agentAct(state.manifestState, nextBelief, 0);

    factor(nextActionERP.score([], observedAction));
    
    return factorAlongTrajectory(index + 1, trajectory, agent, nextBelief);
  }
};

// the inference itself
var agentPosterior = function() {
  return printERP(Enumerate(function(){

    var alpha = 100;
    
    var utilityTable = {
      Donut: uniformDraw([1,2,3]),
      // Donut: 1,
      Veg: uniformDraw([1,2,3]),
      Noodle: uniformDraw([1,2,3]),
      timeCost: -0.1
    };
    var utility = tableToUtilityFunction(utilityTable);
    
    var agentPrior = uniformDraw([informedBelief, vegClosedBelief]);

    var agentType = uniformDraw(_.range(3));

    var isMyopic = (agentType === 0);
    var myopiaBound = isMyopic ? 4 : 0;

    var hasBoundVOI = false;
    var voiBound = 0;

    var discount = (agentType === 1) ? 2 : 0;
    var noDelays = (discount === 2);

    var sophisticatedOrNaive = 'naive';

    var params = {
      alpha: alpha,
      utility: utility,
      noDelays: noDelays,
      discount: discount,
      sophisticatedOrNaive: sophisticatedOrNaive,
      myopia: {on: isMyopic, bound: myopiaBound},
      priorBelief: agentPrior,
      boundVOI: {on: hasBoundVOI, bound: voiBound}
    };
    
    var agent = makeBeliefDelayAgent(params, gridworldPOMDP);

    factorAlongTrajectory(0, observedTrajectory, agent, agentPrior);

    return {utilityTable: utilityTable,
	    agentPrior: agentPrior,
	    isMyopic: isMyopic,
	    discount: discount};
  }));
};

timeit(agentPosterior);
