// here, we observe the agent in a gridworld, going past a nearby donut shop
// and towards a further away donut shop. we can conclude that the agent likes
// donuts, but thinks that the nearby donut shop is closed.

// assume that the agent is not a discounter, does not have bounded VOI, etc



// Make big gridworld
var getWorld = function(){
  var gridworldMDP = makeDonutWorld2({big: true});
  var gridworldPOMDP = makeGridworldPOMDP(gridworldMDP);
  var feature = gridworldMDP.feature;

  var transition = gridworldPOMDP.transition;
  var worldObserve = gridworldPOMDP.observe;
  var observe = worldObserve // TODO CHANGE BACK getFullObserve(worldObserve);

  return {gridworldPOMDP: gridworldPOMDP, observe:observe, transition:transition, feature:feature};
};

var tableToUtilityFunction = function(table, feature ) {
  
  return function(state, action) {
    if (state.manifestState.terminateAfterAction) {
      return 0;
    }
    var stateFeatureName = feature(state.manifestState).name;
    if (stateFeatureName) {  
      return table[stateFeatureName];
    } else {
      return table.timeCost;
    }
  };
};


var getStartState = function(startingLocation, perceivedTotalTime, latentState){
  return buildState({loc: startingLocation,
		     terminateAfterAction: false,
		     timeLeft: perceivedTotalTime,
		     timeAtRestaurant: 0},
	            latentState);
};


var getPriorBelief = function(totalTime, startingLocation, latentStateSampler){
  return _getPriorBelief(totalTime, startingLocation, latentStateSampler, true);
};


var inferIRLBandit = function(worldAndStart, baseAgentParams, prior, observedStateAction, trajectoryOrOffPolicy, 
                              numRejectionSamples, beliefOrBeliefDelay){
  var world = worldAndStart.world;
  var startState = worldAndStart.startState;
  var worldObserve = world.observe;
  var observe = getFullObserve(worldObserve);

  var simulate = getSimulateFunction(beliefOrBeliefDelay);

  var priorPrizeToUtility = prior.priorPrizeToUtility;
  var priorAgentPrior = prior.priorAgentPrior;

  assert.ok(isPOMDPWorld(world) && isPOMDPState(startState) && isERP(priorPrizeToUtility) && isERP(priorAgentPrior), 'inferirlbandit args');
  assert.ok(trajectoryOrOffPolicy == 'trajectory' || trajectoryOrOffPolicy=='offPolicy', 'trajectoryOrOffPolicy bad');
  assert.ok( isPOMDPState(observedStateAction[0][0]), 'fullstate in trajectory for inferirlbandit');

  
  return Enumerate(function(){
    // priors and makeAgent are specific to IRL Bandits
    var prizeToUtility = sample(priorPrizeToUtility);
    var priorBelief = sample(priorAgentPrior);
    
    var agent = makeIRLBanditAgent(prizeToUtility, update(baseAgentParams, {priorBelief:priorBelief}), worldAndStart, beliefOrBeliefDelay);
    var agentAct = agent.act;
    var agentUpdateBelief = agent.updateBelief;

    // Factor on whole sampled trajectory (SLOW IF NOT DETERMINISTIC AND NUM SAMPLES HIGH)
    var factorOnTrajectory = function(){
      var trajectoryERP = Rejection( function(){
        return simulate(startState, world, agent, 'states')}, numRejectionSamples);
      factor(trajectoryERP.score([], map(first, observedStateAction)));
    };

    // Move agent through observed sequence 
    var factorSequenceOffPolicy = function(currentBelief, previousAction, timeIndex){
      if (timeIndex < observedStateAction.length) { 

        // Go to next world state and sample observation from that state
        var state = observedStateAction[timeIndex][0];
        var observation = observe(state);

        // Update agent's internal state and get action ERP
        var delay = 0;     
        var nextBelief = beliefOrBeliefDelay == 'belief' ?
            agentUpdateBelief(currentBelief, observation, previousAction) :
            agentUpdateBelief(currentBelief, observation, previousAction, delay);


        var nextActionERP = beliefOrBeliefDelay == 'belief' ? 
            agentAct(nextBelief) : agentAct(nextBelief, delay); 

        var observedAction = observedStateAction[timeIndex][1];
        factor(nextActionERP.score([], observedAction));

        // condition on next world state, passing through updated internal state
        factorSequenceOffPolicy(nextBelief, observedAction, timeIndex + 1);
      }
    };

    var doInfer = (trajectoryOrOffPolicy=='trajectory') ? factorOnTrajectory() : 
        factorSequenceOffPolicy(priorBelief,'noAction', 0);
    
    return {prizeToUtility: prizeToUtility, priorBelief:priorBelief};
  });
};




// Global makeAgent and simulate functions
var beliefOrBeliefDelay = 'beliefDelay';
var makeAgent  = getMakeAgentFunction(beliefOrBeliefDelay);
var simulate = getSimulateFunction(beliefOrBeliefDelay);



// Possible latent states
var allOpenLatentState = {
  'Donut N': true,
  'Donut S': true,
  'Veg': true,
  'Noodle': true
};

var onlyDonutSouthClosedLatentState = {
  'Donut N': true,
  'Donut S': false,
  'Veg': true,
  'Noodle': true
};

// Possible utility functions for agent

var donutUtilityTable = {'Donut N': 5,
			 'Donut S': 5,
			 'Veg': 1,
			 'Noodle': 1,
			 'timeCost': -0.1};
 
var vegUtilityTable = {'Donut N': 1,
		       'Donut S': 1,
		       'Veg': 3,
		       'Noodle': 1,
		       'timeCost': -0.1};


// Make world
var world = getWorld();
var gridworldPOMDP = world.gridworldPOMDP;
var observe = world.observe;
var transition = world.transition;
var feature = world.feature;


// Scenario parameters
var perceivedTotalTime = 10;
var startingLocation = [2,1];
var trueLatentState = allOpenLatentState;
var startState = getStartState(startingLocation, perceivedTotalTime, trueLatentState);


// agent's true prior and alternative hypothesis about agent's prior

var uninformedLatentStateSampler = function(){
  return flip(.8) ? onlyDonutSouthClosedLatentState : trueLatentState;
};


var truePriorBelief = getPriorBelief(perceivedTotalTime, startingLocation, 
                                      uninformedLatentStateSampler);
var alternativePriorBelief = getPriorBelief(perceivedTotalTime, startingLocation,
                                             function(){return trueLatentState;});


// true agent (which we use to simulate trajectory)
var baseParams = {
  priorBelief: null,
  utility: null,
  alpha: 100,
  noDelays: true,
  discount: 0,
  sophisticatedOrNaive: 'sophisticated',
  myopia: {on: false, bound: 0},
  boundVOI: {on: false, bound: 0},
};
var params = update(baseParams, 
                    {priorBelief: truePriorBelief,
                     utility: tableToUtilityFunction(donutUtilityTable, feature)});



var agent = makeAgent(params, gridworldPOMDP);

var observedTrajectory = simulate(startState, gridworldPOMDP, agent, perceivedTotalTime, 'stateAction');


// helper function for inference
var factorAlongTrajectory = function(index, trajectory, agent, belief){
  if (index >= trajectory.length) {
    return [];
  } else {

    var agentAct = agent.act;
    var agentUpdateBelief = agent.updateBelief;
    
    var state = trajectory[index][0];
    var observedAction = trajectory[index][1];

    var observation = observe(state);
    var nextBelief = agentUpdateBelief(state.manifestState, belief, observation, 0);
    var nextActionERP = agentAct(state.manifestState, nextBelief, 0);

    factor(nextActionERP.score([], observedAction));
    
    return factorAlongTrajectory(index + 1, trajectory, agent, nextBelief);
  }
};

var priorUtilityTable = function(){return uniformDraw([donutUtilityTable, vegUtilityTable]);};
var priorAgentPrior = function(){return uniformDraw([truePriorBelief, alternativePriorBelief]);};


// the inference itself
var getPosterior = function(priorUtilityTable, priorAgentPrior) {
  return printERP(Enumerate(function(){
    
    var utilityTable = priorUtilityTable();
    var utility = tableToUtilityFunction(utilityTable, feature);
    var priorBelief = priorAgentPrior();


    var params = update(baseParams, {priorBelief: priorBelief, utility: utility});
    
    var agent = makeAgent(params, gridworldPOMDP);

    
    factorAlongTrajectory(0, observedTrajectory, agent, priorBelief);

    return {utilityTable: utilityTable,
	    priorBelief: priorBelief};
  }));
};

timeit( function(){return getPosterior(priorUtilityTable, priorAgentPrior)});
