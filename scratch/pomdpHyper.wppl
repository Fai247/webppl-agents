


var makeHyperbolicDiscounter = function (utility, alpha, discount, sophisticatedOrNaive) {

  var agent = dp.cache( 
    function(state, world, delay){
      var stateToActions = world.stateToActions;
     
      return Enumerate(function(){
        var possibleActions = stateToActions(state);
        var action = uniformDraw(possibleActions);
        var eu = expUtility(state, action, world, delay);    
        factor(alpha * eu);
        return action;
      });      
    });

  
  var expUtility = dp.cache(
    function(state, action, world, delay){
      var u = 1.0/(1 + discount*delay) * utility(world, state, action);
      assert.ok(u === u,"utility not valid " + u /*+ " " + JSON.stringify(state)*/);
      if (state.dead || state.timeLeft - 1 == 0){
        return u; 
      } else {                     
        return u + expectation( Enumerate(function(){
          var transition = world.transition;
          var nextState = transition(state, action); 
          var perceivedDelay = { naive : delay + 1, sophisticated : 0}[sophisticatedOrNaive]; 
          var nextAction = sample(agent(nextState, world, perceivedDelay));
          return expUtility(nextState, nextAction, world, delay+1);  
        }));
      }                      
    });

    return {
      utility : utility,
      expUtility : expUtility,
      agent : agent,
      alpha : alpha, 
      discount : discount
    };
};

var simulate = function(state, world, agent, actualTimeLeft, statesOrActions) { 
    var agentAction = agent.agent;
    var expUtility = agent.expUtility;
    var transition = world.transition;

    if (actualTimeLeft==0 | state.dead){
      return [];
    } else {
      var action = agentAction(state, world, 0);
      var nextState = transition(state,sample(action)); 
      var out = {states:state, actions:action, both:[state,action]}[statesOrActions];
      return [ out ].concat( simulate(nextState, world, agent, actualTimeLeft-1, statesOrActions));
    }
}

var mdpSim = function(start, world, agent, time) { 
  var agentAgent = agent.agent;
  var agentExp = agent.expUtility;
  var stateToActions = world.stateToActions;

  var trajectory = simulate(start, world, agent, time, 'states');
  var exp = map(function(state) {
    return [state.loc,
            map(function(a){return agentExp(state, a, world, 0);}, stateToActions(state)) ];
  }, trajectory);
  return {trajectory: trajectory, exp: exp};

  //GridWorld.draw(world, {trajectory : trajectory, expUtilities : exp });
};

var printOut = function( out ){
  console.log('trajectory', map( function(state){return state.loc;}, out.trajectory) );
  console.log('expUtilities',  out.exp );
};



var makeBandits = function(numArms, noiseProb){
  
  var detTransition = function(state,action){
    return update(state,{loc:action, timeLeft:state.timeLeft-1});
  };
  
  var stochasticTransition = function(state,action){
    return flip(noiseProb) ? detTransition(state,0) : detTransition(state,action);
  };

  var transition = noiseProb > 0 ? stochasticTransition : detTransition;
  
  var stateToActions = function(state){return  _.range(numArms);};
  
  return {stateToActions: stateToActions, transition:transition};
};


var makeLine = function(noiseProb){
  var detTransition = function(state,action){
    var newLoc = (state.loc == 0 & action==-1) ? 0 : state.loc + action;
    return update(state,{loc:newLoc, timeLeft:state.timeLeft-1});
  };

  var stochasticTransition = function(state,action){
    return flip(noiseProb) ? detTransition(state,-1) : detTransition(state,action);
  };

  var transition = noiseProb > 0 ? stochasticTransition : detTransition;
  
  var stateToActions = function(state){return  [-1,1];};
  
  return {stateToActions: stateToActions, transition: transition};
};


var testLine = function(){
  var noiseProb = 0;
  var world = makeLine(noiseProb);
  
  var utility = function(world, state, action){
    if (state.loc==1){return -4;}
    return state.loc;
  };
  
  var alpha = 100;
  var perceivedTotalTime = 4;
  var actualTotalTime = 4;  

  var start = { 
    loc : 0,
    dead : false,
    timeLeft : perceivedTotalTime
  };
 
  map( function(naiveOrSophisticated){

    var runSim = function(discount, naiveOr){
      var agent = makeHyperbolicDiscounter(utility, alpha, discount, 
                                           naiveOrSophisticated);
      return mdpSim(start, world, agent, actualTotalTime);
    };
    
    assert.ok( runSim(0).trajectory[1].loc == 1 );
    assert.ok( runSim(.1).trajectory[1].loc == 1 );
    assert.ok( runSim(1).trajectory[1].loc == 0 );
    assert.ok( runSim(2).trajectory[1].loc == 0 );
  }, ['naive', 'sophisticated']);
  
  console.log('Passed testLine');
  //printOut( mdpSim(start, world, agent, actualTotalTime) );
};

testLine();
ash();

var runBandits = function(){
  var numArms = 3;
  var noiseProb = 0;
  var world = makeBandits(numArms, noiseProb);
  
  var utility = function(world, state, action){
    return {'start':0, 0:1, 1:5}[state.loc];
  };
  
  var alpha = 100;
  var discount = 0;
  var agent = makeHyperbolicDiscounter(utility, alpha, discount, 'sophisticated');
  var perceivedTotalTime = 4;
  var actualTotalTime = 4;  

  var start = { 
    loc : 'start',
    dead : false,
    timeLeft : perceivedTotalTime
  };
  
  printOut( mdpSim(start, world, agent, actualTotalTime) );
};

ash();
// var t1 = timeit( function () { 
//   var f = agent.agent;
//   var trajectory = f(start, world, 0);
// });
