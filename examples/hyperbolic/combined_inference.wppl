



var world = restaurantChoiceMDP; // noReverse: true

// TODO why does this not work?
//var world = makeDonutWorld2({big:true, noReverse:false}); 

// loc: [3,1], timeLeft:11
var start = restaurantChoiceStart; // TODO starts at [3,1]. Why does the agent do weird things when starting at [3,0]?
var restaurantHyperbolicInfer = getRestaurantHyperbolicInfer();
var getObservations = restaurantHyperbolicInfer.getObservations;
var getPosterior = restaurantHyperbolicInfer.getPosterior;



// Condition on naive/soph/vegDirect with the same prior
// Prior includes utilities and discouting with a minimal number of parameters
// *discountingOn* allows for discount > 0
// *timeCostDonut* includes possibly +ve timeCost and different values for DonutS and donutN
var hyperbolicQuick = function(alphaValues, discountingOn, timeCostDonut){
  
  var priorAlpha = function(){return uniformDraw(alphaValues);};

  var priorUtilityTable = function(){
    var c = 0;  // TODO why does this mess up when c=10?
    var getU = function(){return uniformDraw([-10,10,20]);};
    var donut = [getU()+c, getU()+c];
    var veg = [getU()+c, getU()+c];

    var donut2 = timeCostDonut ?
        [donut[0]+uniformDraw([-5,5]), donut[1]] : donut;
    var timeCost = timeCostDonut ? uniformDraw([-.01, .5]) : -.01;
    
    return {
      'Donut N' : donut,
      'Donut S' : donut2,
      'Veg'     : veg,
      'Noodle'  : [-5+c, -5+c],
      'timeCost': timeCost
    };
  };
  
  var priorDiscounting = function(){
    return {
      discount: uniformDraw([0,1]),
      sophisticatedOrNaive: uniformDraw(['sophisticated', 'naive']),
    };
  };

  var priorDiscounting = discountingOn ? priorDiscounting :
      function(){return {discount:0, sophisticatedOrNaive:'naive'};}

  var run = function(observationName){
    var observedStateActionSequence = getObservations(world, start, observationName);
    var posterior = getPosterior(world, priorUtilityTable, priorDiscounting, priorAlpha, 
                                 observedStateActionSequence);
    console.log(' \n\n', observationName, ' : '); 
    printTopK(posterior,4);
    displayMarginals(posterior,['alpha', 'discount', 'sophisticatedOrNaive', 'vegMinusDonut',
                               'donutNWins']);
  }
  run('naive'); 
  run('sophisticated');
  run('vegDirect');
};




var runHyperbolicQuick = function(){
  // TODO: with noReverse=true, with alpha=50, we don't infer naive/soph marginals correctly
  // (but this does work OK with alpha=500)
  var alphaValues = [.5, 10, 50, 500];
  var discountingOn = true;
  var timeCostDonut = false;
  hyperbolicQuick(alphaValues, discountingOn,timeCostDonut);

  // compare to model without discounting, which infers that alpha is small
  // (should not infer this for vegDirect). this seems to work. 
  var discountingOn = false;
  var timeCostDonut = false;
  //hyperbolicQuick(alphaValues, discountingOn,timeCostDonut);

  // Should learn DonutNWins for *naive*, timeCost=.5 for *sophisticated*
  // and neither for *vegDirect*
  var discountingOn = false
  var timeCostDonut = true;
  //hyperbolicQuick(alphaValues, discountingOn, timeCostDonut);
};

// runHyperbolicQuick();
// ash();



// Naive params that yield temptation 
var priorAlpha = function(){return 3;};

// Single variable case
var priorUtilityTable = function(){
  var getU = function(){return uniformDraw( _.range(-4,20,1));}
  var donut = [10, 0]; // take MAP params for all but veg 2. 
  var veg = [10, getU()]; 
  
  return {
    'Donut N' : donut,
    'Donut S' : donut,
    'Veg'     : veg,
    'Noodle'  : [-5, -5],
    'timeCost': -.01
  };
};

// Two variable case
var priorUtilityTable2 = function(){
  var getU = function(){return uniformDraw( _.range(-4,20,2));}
  var donut = [getU(), 0]; // take MAP params for all but veg 2. 
  var veg = [10, getU()]; 
  
  return {
    'Donut N' : donut,
    'Donut S' : donut,
    'Veg'     : veg,
    'Noodle'  : [-5, -5],
    'timeCost': -.01
  };
};
var priorUtilityTable = priorUtilityTable2;

var priorDiscounting = function(){
  return { discount: 1, sophisticatedOrNaive: 'naive'};
};

// var observationName = 'naive';
// var observedStateActionSequence = getObservations(world, start, observationName);
// var posterior = getPosterior(world,priorUtilityTable, priorDiscounting, priorAlpha, observedStateActionSequence);
// var marginalVeg = Enumerate( function(){
//   return sample(posterior).utility.Veg[1];
// });
// console.log('marginal veg');
// printERP(marginalVeg);

// displayMarginals(posterior, ['sophisticatedOrNaive', 'discount', 'vegOverDonut']);
// printTopK(posterior,5);






// This is *not* the function we actually use. But it is a slightly simplified
// version of the library function 
var _getPosterior = function(world, priorUtilityTable, priorDiscounting, priorAlpha, observedStateAction){
  return Enumerate(function () {
    // Sample parameters from prior
    var utilityTable = priorUtilityTable();
    var sophisticatedOrNaive = priorDiscounting().sophisticatedOrNaive;

    // Create agent with those parameters
    var agent = makeHyperbolicDiscounter(
      { utility   : makeRestaurantUtilityMDP(world, utilityTable),
        alpha     : priorAlpha(), 
        discount  : 1,
        sophisticatedOrNaive : sophisticatedOrNaive
      }, world);
    
    var agentAction = agent.act;

    // Condition on observed actions
    map(function (stateAction) {
      var state   = stateAction[0];
      var action  = stateAction[1];
      factor(agentAction(state, 0).score([], action)) ; 
    }, observedStateAction);

    // return parameters
    var vegMinusDonut = sum(utilityTable['Veg']) - sum(utilityTable['Donut N']);
    return {
      utility: utilityTable, 
      sophisticatedOrNaive: discounting.sophisticatedOrNaive,
      vegMinusDonut: vegMinusDonut,
    };
  });
};


var example1_inferType = function(){
  // Fold
  
  var runInference = function(observationName){
    // library function for getting observations and computing posterior for Restaurant Choice MDP
    var restaurantHyperbolic = getRestaurantHyperbolicInfer();
    var getObservations = restaurantHyperbolicInfer.getObservations;
    var getPosterior = restaurantHyperbolicInfer.getPosterior;

    // From world and start, get a sequence of observations (which we later condition on)
    var observedStateActionSequence = getObservations(world, start, observationName);
    return getPosterior(world, priorUtilityTable, priorDiscounting, priorAlpha, 
                        observedStateActionSequence);
  };

  // Prior on agent's utility function
  var priorUtilityTable = function(){
    var utilityValues = [-10,0,10,20];
    var getUtilityPair = function(){return [uniformDraw(utilityValues), uniformDraw(utilityValues)];};
    var donut = getUtilityPair();
    var veg = getUtilityPair();
    return {
      'Donut N' : donut,
      'Donut S' : donut,
      'Veg'     : veg,
      'Noodle'  : [-10, -10],
      'timeCost': -.01
    };
  };

  // Prior on discount constant is fixed on 1, but we do attempt to learn whether
  // agent is Sophisticated or Naive. 
  var priorDiscounting = function(){
    return {
      discount: 1,
      sophisticatedOrNaive: uniformDraw(['sophisticated', 'naive']),
    };
  };

  var priorAlpha = function(){return 1000;};
  
  runInference('naive'); 
  runInference('sophisticated');
  runInference('vegDirect');
};

var example2_optimal = function(){
  
  ///fold:
  var runInference = function(observationName){
    // library function for getting observations and computing posterior for Restaurant Choice MDP
    var restaurantHyperbolic = getRestaurantHyperbolicInfer();
    var getObservations = restaurantHyperbolicInfer.getObservations;
    var getPosterior = restaurantHyperbolicInfer.getPosterior;

    // From world and start, get a sequence of observations (which we later condition on)
    var observedStateActionSequence = getObservations(world, start, observationName);
    return getPosterior(world, priorUtilityTable, priorDiscounting, priorAlpha, 
                        observedStateActionSequence);
  };
  ///
  
  // Prior as above but we set the delayed utilities to zero
  var priorUtilityTable = function(){
    var utilityValues = [-10,0,10,20,30,40];
    var getUtilityPair = function(){return [uniformDraw(utilityValues), 0];};
    var donut = getUtilityPair();
    var veg = getUtilityPair();
    return {
      'Donut N' : donut,
      'Donut S' : donut,
      'Veg'     : veg,
      'Noodle'  : [-5, -5],
      'timeCost': -.01
    };
  };

  // We assume no discounting (so *sophisticated* has no effect here)
  var priorDiscounting = function(){
    return {
      discount: 0,
      sophisticatedOrNaive: 'sophisticated'
    };
  };

  var priorAlpha = function(){return uniformDraw([0.1, 10, 100, 1000]);};
  
  var posterior = runInference('naive'); 
  //var posterior = runInference('sophisticated');
  printTopK(posterior,4);
  displayMarginals(posterior,['alpha', 'discount', 'sophisticatedOrNaive', 'vegMinusDonut',
                              'donutNWins']);
};
example2_optimal(); ash();


// TODO try this with noReverse=false and see if it works better
var example3_biased = function(){
  ///fold:
  var runInference = function(observationName, numberMHSamples, repeatObservations){
    // library function for getting observations and computing posterior for Restaurant Choice MDP
    var restaurantHyperbolic = getRestaurantHyperbolicInfer();
    var getObservations = restaurantHyperbolicInfer.getObservations;
    var getPosterior = restaurantHyperbolicInfer.getPosterior;

    // From world and start, get a sequence of observations (which we later condition on)
    var observedStateActionSequence = getObservations(world, start, observationName);
    return getPosterior(world, priorUtilityTable, priorDiscounting, priorAlpha, 
                        observedStateActionSequence,numberMHSamples, repeatObservations);
  };
  ///

  // Prior on agent's utility function
  var priorUtilityTable = function(){
    var utilityValues =  [-10,0,10,20,30];
    var getUtilityPair = function(){return [uniformDraw(utilityValues), uniformDraw(utilityValues)];};
    
    var donut = [uniformDraw(utilityValues), uniformDraw(utilityValues)];
    //var veg = getUtilityPair();
    var veg = [uniformDraw(utilityValues), 20];
    return {
      'Donut N' : donut,
      'Donut S' : donut,
      'Veg'     : veg,
      'Noodle'  : [-5, -5],
      'timeCost': -.01
    };
  };

  // Prior on discount constant is fixed on 1, but we do attempt to learn whether
  // agent is Sophisticated or Naive. 
  var priorDiscounting = function(){
    return {
      discount: uniformDraw([0,1]),
      sophisticatedOrNaive: uniformDraw(['sophisticated','naive'])
    };
  };

  var priorAlpha = function(){return uniformDraw([0.1, 10, 1000]);};

  var numberMHSamples = undefined;
  var repeatObservations = undefined;
  var posterior = runInference('naive', numberMHSamples, repeatObservations);
  //var posterior = runInference('sophisticated');
  printTopK(posterior,8);
  displayMarginals(posterior,['alpha', 'discount', 'sophisticatedOrNaive', 'vegMinusDonut',
                              'donutNWins']);

  //runInference('vegDirect');
};



example3_biased(); ash();

