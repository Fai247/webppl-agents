
// discounter_procrastinates

// procrastinates, because it thinks that it will do it later

var world = makeProcrastinationMDP2();

var utilityTable = {reward: 10,
		    waitCost: -0.1,
		    workCost: -1};
var utility = makeProcrastinationUtility2(utilityTable);

var startState = {loc: "wait_state",
		  waitSteps: 0,
		  timeLeft: 10,
		  terminateAfterAction: false};

var params = {utility: utility,
	      alpha: 100,
	      discount: 5,
	      sophisticatedOrNaive: 'naive'};
  
var agent = makeHyperbolicDiscounter(params, world);
var trajectory = simulateHyperbolic(startState, world, agent, 'stateAction');
map(function(stateAction){return [stateAction[0].loc, stateAction[1]];},
    trajectory);


// Construct Procrastinate Problem world 
var deadline = 10;
var world = makeProcrastinationMDP2(deadline);

// Agent's params
var utilityTable = {reward: 10,
		    waitCost: -0.1,
		    workCost: -1};

var params = {utility: makeProcrastinationUtility2(utilityTable),
	      alpha: 1000,
	      discount: null,
	      sophisticatedOrNaive: 'naive'};

var simulatePro = function(discount){
  var agent = makeHyperbolicDiscounter(update(params, {discount: discount}), world);
  var stateActions = simulateHyperbolic(world.startState, world, agent);
  var states = map(first,stateActions);
  return [last(states).loc, stateActions.length];
};

var discounts = range(11);
var lastActionsAndTimes = map(simulatePro, discounts);

// console.log('\n\n Discounts: ' + discounts + '\nLast actions and lengths of trajectories:'
//       + JSON.stringify(lastActionsAndTimes));



// infer_procrastination

//for non-browser use of viz functions
var viz = webpplGridworld;
var viz = update(viz, {line: function(x){return console.log(x);}});
var print = function(x){
  return console.log(JSON.stringify(x));
};


///fold
var displayTimeSeries = function(observedStateAction, getPosterior){
  var features = ['reward', 'predictWorkLastMinute', 'alpha', 'discount'];
  
  // erp on {a:1, b:3, ...} -> [E('a'), E('b') ... ]
  var erpToMarginalExpectations = function(erp, keys){
    return map(function(key){
      return expectation(getMarginal(erp,key));
    }, keys);
  };
  // condition observations up to *timeIndex* and take expectations
  var inferUpToTimeIndex = function(timeIndex, useOptimalModel){
    var observations = observedStateAction.slice(0,timeIndex);
    return erpToMarginalExpectations( getPosterior(observations, useOptimalModel), features);
  };

  var getTimeSeries = function(useOptimalModel){
    var dummy = useOptimalModel ? print('Optimal Model:') : print('Possibly Discounting Model:');

    var inferAllTimeIndexes = map( function(index){
      return inferUpToTimeIndex(index, useOptimalModel);
    }, range(observedStateAction.length));

    return map( function(i){
      // get full time series of online inferences for each feature
      var series = map(function(infer){return infer[i];}, inferAllTimeIndexes);
      
      print('\n\n feature:' + features[i]); //, ' \n', featureOut);
      viz.line( range(observedStateAction.length), series );
    }, range(features.length) );
  };

  print('Posterior expectation on feature after observing agent "wait" for t timesteps (and "work" when t=9)');
  map(getTimeSeries,[true, false]);  
};
///


var getPosterior = function(observedStateAction, useOptimalModel) {
  var world = makeProcrastinationMDP2();
  var lastChanceState = secondLast(procrastinateUntilEnd102)[0];
  
  return Enumerate(function(){
   
    var utilityTable = {reward: uniformDraw([0.5, 2, 3, 4, 5, 6, 7, 8]),
			waitCost: -0.1,
			workCost: -1};
    var params = {
      utility: makeProcrastinationUtility2(utilityTable),
      alpha: categorical([0.1, 0.2, 0.2, 0.2, 0.3], [0.1, 1, 10, 100, 1000]),
      discount: useOptimalModel ? 0 : uniformDraw([0, .5, 1, 2, 4]),
      sophisticatedOrNaive: 'naive'
    };
    
    var agent = makeHyperbolicDiscounter(params, world);
    var act = agent.act;

    map(function(stateAction){
      var state = stateAction[0];
      var action = stateAction[1];
      factor( act(state, 0).score([], action) )
    }, observedStateAction);

    return {reward: utilityTable.reward, 
            alpha: params.alpha, 
            discount: params.discount, 
            predictWorkLastMinute: sample( act(lastChanceState, 0) ) == 'work'};
  });
};

var observedStateAction = procrastinateUntilEnd102;
displayTimeSeries(observedStateAction, getPosterior)
