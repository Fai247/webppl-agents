
// discounter_procrastinates

// procrastinates, because it thinks that it will do it later

var world = makeProcrastinationMDP2();

var utilityTable = {reward: 10,
		    waitCost: -0.1,
		    workCost: -1};
var utility = makeProcrastinationUtility2(utilityTable);

var startState = {loc: "wait_state",
		  waitSteps: 0,
		  timeLeft: 10,
		  terminateAfterAction: false};

var params = {utility: utility,
	      alpha: 100,
	      discount: 5,
	      sophisticatedOrNaive: 'naive'};
  
var agent = makeHyperbolicDiscounter(params, world);
var trajectory = simulateHyperbolic(startState, world, agent, 'stateAction');
map(function(stateAction){return [stateAction[0].loc, stateAction[1]];},
    trajectory);


// Construct Procrastinate Problem world 
var deadline = 10;
var world = makeProcrastinationMDP2(deadline);

// Agent's params
var utilityTable = {reward: 10,
		    waitCost: -0.1,
		    workCost: -1};

var params = {utility: makeProcrastinationUtility2(utilityTable),
	      alpha: 1000,
	      discount: null,
	      sophisticatedOrNaive: 'naive'};

var simulatePro = function(discount){
  var agent = makeHyperbolicDiscounter(update(params, {discount: discount}), world);
  var stateActions = simulateHyperbolic(world.startState, world, agent);
  var states = map(first,stateActions);
  return [last(states).loc, stateActions.length];
};

var discounts = range(11);
var lastActionsAndTimes = map(simulatePro, discounts);

// console.log('\n\n Discounts: ' + discounts + '\nLast actions and lengths of trajectories:'
//       + JSON.stringify(lastActionsAndTimes));



// infer_procrastination

// give it prefixes of the actual sequence, see how expected reward and logAlpha varies
var observedStateAction = procrastinateUntilEnd102;
var lastChanceState = secondLast(observedStateAction)[0];


var posterior = function(observedStateAction, optimalModel) {
  var world = makeProcrastinationMDP2();
 
  return Enumerate(function(){
   
    var utilityTable = {reward: uniformDraw([0.5, 2, 3, 4, 5, 6, 7, 8]),
			waitCost: -0.1,
			workCost: -1};
    
    var params = {
      utility: makeProcrastinationUtility2(utilityTable),
      alpha: categorical([0.1, 0.2, 0.2, 0.2, 0.3], [0.1, 1, 10, 100, 1000]),
      discount: optimalModel ? 0 :  uniformDraw([0, .5, .1, 2, 4]),
      sophisticatedOrNaive: 'naive'
    };
    
    var agent = makeHyperbolicDiscounter(params, world);
    var act = agent.act;
    
    map(function(stateAction){
      var state = stateAction[0];
      var action = stateAction[1];
      factor( act(state, 0).score([], action) )
    }, observedStateAction);


    return {reward: utilityTable.reward, 
            alpha: params.alpha, 
            discount: params.discount, 
            predictWorkLastMinute: sample( act(lastChanceState, 0) ) == 'work'};
  });
};

var features = ['reward', 'predictWorkLastMinute', 'alpha', 'discount'];

// inference up to the t-th observation
var inferUpToTimeIndex = function(timeIndex){
  
  var expectations = function(erp){
    return map(function(feature){return expectation(getMarginal(erp,feature));
    }, features)
  };

  return map( function(optimal_or_hyperbolic){
    var observations = observedStateAction.slice(0,timeIndex);
    return expectations( posterior(observations, optimal_or_hyperbolic));
  }, [1,0]);
};


var indexToExpectations = map(inferUpToTimeIndex, range(observedStateAction.length));


// build full time series for each feature
var getTimeSeries = function(optimal_or_hyper){
  optimal_or_hyper == 0 ? print('Optimal Model:') : print('Possibly Discounting Model:');
  return map( function(i){
    var featureOut = map(function(optimal_hyper){return optimal_hyper[optimal_or_hyper][i];}, 
                         indexToExpectations);
    print('\n\n feature:' + features[i]); //, ' \n', featureOut);
    viz.line( range(observedStateAction.length), features[i] );
    return featureOut;
  }, range(features.length) );
};

print('Posterior expectation on feature after observing agent "wait" for t timesteps');
var optimalSeries = getTimeSeries(0);
var hyperbolicSeries = getTimeSeries(1);


null
