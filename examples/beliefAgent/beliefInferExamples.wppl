// currently not functional

var printOut = function ( trajectory ) {
  console.log('trajectory', map( function (state) {return state.manifestState.loc;},
				 trajectory) );
  //console.log('expUtilities', out.startEU);
};


// second inference function: generate an agent. In the first state of the trajectory,
// update that agent's beliefs, get the agent's Dist over next states, get the score
// of the actual next state, then put the agent in the actual next state, and repeat
// this process for the whole trajectory.

// same args as before
var inferUtilityBeliefBandits2 = function(observedTrajectory, utilitySignPrior,
					  beliefPrior, alpha, world) {
  var trajectoryLength = observedTrajectory.length;
  var perceivedTotalTime = observedTrajectory[0].manifestState.timeLeft;
  
  var rewardUtility = function(state, action) {
    return state.latentState[state.manifestState.loc];
  };

  return Infer({ method: 'enumerate' }, function(){
    var agentUtilitySign = sample(utilitySignPrior);
    var agentUtility = function(state, action){
      return agentUtilitySign * rewardUtility(state, action);
    };
    var agentPrior = sample(beliefPrior);
    var agent = makeBeliefAgent({utility: agentUtility,
				 alpha: alpha,
				 priorBelief: agentPrior},
				world);
    
    var agentActionBelief = agent.agent;
    var observe = world.observe;

    var sampleAlongTrajectory = function(state, currentBelief, actionsSampled) {
      if (actionsSampled === trajectoryLength - 1) {
	return [];
      } else {
	var actionDist = Infer({ method: 'enumerate' }, function(){
	  return sample(agentActionBelief(state.manifestState, currentBelief,
					  observe(state))).action;
	});

	var newBelief = sample(agentActionBelief(state.manifestState, currentBelief,
						 observe(state))).belief;

	var nextState = observedTrajectory[actionsSampled + 1];
	
	factor(actionDist.score(nextState.manifestState.loc));
	
	return sampleAlongTrajectory(nextState, newBelief, actionsSampled + 1);
      }
    };

    sampleAlongTrajectory(observedTrajectory[0], agentPrior, 0);

    return {utilitySign: agentUtilitySign, prior: agentPrior};
  });
};

// arguments: *observedTrajectories* an array of trajectories,
// *utilityParamsPrior* an Dist over parameters for a utility function,
// *beliefPrior* an Dist over the agent's prior over the latent state,
// *alphaPrior an Dist over the agent's softmax noise,
// *paramsToUtilityFunction* a function which takes parameters for a utility function
// and returns the associated utility function, and *world* the POMDP that the
// trajectories were generated in.

// infers the agent's prior over latent state, the parameters for their utility
// function, and their softmax noise.
var inferBeliefAgent = function(observedTrajectories, utilityParamsPrior, beliefPrior,
				alphaPrior, paramsToUtilityFunction, world) {
  var numTrajectories = observedTrajectories.length;
  var transition = world.transition;
  var observe = world.observe;

  var sampleAlongTrajectory = function(state, currentBelief, actionsSampled,
				       trajectory, agentActionBelief) {
    assert.ok(isDist(agentActionBelief(state.manifestState, currentBelief,
				      observe(state))),
	      'agentActionBelief not correct in sampleAlongTrajectory');
    
    if (actionsSampled === trajectory.length - 1) {
      return [];
    } else {
      var actionBeliefDist = agentActionBelief(state.manifestState, currentBelief,
					      observe(state));
      var nextStateDist = Infer({ method: 'enumerate' }, function(){
	return transition(state, sample(actionBeliefDist).action);
      });
      var newBelief = sample(actionBeliefDist).belief;

      var trajectoryNextState = trajectory[actionsSampled + 1];
      
      factor(nextStateDist.score(trajectoryNextState));
      
      return sampleAlongTrajectory(trajectoryNextState, newBelief, actionsSampled + 1,
				   trajectory, agentActionBelief);
    }
  };

  return Infer({ method: 'enumerate' }, function(){
    var utilityParams = sample(utilityParamsPrior);
    var utility = paramsToUtilityFunction(utilityParams);
    var agentPrior = sample(beliefPrior);
    var alpha = sample(alphaPrior);
    var agent = makeBeliefAgent({utility: utility,
				 alpha: alpha,
				 priorBelief: agentPrior},
			       world);
    var agentActionBelief = agent.agent;

    var factorTrajectory = function(trajectory) {
      return sampleAlongTrajectory(trajectory[0], agentPrior, 0, trajectory,
				   agentActionBelief);
    };

    map(factorTrajectory, observedTrajectories);

    return {utilityParams: utilityParams,
	    prior: agentPrior,
	    alpha: alpha};
  });
};
