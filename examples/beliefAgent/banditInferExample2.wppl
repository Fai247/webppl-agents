// here, we infer the agent's beliefs about the latent state, and also whether
// they like rewards. we show the agent pulling arm 1 and then 0, where the
// latent state is that arm 0 yields higher reward than 1. This shows that
// the agent thought that 1 had higher reward, and that they like reward (since
// otherwise they would not switch to 0).

// the start of this script is the same as in example 1.
var numArms = 2;
var bandit = makeDeterministicBandit(numArms);
var trueLatent = {start: 0, rewards: [10, 1]};
var falseLatent = {start: 0, rewards: [10, 20]};

var agentBelief = Enumerate(function(){
  if (flip(0.8)) {
    return falseLatent;
  } else {
    return trueLatent;
  }
});

var informedBelief = deltaERP(trueLatent);

// reader: try changing 3 to 2 and see what happens and why.
var observedTrajectory = runBeliefAgentBandit(numArms, trueLatent, agentBelief, 2);

// note: change console.log to print in codeboxes
console.log('observed trajectory', map( function (state) {
  return state.manifestState.loc;
}, observedTrajectory) );

// here is where the inference happens
var inferredAgent = function () {
  return printERP(Enumerate(function(){
    var priorBelief = uniformDraw([agentBelief, informedBelief]);
    // to represent uncertainty about the agent's utility function, we randomly
    // generate a utility sign, 1 or -1. If the utility sign is 1, then the
    // agent's utility function is the value of rewards it receives, and if
    // the sign is -1, then the utility function is the negative of its rewards
    var utilitySign = uniformDraw([-1, 1]);
    var agentUtility = function (state,action) {
      return state.manifestState.loc === 'start' ? 0 :
	utilitySign * state.latentState.rewards[state.manifestState.loc];
    };
    
    var alpha = 100;
    
    var agent = makeBeliefAgent({utility: agentUtility,
				 alpha: alpha,
				 priorBelief: priorBelief},
				bandit);
    var newTrajectory = simulateBeliefAgent(observedTrajectory[0], bandit, agent,
					    observedTrajectory.length, 'states');
    condition(_.isEqual(newTrajectory, observedTrajectory));

    return {utilitySign: utilitySign, priorBelief: priorBelief};
  }));
};

timeit(inferredAgent);

