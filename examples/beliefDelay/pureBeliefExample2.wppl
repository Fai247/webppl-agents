// here, we see the agent go the long way around to veg. we deduce that they
// must prefer noodle to veg, and think that noodle is open, despite noodle
// actually being closed (as otherwise they would just go the short way
// around)

// WORLD PARAMS

var world = getBigDonutWorld();
var feature = world.feature;

// possible latent states

var noodleClosedLatent = {'Donut N': true,
			  'Donut S': true,
			  'Veg': true,
			  'Noodle': false};

var everythingOpenLatent = {'Donut N': true,
			    'Donut S': true,
			    'Veg': true,
			    'Noodle': true};

var trueLatentState = noodleClosedLatent;

// start state
var startState = {manifestState: {loc: [3,1],
				  terminateAfterAction: false,
				  timeLeft: 10},
		  latentState: trueLatentState};

// POTENTIAL AGENT PARAMS

// possible utility functions
var noodleUtilityTable = {'Donut N': 1,
			  'Donut S': 1,
			  Veg: 1,
			  Noodle: 3,
			  timeCost: -0.1};

var vegUtilityTable = {'Donut N': 1,
		       'Donut S': 1,
		       Veg: 3,
		       Noodle: 1,
		       timeCost: -0.1};

// possible priors that the agent could have
var uninformedLatentStateSampler = function(){
  return flip(.8) ? everythingOpenLatent : trueLatentState;
};

var uninformedPriorBelief = getPriorBeliefGridworld( startState.manifestState,
					       uninformedLatentStateSampler);

var informedPriorBelief = getPriorBeliefGridworld( startState.manifestState,
						   function(){
						     return trueLatentState;
						   });

// PRIORS OVER AGENT PARAMS

var agentProbNoodleOpenSampler = function() {
  return uniformDraw([0, 0.8]);
};

var agentUtilityTableSampler = function() {
  return uniformDraw([noodleUtilityTable, vegUtilityTable]);
};

// PATH WE CONDITION ON

var path = [[3,1], [3,2], [3,3], [4,3], [5,3], [5,4], [5,5], [5,6],
	    [4,6], [4,7]];

// INFERENCE

var conditionOnPath = function (agent, path, world, startState) {
  var agentAct = agent.act;
  var agentUpdateBelief = agent.updateBelief;
  var priorBelief = agent.params.priorBelief;
  var transition = world.transition;
  var worldObserve = world.observe;
  var observe = getFullObserve(worldObserve);

  var shouldTerminate = function (manifestState) {
    return manifestState.terminateAfterAction;
  };
  
  var _conditionOnPath = function(state, priorBelief, action, i) {
    var observation = observe(state);

    var delay = 0;

    var belief = agentUpdateBelief(priorBelief, observation, action, delay);

    var newAction = sample(agentAct(belief, delay));

    if (shouldTerminate(state.manifestState) || i >= path.length) {
      return 0;
    } else {   
      var nextState = transition(state, newAction);

      condition(_.isEqual(nextState.manifestState.loc, path[i]));

      return _conditionOnPath(nextState, belief, newAction, i+1);
    }
  };

  var startAction = 'noAction';

  return _conditionOnPath(startState, priorBelief, startAction, 1);
};

var posterior = function() {

  var posteriorDist = Infer({ method: 'enumerate' }, function () { 

    var agentProbNoodleOpen = agentProbNoodleOpenSampler();
    var agentPrior = agentProbNoodleOpen === 0 ? informedPriorBelief
	  : uninformedPriorBelief;
    var agentUtilityTable = agentUtilityTableSampler();

    var agent = makeBeliefDelayAgent({
      priorBelief : agentPrior,
      utility : tableToUtilityFunction(agentUtilityTable, feature),
      alpha : 100,
      noDelays: true,
      discount: 0,
      sophisticatedOrNaive: 'sophisticated',
      myopia: {on: false, bound: 0},
      boundVOI: {on: false, bound: 0}
    }, world);

    conditionOnPath(agent, path, world, startState);

    return {
      probNoodleOpen : agentProbNoodleOpen, 
      utilityTable : agentUtilityTable
    };

  });

  printDist(posteriorDist);

};

// printDist(posterior);

timeit(posterior);


