var makeDonutUtility = function (max_digest, rewards) { 
  return function(world, state, action) {
    var getFeature = world.feature;
    var feature = getFeature(state);

    if (state.dead)   { return 0; }
    if (feature.name) { return rewards[feature.name][max_digest - state.digest]; }
    return -0.01;
  };
};


var makeHyperbolicDiscounter = function (agentParams, world) {
  map(function(s){assert.ok(agentParams.hasOwnProperty(s),'makeAgent args: ' + s + '; ' + JSON.stringify(agentParams));}, 
      ['utility','alpha','discount','sophisticatedOrNaive']);

  var stateToActions = world.stateToActions;
  var transition = world.transition;
  var utility = agentParams.utility;
 
    
  var _agent = dp.cache( 
    function(state, delay){
      return Enumerate(function(){
        var possibleActions = stateToActions(state);
        var action = uniformDraw(possibleActions);
        var eu = _expectedUtility(state, action, delay);    
        factor(agentParams.alpha * eu);
        return action;
      });      
    });
  var agent = function(state) { return _agent(state, 0); };

  
  var _expectedUtility = dp.cache(
    function(state, action, delay){
      var u = 1.0/(1 + agentParams.discount*delay) * utility(world, state, action);
      
      assert.ok(u === u,"utility not valid " + u + " " + JSON.stringify(state));
      if (state.dead){
        return u; 
      } else {                     
        return u + expectation( Enumerate(function(){
          var nextState = transition(state, action); 
          var perceivedDelay = { naive : delay + 1, sophisticated : 0}[agentParams.sophisticatedOrNaive]; 
          var nextAction = sample(_agent(nextState, perceivedDelay));
          return _expectedUtility(nextState, nextAction, delay+1);  
        }));
      }                      
    });
  var expectedUtility = function(state, action) { return _expectedUtility(state, action, 0); };


  return {
    agentParams : agentParams,
    expectedUtility : expectedUtility,
    agent : agent,
    _expectedUtility : _expectedUtility,
    _agent : _agent,
  };
};

var simulate = function(state, world, agent, actualTotalTime, statesOrActions) { 
  var perceivedTotalTime = state.timeLeft;
  assert.ok( perceivedTotalTime  > 1, 'perceivedTime<=1. If=1 then should have state.dead, but then simulate wont work');


  var agentAction = agent.agent;
  var expectedUtility = agent.expectedUtility;
  var transition = world.transition;

  var sampleSequence = function (state, actualTimeLeft) {
    if (actualTimeLeft==0 | state.dead){
      return [];
    } else {
      var action = sample(agentAction(state));
      var nextState = transition(state, action); 
      var out = {states:state, actions:action, both:[state,action]}[statesOrActions];
      return [ out ].concat( sampleSequence(nextState, actualTimeLeft-1));
    }

  };
  return sampleSequence(state, actualTotalTime);
};


var mdpSim = function(start, world, agent, actualTotalTime) { 
  var agentAgent = agent.agent;
  var expectedUtility = agent.expectedUtility;

  var trajectory = simulate(start, world, agent, actualTotalTime, 'states');

  var expectedUtilities = map(function(state) {
    return [state.loc, map(function (a) { return  expectedUtility(state, a); }, world.actions)];
  }, trajectory);

  GridWorld.draw(world, {trajectory : trajectory, expUtilities : expectedUtilities });
}
