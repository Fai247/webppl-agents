// POMDP AGENT WITHOUT DELAYS
// basically the same as makeBeliefDelayAgent without delays or discounting

var makeBeliefAgent = function(agentParams, world) {
  map(function(s){assert.ok(agentParams.hasOwnProperty(s),'makeBeliefAgent args');}, 
      ['utility','alpha', 'priorBelief']);
  assert.ok( isPOMDP(world),
	     'world argument lacks transition, stateToActions, or observe');

  var utility = agentParams.utility;
  var manifestStateToActions = world.manifestStateToActions;
  var transition = world.transition;
  var observe = world.observe;

  
  var updateBelief = dp.cache(
    function(manifestState, currentBelief, observation){
      return observation === 'noObservation' ? currentBelief :
	Enumerate(function(){
	  var latentState = sample(currentBelief);
	  var state = buildState(manifestState, latentState);
	  condition(_.isEqual(observe(state), observation));
	  return latentState;
	});
    });

  
  var makeAgent(belief) {
    
    var act = dp.globalCache(function(manifestState) {
      return Enumerate(function(){
	var action = uniformDraw(manifestStateToActions(manifestState));
	var eu = expectedUtility(manifestState, action);
	factor(agentParams.alpha * eu);
	return { action: action, belief: belief };
      });        
    }, [belief]);  // FIXME: may need to cache on other agent parameters
    
    var expectedUtility = dp.globalCache(function(manifestState, action){
      return expectation(
	Enumerate(function(){
	  var latentState = sample(belief);
	  var state = buildState(manifestState, latentState);
	  var u = utility(state, action);
	  if (state.manifestState.dead) {
	    return u;
	  } else {
	    var nextState = transition(state, action);
            var nextObservation = observe(nextState);
            var nextAgent = updateAgent(agent, nextObservation);
	    var nextAction = sample(nextAgent.act(nextState.manifestState));  // FIXME: method calls
	    var futureU = nextAgent.expectedUtility(nextState.manifestState, nextAction.action);  // FIXME: method calls; also, nextAgent.expectedUtility questionable
	    return u + futureU;
	  }
	})
      );
    }, [belief]);  // FIXME: may need to cache on other agent parameters
    
    return { act: act, expectedUtility: expectedUtility, belief: belief };
  }
  
  var updateAgent = function(agent, observation) {  // FIXME: would need to dp.cache this, but that requires that agent can be turned into cache key
    var newBelief = updateBelief(manifestState, agent.belief, observation);
    return makeAgent(newBelief);
  };

  return makeAgent(agentParams.priorBelief);
};

// *simulateBeliefDelayAgent* doesn't actually refer to the delays, so I can copy and
// paste it here
var simulateBeliefAgent = function (startState, world, agent, actualTotalTime,
				    outputStatesOrActions) {
  // var perceivedTotalTime = startState.manifestState.timeLeft;
  // assert.ok( actualTotalTime <= perceivedTotalTime && isState(startState),
  //            'simulate args');
  // assert.ok( perceivedTotalTime  > 1, 'perceivedTime<=1. If=1 then should have state.dead, but then simulate wont work');

  var agentAction = agent.agent;
  var priorBelief = agent.agentParams.priorBelief;
  var transition = world.transition;
  var observe = world.observe;

  var cutoffCondition = function (actualTimeLeft, state) {
    return actualTimeLeft == 0 || state.dead;
  };

  var sampleSequence = function(state, currentBelief, actualTimeLeft) {
    if (cutoffCondition(actualTimeLeft, state.manifestState) ) {
      return [];
    } else {
      var nextAction = sample(agentAction(state.manifestState, currentBelief,
					  observe(state)));
      var nextState = transition(state, nextAction.action);
      var out = {states:state, actions:nextAction.action,
		 both:[state, nextAction.action],
                 stateBelief: [state, currentBelief]}[outputStatesOrActions];
      // could return observations
      
      return [out].concat( sampleSequence(nextState, nextAction.belief,
					  actualTimeLeft - 1));
    }
  };
  return sampleSequence(startState, priorBelief, actualTotalTime);
};

// *armToRewards* is the actual rewards for each arm (true latentState)
// *priorBelief* is agent's belief about rewards,
// which must have true latentState in support
var runBandit = function(numArms, armToRewards, priorBelief,
			  perceivedTotalTime) {
  map( function(n){assert.ok(_.isFinite(armToRewards.rewards[n]),'check armTo');},
       _.range(numArms) );
  var world = makeDeterministicBandit(numArms);
  
  // agent params 
  assert.ok( _.isFinite(priorBelief.score([],armToRewards)),
	     "actual latent not in prior's support" );

  var agentParams = { 
    utility: function (state,action) {
      return state.manifestState.loc === 'start' ? 0 :
	state.latentState.rewards[state.manifestState.loc];
    }, // utility == reward
    alpha: 100,
    priorBelief: priorBelief
  };

  var agent = makeBeliefAgent(agentParams, world);

  var actualTotalTime = perceivedTotalTime;
  var startState = {manifestState: {loc: 'start',
				    timeLeft: perceivedTotalTime,
				    dead: false},
		    latentState: armToRewards};

  return simulateBeliefAgent(startState, world, agent, actualTotalTime, 'states');
};
