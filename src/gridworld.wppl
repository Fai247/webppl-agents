/* jshint shadow: true, newcap: false, maxerr:500, sub:false, latedef:false */

var GridWorld = webpplGridworld; // reference to the exports of gridworld.js


//TODO
// 3. Have some functions for converting the output of *mdpSimulate* to tables for display.



// GridWorld library and MDP agent


// Helper Functions
var ash = function(){assert.ok(0,'assert halt');};

var range = function(n){
  if (n===0){return [];} 
  else {return range(n-1).concat([n-1]);}
};

var downToOne = function(n){
  if (n==0){return [];}
  else {return [n].concat(downToOne(n-1));}
};

var selectIndex = function(ar,i){
    return  map(function(tuple){return tuple[i];}, ar);
};

var arraysEqual = function(xs, ys){
  return JSON.stringify(xs) === JSON.stringify(ys);
};

var printERP = function(x,k) {
  var erpValues = sort(x.support(), undefined, function(v){return -x.score([], v);});
  var erpValues = typeof(k)=='undefined' ? erpValues : erpValues.slice(0,k);
  map(
    function(v){
      var prob = Math.exp(x.score([], v));
      if (prob > 0.0){
        console.log(JSON.stringify(v) + ': ' + prob.toFixed(5));
      }
    },
    erpValues);
};

var update = function(base, ext){
  return _.extend({}, base, ext);
};




// GRIDWORLD LIBRARY

// States have form [x,y] with Cartesian coordinates
// Grid dimenions are called xLim and yLim
// Actions don't include "stay" or diagonal moves.
// Agent gets rewards on exiting a state. 
// Transition function can be stochastic. 

var gridActions = ['l','r','u','d'];  // left, right, up down


// Will treat the postTerminal as distinct from the terminal
var gridEqual = function(state1,state2){
  return arraysEqual(state1,state2);
};

// gridworld state is in array of states
var stateInArray = function(state,ar){
  assert.ok(state.length==2 & ar.length >= 0, 'stateInArray args');
  return any( function(x){return x===true;},
              map( function(x){return gridEqual(x,state)}, ar));
};

// After entering a terminal, agent goes to "postTerminal" for rest of time
var isPostTerminal = function(state){return state[0]=='dead';};

var inGrid = function(xLim, yLim, state){ 
  return (indexOf(state[0],range(xLim)) != undefined) & (indexOf(state[1],range(yLim)) != undefined);
};

var isBlockedState = function(state,blockedStates){
  return stateInArray(state,blockedStates);
};

var openToBlocked = function(open, xLim, yLim){
  var fullGrid = Gridworld.getGridStates(xLim, yLim);
  return filter( function(state){return !stateInArray(state,open);}, fullGrid);
};



//  Construct gridworld transition function
var makeGridTransition = function(xLim, yLim, blockedStates, terminals){
  
  assert.ok( xLim>1 | yLim>1, 'makeGridTransition');

  var isAllowedState = function(state){
    return (inGrid(xLim, yLim, state) | isPostTerminal(state)) & !isBlockedState(state,blockedStates) ;
  };

  return function(state,action){    
    assert.ok( isAllowedState(state), 'current state is not allowed');
    assert.ok( indexOf( action, gridActions ) != undefined, 'action in gridActions');
    
    var gridTransition = {l: [state[0]-1, state[1]],
                          r: [state[0]+1, state[1]],
                          u: [state[0], state[1]+1],
                          d: [state[0], state[1]-1]};

    // terminals: ignore action
    if (stateInArray(state, terminals)){return ['dead', state[0], state[1]];}
    if (isPostTerminal(state)){return state;}

    var possibleNextState = gridTransition[action];
    return isAllowedState(possibleNextState) ? possibleNextState : state
  };
};

// Standard stochastic transitions, where agent sometimes goes in orthogonal direction
// to the one intended. We implement this by using a deterministic transition function
// and stochastically changing the action the agent performs.

var makeStochasticGridTransition = function(xLim, yLim, blockedStates, noiseProb, terminals){

  var detTransition = makeGridTransition(xLim, yLim, blockedStates, terminals);

  // If agent selects *key*, with *noiseProb* they do one of the two orthogonal actions
  var noiseActionTable = {u: ['l','r'], d: ['l','r'], l: ['u','d'], r: ['u','d'] };
  
  return function(state,action){
    sample(Enumerate( function(){
      return flip(1-noiseProb) ? detTransition(state,action) : 
        detTransition(state, uniformDraw(noiseActionTable[action]))
    }))
  };
};

// All params for gridworld
var makeBlockedGridParams = function(xLim, yLim, blockedStates, terminals, utilityFunction, noiseProb, alpha, labels){
  var t = noiseProb==0 ? makeGridTransition(xLim, yLim, blockedStates, terminals) : 
      makeStochasticGridTransition(xLim, yLim, blockedStates, noiseProb, terminals)
  return {utility: utilityFunction,
          transition: t,
          actions: gridActions,
          terminals: terminals,
          alpha: alpha,
          blockedStates: blockedStates,
          xLim: xLim,
          yLim: yLim, 
          labels : labels};
};



// get all grid states [[0,0],[0,1], ... ] 
var getFullGrid = function(xLim, yLim){
  var erp = Enumerate(function(){return [uniformDraw(range(xLim)), uniformDraw(range(yLim))];});
  return erp.support();
};

// Map states to their features and then display via JS library function
var displayGrid = function(params){
  var u = params.utility;
  var states = getFullGrid(params.xLim, params.yLim);

  var out = map( function(state){
    if ( stateInArray(state, params.blockedStates) ){return '#';}
    if ( stateInArray(state, params.terminals) ){return u(state,'u')+'t';}
    if ( u(state,'u') != 0 ){ return JSON.stringify(u(state,'u'));}
    if ( true ){return '_';}
  }, states);

  var zipGrid = zip(states,out);
  GridWorld.zipToDisplayGrid( zipGrid, params.xLim, params.yLim);
  return zipGrid;
};



var _getStates = function( s0, actionSequence, t){
  var l = actionSequence.length;
  if (l==0){
    return []; // leave off the last state transition
  } else {
    var s1 = t(s0,actionSequence[0]);
    return [s0].concat( _getStates( s1, actionSequence.slice(1,l), t));
  };
};

// iterate the transition function to get [s0, t(s0,a0), ....]
var getStates = function(s0, actionSequence, t){
  return Rejection(function(){
    return _getStates(s0, actionSequence, t);
    }, 1000, undefined, true);
};



// 3x3 grid where you go from anywhere to top-right
var _makeSmall = function(noiseProb, alpha, xLim, yLim){
  var u = function(state,action){
    if (gridEqual(state,[2,2])){return 1;}
    if (isPostTerminal(state)){return 0;}
    return -0.05;
  };
  var blockedStates = [];
  var terminals = [ [2,2]];
  return makeBlockedGridParams(xLim, yLim, blockedStates, terminals, u, noiseProb, alpha);
};

var makeSmall = function(noiseProb, alpha){return _makeSmall(noiseProb, alpha, 3, 3);};
var makeSmallRectangle = function(noiseProb, alpha){return _makeSmall(noiseProb, alpha, 3, 4);};



// Russell-Norvig basic example
var make43 = function(noiseProb, alpha){
  var utility = function(state,action){
    if (gridEqual(state,[3,2]) ){ return 1;}
    if (gridEqual(state,[3,1]) ){ return -1;}
    if (isPostTerminal(state)){ return 0;}
    return -.1;
  };
  var blockedStates = [[1,1] ];
  var terminals = [[3,2], [3,1]];
  return makeBlockedGridParams(4,3, blockedStates, terminals, utility, noiseProb, alpha);
};


// Donut example from AAAI paper
var makeDonut = function(noiseProb, alpha){
  var blockedStates = [ [0,5], [1,5], [2,5],      [4,5], [5,5],
                        [0,4], [1,4],                    [5,4],  
                        [0,3],              [3,3],       
                        [0,2], [1,2],       [3,2],       [5,2],
                                                         [5,1],
                        [0,0], [1,0],       [3,0], [4,0], [5,0] ];
  var terminals = [[0,1], [1,3], [5,3], [3,5] ];
  var labels = [ 
      { point : [0, 1], content : "Donut"},
      { point : [1, 3], content : "Donut"},
      { point : [3, 5], content : "Veg"},
      { point : [5, 3], content : "Noodle"},
      { point : [2, 0], content : "Start"}
  ];

  var u = function(state,action){
    if (gridEqual(state,[3,5])){return 4;}
    if (isPostTerminal(state)){return 0;};
    if (stateInArray(state,terminals)){return 1;}
    return -0.1;
  };
  return makeBlockedGridParams(6,6, blockedStates, terminals, u, noiseProb, alpha, labels);
};

var makeHike = function(noiseProb, alpha, utilityEast, utilityWest, utilityHill, timeCost){
  map( function(input){assert.ok( typeof(input)=='number', 'makeHike inputs' );}, [noiseProb, alpha, utilityEast, utilityWest, utilityHill, timeCost] );
  assert.ok(timeCost <=0, 'makeHike inputs' );
  assert.ok(noiseProb >= 0 & alpha >= 0, 'makeHike inputs' );

  
  var xLim = 5;
  var yLim = 5;
  var blockedStates = [ [1,2], [1,3], [3,2] ];
  var terminals = [ [0,0], [1,0], [2,0], [3,0], [4,0], [2,2], [4,2] ]; 

  var u = function(state,action){
    if (gridEqual(state,[2,2])){return utilityWest;}
    if (gridEqual(state,[4,2])){return utilityEast;}
    if (isPostTerminal(state)){return 0;};
    if (stateInArray(state,terminals)) {return utilityHill;}
    return timeCost;
  };
  return makeBlockedGridParams(xLim, yLim, blockedStates, terminals, u, noiseProb, alpha);
};





// MDP AGENT

// *actualTotalTime*: how many steps we run *simulate* for
// *perceivedTotalTime*: how many steps agent perceives in the future (*actualTotalTime* could be less)
// *numberRejectionSamples*: if ==0, we use Enumerate for simulating trajectories, otherwise we rejection sample
// *output*: *simulate* either outputs states (form [state,'X']), actions (['X',action]) or both ([state,action])

var mdpSimulate = function(startState, actualTotalTime, perceivedTotalTime, params, numberRejectionSamples, 
                           getExpUtilityValues, output, conditionOnStates){

  var terminalCheck = true; // toggle whether end at terminals (if false, agent stays in postTerminal state --
  // this is equivalent in terms of the agent's plans but means sequences of states are longer)

  // At a terminal, agent takes a single action and then transitions to a "postTerminal" state
  // which has form [ 'dead', [x,y] ] where [x,y] is terminal's coordinates.
  var isTerminal = function(state){return terminalCheck & isPostTerminal(state);}; 


  var agent = cache( 
    function(_agent, _expUtility, state, timeLeft, params){
     
      return Enumerate(function(){
        var action = uniformDraw(params.actions);
        var eu = _expUtility(_agent, _expUtility, state, action, timeLeft, params);    
        factor(params.alpha * eu);
        return action;
      });      
    });

  
  var expUtility = cache(
    function(_agent, _expUtility, state, action, timeLeft, params){
      var utility = params.utility;
      var u = utility(state,action);
      
      if (timeLeft - 1 == 0 | isTerminal(state)){
        return u; 
      } else {                     
        return u + expectation( Enumerate(function(){
          var transition = params.transition;
          var nextState = transition(state, action); 
          var nextAction = sample(_agent(_agent, _expUtility, nextState, timeLeft-1, params));
          return _expUtility(_agent, _expUtility, nextState, nextAction, timeLeft-1, params);  
        }));
      }                      
    });

  
  var simulate = function(startState, actualTotalTime, perceivedTotalTime, params, output){

    var sampleSequence = function(state, actualTimeLeft, perceivedTimeLeft){
      if (actualTimeLeft==0 | isTerminal(state)){
        return [];
      } else {
        var action = sample(agent(agent, expUtility, state, perceivedTimeLeft, params));
        var transition = params.transition;
        var nextState = transition(state,action); 
        var out = {states:[state,'X'], actions:['X',action], 
                   actionOnly: action, both: [state,action]}[output];
        return [ out ].concat( sampleSequence(nextState,actualTimeLeft-1, perceivedTimeLeft-1));
      }
    };
    
    return numberRejectionSamples==0 ? 
      Enumerate(function(){
        return sampleSequence(startState, actualTotalTime, perceivedTotalTime); 
      }) : 
    Rejection(function(){
      return sampleSequence(startState, actualTotalTime, perceivedTotalTime); 
    }, numberRejectionSamples, undefined, true);
  };

  // Get expU for each state visited in MAP() and for all four possible actions
  // output has form: [ [state0,[EU(state0,'l'), EU(state0,'r'), EU(state0,'u'), EU(state0,'d') ] ], .... ]
  // TODO give some warning because expUtilities are misleading for single action
  var getExpUtility = function(){
    
    var erp = simulate(startState, actualTotalTime, perceivedTotalTime, params, 'states');
    var states = selectIndex(erp.MAP().val,0);
    var timeStates = zip(downToOne(states.length), states);
    
    return map( function(timeState){
      return [JSON.stringify(timeState[1]), map(function(action){
        return expUtility(agent, expUtility, timeState[1], action, timeState[0], params);
      }, params.actions)];
    }, timeStates);
   
  };

  var getStateActionERPs = function( states ){
    var timeStates = zip(downToOne(perceivedTotalTime).slice(0,states.length), states); // assumes states begin at start
    //var timeStates2 = zip(downToOne(states.length), states);
    //console.log('timestates: ', timeStates, timeStates2);
    return map( function(timeState){
      var time = timeState[0];
      var state = timeState[1];
      return agent(agent, expUtility, state, time, params);
    }, timeStates);
  };
  

  var erp = simulate(startState, actualTotalTime, perceivedTotalTime, params, output);
  var expUtilityValues = getExpUtilityValues ? getExpUtility() : [];
  var stateActionERPs = conditionOnStates != undefined ? getStateActionERPs(conditionOnStates) : [];
  
  return {erp: erp, expUtilityValues: expUtilityValues, stateActionERPs: stateActionERPs }; 
  
};











var displaySequence = function( stateActions, params ){
  return GridWorld.zipToDisplayGrid( stateActions, params.xLim, params.yLim, true )
};

// THIS IS USED IN CHAPTER 5. TODO: USE MORE DESCRIPTIVE NAMES.
// *mdpSimulate* function above should be used for inference/MDP experiments
var mdpSimulateTemp = function(startState, totalTime, params, numRejectionSamples){
  var alpha = params.alpha;
  var transition = params.transition;
  var utility = params.utility;
  var actions = params.actions;
  var isTerminal = function(state){return state[0]=='dead';};


  var agent = dp.cache(function(state, timeLeft){
    return Enumerate(function(){
      var action = uniformDraw(actions);
      var eu = expUtility(state, action, timeLeft);    
      factor( alpha * eu);
    return action;
    });      
  });
  
  
  var expUtility = dp.cache(function(state, action, timeLeft){
    var u = utility(state,action);
    var newTimeLeft = timeLeft - 1;
    
    if (newTimeLeft == 0 | isTerminal(state)){
      return u; 
    } else {                     
      return u + expectation( Enumerate(function(){
        var nextState = transition(state, action); 
        var nextAction = sample(agent(nextState, newTimeLeft));
        return expUtility(nextState, nextAction, newTimeLeft);  
      }));
    }                      
  });
  
  var simulate = function(startState, totalTime){
  
    var sampleSequence = function(state, timeLeft){
      if (timeLeft == 0 | isTerminal(state)){
        return [];
      } else {
      var action = sample(agent(state, timeLeft));
        var nextState = transition(state,action); 
        return [[state,action]].concat( sampleSequence(nextState,timeLeft-1 ))
      }
    };
    return Rejection(function(){return sampleSequence(startState, totalTime);}, numRejectionSamples);
  };

  return simulate(startState, totalTime);
};










