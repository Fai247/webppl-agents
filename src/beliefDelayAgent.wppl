// BELIEF DELAY AGENT

// Test script by running:
//webppl beliefDelayAgent/irlBanditTests.wppl --require webppl-timeit --require webppl-dp --require .


// Helper functions for testing argument types (warning: heuristics only)

var isGreaterZero = function (x) {return _.isFinite(x) && x > 0;};
var isERP = function (x) {return x.hasOwnProperty('score') && x.hasOwnProperty('sample');};
var isState = function (x) {x.hasOwnProperty('latentState') && _.isFinite(x.manifestState.timeLeft);};
var isGridworld = function(world){return arraysEqual(world.actions, ['l', 'r', 'u', 'd']);};
var isWorld = function (x) { return x.hasOwnProperty('transition') && x.hasOwnProperty('manifestStateToActions') &&
                             x.hasOwnProperty('observe');};

var assertIsWorld = function(world){
  assertHasProperties(world, ['transition', 'manifestStateToActions', 'observe'], 'putative world lacks properties of world')
};

var inSupport = function(x, erp){return _.isFinite( erp.score([], x) ); };
                   

// Helper functions

var buildState = function (manifestState, latentState) {
  return { manifestState:manifestState, latentState:latentState };
};

var downToOne = function(n){
  if (n==0){return [];}
  else {return [n].concat(downToOne(n-1));}
};

// From array of POMDP states, extract locations array
var getLocs = function(trajectory){
  assert.ok(_.isArray(trajectory) && isState(trajectory[0]), 'getLocs args');
  return _.pluck( _.pluck(trajectory,'manifestState'), 'loc' );
};

// From array of locs, add *timeLeft* and *dead*
var locsToManifestStates = function(locs){
  return map( function(locTime){ 
    var dead = locTime[1]==1;
    return {loc: locTime[0], timeLeft:locTime[1], dead: dead};
  }, zip( locs, downToOne(locs.length) ) );
};

// From array of form [ [loc, action] ], output array of form:
// [  [{manifestState:{loc:, timeLeft:, dead:}, latentState:latentState}, action ]  ]
var stateActionToFullStates = function(locAction, latentState){
  var locs = map(first,locAction);
  var manifestStates = locsToManifestStates(locs);
  var fullStates = map( function(manifest){
    return buildState(manifest,latentState);
    }, manifestStates);
  
  return zip( fullStates, map(second,locAction) );
};




var oldMakeBeliefDelayAgent = function (agentParams, world){
  assertHasProperties(agentParams, ['utility','alpha','discount','sophisticatedOrNaive', 'priorBelief', 'noDelays'], 
                      'makeBeliefDelayAgent args');
  assertIsWorld(world);
  
  var utility = agentParams.utility;
  var manifestStateToActions = world.manifestStateToActions;
  var transition = world.transition;
  var observe = world.observe;

  
  // Set all delays to zero if *noDelays* (for POMDP agent without discounting)
  var noDelays = agentParams.noDelays || (agentParams.discount==0 && !agentParams.myopiaCutoff);
  
  var getPerceivedDelay = function(currentDelay){
    return noDelays ? 0 : {naive: currentDelay + 1, sophisticated: 0 }[agentParams.sophisticatedOrNaive];
  };
  
  var incrementDelay = function(currentDelay){
    return noDelays ? 0 : currentDelay + 1;
  };

  // For myopic agent, terminate in expUtility when delay reaches *myopiaCutoff*
  if (agentParams.myopiaCutoff){assert.ok(!noDelays && agentParams.sophisticatedOrNaive==='naive',
                                          'Myopia needs delays and naive');}
  var myopiaCutoff = function(delay){
    return _.isNumber(agentParams.myopiaCutoff) ? delay >= agentParams.myopiaCutoff : false;
  };

  
  // *currentBelief* is ERP on latent states, returns posterior ERP on latent states
  var updateBelief = dp.cache(
    function (manifestState, currentBelief, observation) {
      return Enumerate(function () {
        var latentState = sample(currentBelief);
        var state = buildState(manifestState, latentState);
        condition(_.isEqual(observe(state), observation));
        return latentState;
      });
    });

  var _agent = dp.cache(
    function (manifestState, currentBelief, observation, delay) {
      assert.ok(isGreaterZero(manifestState.timeLeft) && isERP(currentBelief) && _.isFinite(delay), '_agent args fail'); 

      var newBelief = updateBelief(manifestState, currentBelief, observation);
      
      return Enumerate(function () {
        var action = uniformDraw(manifestStateToActions(manifestState));
        var eu = expectedUtility(manifestState, newBelief, action, delay);
        factor(agentParams.alpha * eu);
        return { action: action, belief: newBelief };
      });
    });
  
  var agent = function (manifestState, currentBelief, observation) {
    return _agent(manifestState, currentBelief, observation, 0);
  };

  var expectedUtility = dp.cache(
    function (manifestState, currentBelief, action, delay) {
      return expectation(
        Enumerate(function () {
          var latentState = sample(currentBelief);
          var state = buildState(manifestState, latentState);
          var u = 1.0 / (1 + agentParams.discount * delay) * utility(state, action);
          if (state.manifestState.dead || myopiaCutoff(delay)) {
            return u;
          } else {
            var nextState = transition(state, action);
            var nextObservation = observe(nextState);
            var perceivedDelay = getPerceivedDelay(delay);
            var nextAgentOutput = sample(_agent(nextState.manifestState, currentBelief, nextObservation, perceivedDelay));
            var futureU = expectedUtility(nextState.manifestState, nextAgentOutput.belief, nextAgentOutput.action, incrementDelay(delay));                                                                                                                
            return u + futureU;
          }
        }));
    });

  return { agent : agent, _agent:_agent, expectedUtility : expectedUtility, agentParams: agentParams};
};

var makeBeliefDelayAgent = function (agentParams, world){
  assertHasProperties(agentParams, ['utility','alpha','discount','sophisticatedOrNaive', 'priorBelief', 'noDelays'], 
                      'makeBeliefDelayAgent args');
  assertIsWorld(world);
  
  var utility = agentParams.utility;
  var manifestStateToActions = world.manifestStateToActions;
  var transition = world.transition;
  var observe = world.observe;

  
  // Set all delays to zero if *noDelays* (for POMDP agent without discounting)
  var noDelays = agentParams.noDelays || (agentParams.discount==0 && !agentParams.myopiaCutoff);
  
  var getPerceivedDelay = function(currentDelay){
    return noDelays ? 0 : {naive: currentDelay + 1, sophisticated: 0 }[agentParams.sophisticatedOrNaive];
  };
  
  var incrementDelay = function(currentDelay){
    return noDelays ? 0 : currentDelay + 1;
  };

  // For myopic agent, terminate in expUtility when delay reaches *myopiaCutoff*
  if (agentParams.myopiaCutoff){assert.ok(!noDelays && agentParams.sophisticatedOrNaive==='naive',
                                          'Myopia needs delays and naive');}
  var myopiaCutoff = function(delay){
    return _.isNumber(agentParams.myopiaCutoff) ? delay >= agentParams.myopiaCutoff : false;
  };

  
  // *currentBelief* is ERP on latent states, returns posterior ERP on latent states
  var updateBelief = dp.cache(
    function (manifestState, currentBelief, observation) {
      return Enumerate(function () {
        var latentState = sample(currentBelief);
        var state = buildState(manifestState, latentState);
        condition(_.isEqual(observe(state), observation));
        return latentState;
      });
    });

  var _act = dp.cache(
    function (manifestState, currentBelief, delay) {
      assert.ok(isGreaterZero(manifestState.timeLeft) && isERP(currentBelief) && _.isFinite(delay), '_agent args fail'); 
   
      return Enumerate(function () {
        var action = uniformDraw(manifestStateToActions(manifestState));
        var eu = expectedUtility(manifestState, newBelief, action, delay);
        factor(agentParams.alpha * eu);
        return action;
      });
    });
  
  var act = function (manifestState, currentBelief) {
    return _act(manifestState, currentBelief, observation, 0);
  };

  var expectedUtility = dp.cache(
    function (manifestState, currentBelief, action, delay) {
      return expectation(
        Enumerate(function () {
          var latentState = sample(currentBelief);
          var state = buildState(manifestState, latentState);
          var u = 1.0 / (1 + agentParams.discount * delay) * utility(state, action);
          if (state.manifestState.dead || myopiaCutoff(delay)) {
            return u;
          } else {
            // Change state and get observation based on *latentState*
            var nextState = transition(state, action);
            var nextObservation = observe(nextState);

            // Update agent's internal state based on new manifestState, the observation, old belief, old delay.
            var nextBelief = updateBelief(nextState.manifestState, currentBelief, nextObservation);
            var perceivedDelay = getPerceivedDelay(delay);
            var nextAction = sample(_act(nextState.manifestState, nextBelief, perceivedDelay));

            // Compute utility given agent's new internal belief state, the new manifestState, and agent's action. 
            var futureU = expectedUtility(nextState.manifestState,nextBelief,nextAction,incrementDelay(delay));
            return u + futureU;
          }
        }));
    });

  
  return { act:act, _act:_act, updateBelief:updateBelief, expectedUtility : expectedUtility, agentParams: agentParams};
};



var simulateBeliefDelayAgent = function (startState, world, agent, actualTotalTime, outputVariables) {
  var perceivedTotalTime = startState.manifestState.timeLeft;
  assert.ok( actualTotalTime <= perceivedTotalTime && isState(startState), 'simulate args');
  assert.ok( perceivedTotalTime  > 1, 'perceivedTime<=1. If=1 then should have state.dead, but then simulate wont work');

  var agentAct = agent.act;
  var agentUpdateBelief = agent.updateBelief;
  var priorBelief = agent.agentParams.priorBelief;
  var transition = world.transition;
  var observe = world.observe;
  
  var getOutputVariables = function(state, nextAction, currentBelief){
    var table =  {states:state, actions:nextAction.action, stateAction:[state, nextAction.action], 
                  stateBelief: [state, currentBelief]};
    assert.ok( _.has(table,outputVariables), "outputVariables key not in ['states', 'actions', 'stateAction', 'stateBelief']");
    return table[outputVariables];
  };
 
  var terminateCondition = isGridworld(world) ? function (actualTimeLeft, state) {return actualTimeLeft == 0 || state.dead;} :
      function (actualTimeLeft, state) {return actualTimeLeft == 0;};


  var sampleSequence = function(state, currentBelief, actualTimeLeft) {
    if (terminateCondition(actualTimeLeft, state.manifestState) ) {
      return [];
    } else {
      var nextObservation = observe(state);

      // Update agent's internal state and get action
      var nextBelief = agentUpdateBelief( state.manifestState, currentBelief, nextObservation );
      var nextAction = sample(agentAct(state.manifestState, nextBelief));

      // Update world state and return output and output from recursing on updated world state, internal state, and time. 
      var nextState = transition(state, nextAction);
      var out = getOutputVariables(state, nextAction, currentBelief);
      return [out].concat( sampleSequence(nextState, nextBelief, actualTimeLeft - 1));
    }
  };
  return sampleSequence(startState, priorBelief, actualTotalTime);
};


// TODO REWRITE EXP UTILITY IF IT NEEDS IT?

// Run *simulate*. Then use *expectedUtility* to compute the expected
// utilities of each state along the trajectory. Do this from the
// perspective of each timestep. For discounting agents, the expected
// utilities for the same state/timeLeft will change depending on how
// close the agent is to the state (as measured by *delay*).

var getExpectedUtilitiesBeliefDelayAgent = function (startState, world, agent, actualTotalTime){
  assert.ok( !agent.agentParams.noDelays, 'Delays switched off. This function uses variation in delays.');
  
  var trajectory = simulateBeliefDelayAgent(startState, world, agent, actualTotalTime, 'stateBelief');
  
  var expectedUtility = agent.expectedUtility;
  var stateToActions = world.manifestStateToActions;

  
  var getExpectedUtilityFromTimestep = function(t){
    var trajectoryAfterT = trajectory.slice(t, trajectory.length);
    var len = trajectoryAfterT.length;
    
    return map(function(stateBelief){
      var manifestState = stateBelief[0].manifestState;
      var belief = stateBelief[1];
      var timeLeft = manifestState.timeLeft;
      var delay = len - timeLeft;
      
      return [stateBelief[0], 
              map(function(a){
                return expectedUtility(manifestState, belief, a, delay);
              }, stateToActions(manifestState))
             ];
    }, trajectoryAfterT);
  };

  var expectedUtilities = map(getExpectedUtilityFromTimestep, _.range(trajectory.length));

  return {trajectory: trajectory, expectedUtilities: expectedUtilities};
  
};


// Helper functions to display outputs of *simulate* and *getExpectedUtilities*
var displayTrajectory = function ( trajectory ) {
  console.log('trajectory (locations only)',
              map( function (state) {return state.manifestState.loc;}, trajectory) );
};

var displayExpectedUtilities = function(timeToEUs){
  map( function(EUs){
    console.log('\n\n Next timestep: ');
    map(function(s){console.log(s[0].manifestState.loc, s[1]);}, EUs);
  }, timeToEUs);
};
