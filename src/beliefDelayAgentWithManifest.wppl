// BELIEF DELAY AGENT

// Test script by running:
//webppl tests/beliefDelayAgentIRLBandits.wppl --require webppl-timeit --require webppl-dp --require .


// Agent with beliefs and delays: for hyperbolic discounting, false beliefs
// myopia, boundVOI, and various combinations. 




// Example of well-formed *params* argument for makeBeliefDelayAgent.
// See more examples in ../beliefDelayAgent/irlBanditTests.wppl
var exampleMakeAgentParams = {
  alpha: 100,
  noDelays: false,
  discount: 2,
  sophisticatedOrNaive: 'sophisticated',
  myopia: {on:false, bound:0},
  priorBelief: Enumerate(function(){return flip() ? 'latentA' : 'latentB';}),
  boundVOI: {on:false, bound:0}
};


var makeBeliefDelayAgent = function (params, world){

  // Check on correctness of *params* and *world*
  assert.ok( hasProperties(params, ['utility','alpha','discount','sophisticatedOrNaive', 
                                    'priorBelief', 'noDelays', 'myopia', 'boundVOI']), 
             'makeBeliefDelayAgent args');
  assert.ok( isPOMDPWorld(world), 'makeBeliefDelay world is not world' );
  
  assert.ok( params.myopia.on === false || params.boundVOI.on === false, "one of myopia and boundVOI must be false");
  if (params.myopia.on || params.boundVOI.on){
    assert.ok( params.noDelays === false && params.sophisticatedOrNaive=== 'naive', 
    'myopia and boundVOI require Naive agent with delays');
  }

  // Variables for methods
  var utility = params.utility;
  var manifestStateToActions = world.manifestStateToActions;
  var transition = world.transition;
  var observe = world.observe;
  

  // Update the *delay* parameter in *expectedUtility* for sampling actions and future utilities
  var transformDelay = function(delay){
    var table = {naive: delay + 1, sophisticated: 0 };
    return params.noDelays ? 0 : table[params.sophisticatedOrNaive];
  };
  
  var incrementDelay = function(delay){
    return params.noDelays ? 0 : delay + 1;
  };

  // Termination condition for *expectedUtility*
  var shouldTerminate = function(state, delay) {
    if (state.manifestState.terminateAfterAction) {
      return true;
    }
    if (params.myopia.on) {
      return delay >= params.myopia.bound;
    }
    return false;
  }

  
  // *belief* is ERP on latent states, returns posterior ERP on latent states
  var updateBelief = dp.cache(
    function (manifestState, belief, observation, delay) {
      if (params.boundVOI.on && (delay >= params.boundVOI.bound)){
        return belief;
      } else {
        return Enumerate(function () {
          var latentState = sample(belief);
          var state = buildState(manifestState, latentState);
          condition(_.isEqual(observe(state), observation));
          return latentState;
      });
      }
    });

  
  var act = dp.cache(
    function (manifestState, belief, delay) {
      assert.ok(isGreaterZero(manifestState.timeLeft) && isERP(belief) && _.isFinite(delay), 'act arguments error' + 
                'act: manifestState, belief, delay' + JSON.stringify([manifestState, belief, delay]));

      return Enumerate(function () {
        var action = uniformDraw(manifestStateToActions(manifestState));
        var eu = expectedUtility(manifestState, belief, action, delay);
        factor(params.alpha * eu);
        return action;
      });
    });

  var expectedUtility = dp.cache(
    function (manifestState, belief, action, delay) {
      return expectation(
        Enumerate(function () {
          var latentState = sample(belief);
          var state = buildState(manifestState, latentState);
          var u = 1.0 / (1 + params.discount * delay) * utility(state, action);
          if (shouldTerminate(state, delay)){
            return u;
          } else {
            // Change state and get observation based on *latentState*
            var nextState = transition(state, action);
            var nextObservation = observe(nextState);

            // Update agent's internal state based on new manifestState, the observation, old belief, old delay.
            var transformedDelay = transformDelay(delay);
            var nextBelief = updateBelief(nextState.manifestState, belief, nextObservation, transformedDelay);
            var nextAction = sample(act(nextState.manifestState, nextBelief, transformedDelay));

            // Compute utility given agent's new internal belief state, the new manifestState, and agent's action. 
            var futureU = expectedUtility(nextState.manifestState,nextBelief,nextAction,incrementDelay(delay));
            return u + futureU;
          }
        }));
    });

  return { act:act, updateBelief:updateBelief, expectedUtility : expectedUtility, params: params};
};

var simulateBeliefDelayAgent = function (startState, world, agent, outputType) {

  var totalTime = startState.manifestState.timeLeft;
  assert.ok(isPOMDPState(startState), 'simulateBeliefDelayAgent args');
  assert.ok( _.contains(['states','actions','stateAction','stateBelief'], outputType), 
             "outputType key not in ['states', 'actions', 'stateAction', 'stateBelief']");
  assert.ok(totalTime > 1 || startState.manifestState.terminateAfterAction, 
            'if totalTime==1, must also terminateAfterAction');

  var agentAct = agent.act;
  var agentUpdateBelief = agent.updateBelief;
  var priorBelief = agent.params.priorBelief;
  var transition = world.transition;
  var observe = world.observe;
  
  var selectOutput = function(state, action, belief){
    var table =  {states:state, actions:action, stateAction:[state, action], 
                  stateBelief: [state, belief]};
    return table[outputType];
  };

  var shouldTerminate = function (manifestState) { return manifestState.terminateAfterAction; };

  var sampleSequence = function(state, priorBelief) {
    var observation = observe(state);
    
    var delay = 0;
    var belief = agentUpdateBelief(state.manifestState, priorBelief, observation, delay);
    var action = sample(agentAct(state.manifestState, belief, delay));       
    var output = [selectOutput(state, action, belief)];

    if (shouldTerminate(state.manifestState)) {
      return output;
    } else {   
      var nextState = transition(state, action);
      return output.concat(sampleSequence(nextState, belief));
    }
  };
  return sampleSequence(startState, priorBelief);
};







// TODO REWRITE EXP UTILITY IF IT NEEDS IT?

// Run *simulate*. Then use *expectedUtility* to compute the expected
// utilities of each state along the trajectory. Do this from the
// perspective of each timestep. For discounting agents, the expected
// utilities for the same state/timeLeft will change depending on how
// close the agent is to the state (as measured by *delay*).

var getExpectedUtilitiesBeliefDelayAgent = function (startState, world, agent, actualTotalTime){
  assert.ok( !agent.params.noDelays, 'Delays switched off. This function uses variation in delays.');
  
  var trajectory = simulateBeliefDelayAgent(startState, world, agent, actualTotalTime, 'stateBelief');
  
  var expectedUtility = agent.expectedUtility;
  var stateToActions = world.manifestStateToActions;

  
  var getExpectedUtilityFromTimestep = function(t){
    var trajectoryAfterT = trajectory.slice(t, trajectory.length);
    var len = trajectoryAfterT.length;
    
    return map(function(stateBelief){
      var manifestState = stateBelief[0].manifestState;
      var belief = stateBelief[1];
      var timeLeft = manifestState.timeLeft;
      var delay = len - timeLeft;
      
      return [stateBelief[0], 
              map(function(a){
                return expectedUtility(manifestState, belief, a, delay);
              }, stateToActions(manifestState))
             ];
    }, trajectoryAfterT);
  };

  var expectedUtilities = map(getExpectedUtilityFromTimestep, _.range(trajectory.length));

  return {trajectory: trajectory, expectedUtilities: expectedUtilities};
  
};
